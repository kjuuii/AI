# -*- coding: utf-8 -*-
"""
Regression Tutorial Module for Streamlit App (Self-Contained Version)
Provides an interactive interface to demonstrate regression algorithms.
Includes necessary plotting functions directly.
"""
import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm # Added import
import platform # Added import
import os # Added import
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import traceback

# --- Font Setup (Included directly in this file) ---
def setup_better_chinese_font():
    """è®¾ç½®æ›´å¥½çš„ä¸­æ–‡å­—ä½“æ”¯æŒ"""
    system = platform.system()
    font_candidates = []
    if system == 'Windows':
        font_candidates = ['Microsoft YaHei', 'SimHei', 'SimSun', 'Arial Unicode MS']
    elif system == 'Darwin':  # macOS
        font_candidates = ['PingFang SC', 'Heiti SC', 'STHeiti', 'Apple LiGothic Medium']
    else:  # Linux å’Œå…¶ä»–ç³»ç»Ÿ
        font_candidates = ['Noto Sans CJK SC', 'WenQuanYi Micro Hei', 'Droid Sans Fallback']
    font_candidates.extend(['DejaVu Sans', 'Arial', 'Helvetica'])
    font_prop = None
    for font_name in font_candidates:
        try:
            font_path = fm.findfont(fm.FontProperties(family=font_name))
            if os.path.exists(font_path) and 'DejaVuSans' not in font_path:
                print(f"å­—ä½“æ—¥å¿— (Tutorial): ä½¿ç”¨å­—ä½“ '{font_name}' åœ¨è·¯å¾„: {font_path}")
                plt.rcParams['font.family'] = 'sans-serif'
                plt.rcParams['font.sans-serif'] = [font_name] + plt.rcParams['font.sans-serif']
                font_prop = fm.FontProperties(family=font_name)
                break
        except Exception as e:
            print(f"å­—ä½“æ—¥å¿— (Tutorial): å°è¯•å­—ä½“ {font_name} å¤±è´¥: {e}")
    if not font_prop:
        print("å­—ä½“æ—¥å¿— (Tutorial): æœªæ‰¾åˆ°åˆé€‚çš„ä¸­æ–‡å­—ä½“ã€‚")
    plt.rcParams['axes.unicode_minus'] = False
    return font_prop

FONT_PROP = setup_better_chinese_font() # Define FONT_PROP globally in this module

# --- Plotting Helper Functions (Included directly) ---
def apply_plot_style(ax):
    """åº”ç”¨ç»Ÿä¸€çš„ç»˜å›¾æ ·å¼"""
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.grid(True, linestyle='--', alpha=0.6, color='#bdc3c7')
    ax.tick_params(axis='both', which='major', labelsize=9, colors='#34495e')
    ax.xaxis.label.set_fontsize(10)
    ax.yaxis.label.set_fontsize(10)
    ax.title.set_fontsize(12)
    ax.title.set_fontweight('bold')
    ax.xaxis.label.set_fontweight('bold')
    ax.yaxis.label.set_fontweight('bold')
    font_kwargs = {'fontproperties': FONT_PROP} if FONT_PROP else {}
    if font_kwargs:
        for label in ax.get_xticklabels() + ax.get_yticklabels():
            label.set_fontproperties(FONT_PROP)
        ax.xaxis.label.set_fontproperties(FONT_PROP)
        ax.yaxis.label.set_fontproperties(FONT_PROP)
        ax.title.set_fontproperties(FONT_PROP)
    return ax

def create_figure_with_safe_dimensions(width_inches, height_inches, dpi=80):
    """åˆ›å»ºä¸ä¼šè¶…å‡ºMatplotlibé™åˆ¶çš„å›¾å½¢å°ºå¯¸"""
    max_pixels = 65000
    width_dpi = max_pixels / width_inches if width_inches > 0 else dpi
    height_dpi = max_pixels / height_inches if height_inches > 0 else dpi
    safe_dpi = min(width_dpi, height_dpi, dpi)
    fig, ax = plt.subplots(figsize=(width_inches, height_inches), dpi=safe_dpi)
    return fig, ax

# --- Core Plotting Functions (Copied from regression_validation.py logic) ---
def plot_validation_results(true_values, predictions, indices=None, model_name="Model"):
    """ç»˜åˆ¶æ¨¡å‹é¢„æµ‹å€¼ vs çœŸå®å€¼ (å›å½’)"""
    fig, ax = create_figure_with_safe_dimensions(10, 6) # Use the local helper
    apply_plot_style(ax) # Use the local helper
    font_kwargs = {'fontproperties': FONT_PROP} if FONT_PROP else {}

    # Ensure inputs are numpy arrays
    true_values_np = np.asarray(true_values)
    predictions_np = np.asarray(predictions)

    if indices is None:
        indices = np.arange(len(true_values_np))
    else:
        indices = np.asarray(indices)

    if len(true_values_np) != len(predictions_np) or len(indices) != len(true_values_np):
        ax.text(0.5, 0.5, 'ç»˜å›¾é”™è¯¯ï¼šæ•°æ®é•¿åº¦ä¸åŒ¹é…', ha='center', va='center', transform=ax.transAxes, color='red', **font_kwargs)
        return fig

    try:
        # Sort data by indices for proper line plotting if indices are meaningful
        if len(indices) > 1 and np.any(np.diff(indices) < 0): # Check if sorting is needed
             sort_indices_order = np.argsort(indices)
             sorted_indices = indices[sort_indices_order]
             sorted_true = true_values_np[sort_indices_order]
             sorted_pred = predictions_np[sort_indices_order]
        else: # If indices are sequential or single point, no need to sort
             sorted_indices = indices
             sorted_true = true_values_np
             sorted_pred = predictions_np

        # Plot lines or scatter depending on data size
        marker_true = 'o'
        marker_pred = 'x'
        linestyle_true = '-'
        linestyle_pred = '--'
        markersize_true = 3
        markersize_pred = 4
        if len(sorted_indices) > 200: # Use smaller markers for large datasets
             marker_true = '.'
             marker_pred = '.'
             markersize_true = 2
             markersize_pred = 2
             linestyle_true = 'None' # Use scatter plot for large data
             linestyle_pred = 'None'


        ax.plot(sorted_indices, sorted_true, color='#2ecc71', label='çœŸå®å€¼',
                linewidth=1.5, linestyle=linestyle_true, marker=marker_true, markersize=markersize_true, alpha=0.8)
        ax.plot(sorted_indices, sorted_pred, color='#e74c3c', label=f'{model_name}é¢„æµ‹å€¼',
                linewidth=1.5, linestyle=linestyle_pred, marker=marker_pred, markersize=markersize_pred, alpha=0.8)

        ax.set_title('æ¨¡å‹é¢„æµ‹å€¼ vs çœŸå®å€¼', **font_kwargs)
        ax.set_xlabel('æ ·æœ¬ç´¢å¼•' if len(indices) <= 1 or np.all(np.diff(indices) > 0) else 'ç´¢å¼•å€¼', **font_kwargs) # Adjust x-label based on indices
        ax.set_ylabel('å€¼', **font_kwargs)
        legend = ax.legend(prop=FONT_PROP, fontsize=9)
        if FONT_PROP:
            for text in legend.get_texts():
                text.set_fontproperties(FONT_PROP)
        plt.tight_layout()
    except Exception as e:
        ax.text(0.5, 0.5, f'ç»˜å›¾é”™è¯¯ï¼š{str(e)}', ha='center', va='center', transform=ax.transAxes, color='red', **font_kwargs)

    return fig


def plot_residuals(true_values, predictions, indices=None, model_name="Model"):
    """ç»˜åˆ¶æ®‹å·®å›¾ (çœŸå®å€¼ - é¢„æµ‹å€¼)"""
    fig, ax = create_figure_with_safe_dimensions(10, 6) # Use the local helper
    apply_plot_style(ax) # Use the local helper
    font_kwargs = {'fontproperties': FONT_PROP} if FONT_PROP else {}

    # Ensure inputs are numpy arrays
    true_values_np = np.asarray(true_values)
    predictions_np = np.asarray(predictions)

    if indices is None:
        indices = np.arange(len(true_values_np))
    else:
        indices = np.asarray(indices)

    if len(true_values_np) != len(predictions_np) or len(indices) != len(true_values_np):
        ax.text(0.5, 0.5, 'ç»˜å›¾é”™è¯¯ï¼šæ•°æ®é•¿åº¦ä¸åŒ¹é…', ha='center', va='center', transform=ax.transAxes, color='red', **font_kwargs)
        return fig

    try:
        residuals = true_values_np - predictions_np

        # Sort by indices if needed
        if len(indices) > 1 and np.any(np.diff(indices) < 0): # Check if sorting is needed
            sort_indices_order = np.argsort(indices)
            sorted_indices = indices[sort_indices_order]
            sorted_residuals = residuals[sort_indices_order]
        else:
            sorted_indices = indices
            sorted_residuals = residuals

        # Plot residuals
        marker = '.'
        linestyle = '-'
        if len(sorted_indices) > 200: # Use scatter for large data
             linestyle = 'None'

        ax.plot(sorted_indices, sorted_residuals, color='#3498db', label=f'{model_name}æ®‹å·®',
                linewidth=1.5, linestyle=linestyle, marker=marker, markersize=3, alpha=0.8)
        ax.axhline(y=0, color='#e74c3c', linestyle='--', alpha=0.7, linewidth=1.0)

        ax.set_title('æ®‹å·®åˆ†æ (çœŸå®å€¼ - é¢„æµ‹å€¼)', **font_kwargs)
        ax.set_xlabel('æ ·æœ¬ç´¢å¼•' if len(indices) <= 1 or np.all(np.diff(indices) > 0) else 'ç´¢å¼•å€¼', **font_kwargs)
        ax.set_ylabel('æ®‹å·®', **font_kwargs)
        legend = ax.legend(prop=FONT_PROP, fontsize=9)
        if FONT_PROP:
            for text in legend.get_texts():
                text.set_fontproperties(FONT_PROP)
        plt.tight_layout()
    except Exception as e:
        ax.text(0.5, 0.5, f'ç»˜å›¾é”™è¯¯ï¼š{str(e)}', ha='center', va='center', transform=ax.transAxes, color='red', **font_kwargs)

    return fig


# --- æ•™å­¦çŠ¶æ€åˆå§‹åŒ– ---
def initialize_regression_tutorial_state():
    """åˆå§‹åŒ–å›å½’æ•™å­¦æ¨¡å—ä¸“ç”¨çš„ä¼šè¯çŠ¶æ€å˜é‡"""
    defaults = {
        'reg_tut_dataset_name': 'Synthetic', 'reg_tut_n_samples': 200, 'reg_tut_n_features': 1,
        'reg_tut_n_informative': 1, 'reg_tut_noise': 15.0, 'reg_tut_bias': 0.0,
        'reg_tut_method_select': 'Linear Regression', # Use key name for state
        'reg_tut_ridge_alpha': 1.0,
        'reg_tut_lasso_alpha': 1.0,
        'reg_tut_svr_c': 1.0, 'reg_tut_svr_kernel': 'rbf', 'reg_tut_svr_epsilon': 0.1,
        'reg_tut_rf_n_estimators': 100, 'reg_tut_rf_max_depth': 0, # Use 0 for None
        'reg_tut_data_X_raw': None,
        'reg_tut_data_X': None, # æ ‡å‡†åŒ–åçš„ç‰¹å¾æ•°æ®
        'reg_tut_data_y': None, # çœŸå®ç›®æ ‡å€¼
        'reg_tut_X_train': None, 'reg_tut_X_test': None,
        'reg_tut_y_train': None, 'reg_tut_y_test': None,
        'reg_tut_model': None, # è®­ç»ƒå¥½çš„æ¨¡å‹
        'reg_tut_y_pred': None, # æµ‹è¯•é›†é¢„æµ‹å€¼
        'reg_tut_scaler': StandardScaler(),
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value
        if key == 'reg_tut_rf_max_depth' and st.session_state.get(key) is None:
             st.session_state[key] = 0 # Ensure it's 0 if None

# --- æ•™å­¦ UI å‡½æ•° ---
def show_regression_tutorial_page():
    """åˆ›å»ºäº¤äº’å¼å›å½’æ•™å­¦æ¼”ç¤ºçš„ç”¨æˆ·ç•Œé¢"""
    initialize_regression_tutorial_state()

    st.header("ğŸ“ å›å½’æ•™å­¦æ¼”ç¤º")
    st.markdown("""
    æ¬¢è¿æ¥åˆ°å›å½’æ•™å­¦æ¨¡å—ï¼åœ¨è¿™é‡Œï¼Œä½ å¯ä»¥ï¼š
    1.  ç”Ÿæˆ **åˆæˆå›å½’æ•°æ®**ã€‚
    2.  è°ƒæ•´ç”Ÿæˆæ•°æ®çš„ **å‚æ•°**ï¼Œä¾‹å¦‚ç‰¹å¾æ•°é‡ã€å™ªå£°æ°´å¹³ç­‰ã€‚
    3.  é€‰æ‹© **å›å½’ç®—æ³•**ï¼ˆå¦‚çº¿æ€§å›å½’, Ridge, Lasso, SVR, éšæœºæ£®æ—å›å½’ï¼‰å¹¶è°ƒæ•´å…¶å…³é”®å‚æ•°ã€‚
    4.  **è®­ç»ƒæ¨¡å‹** å¹¶ **å¯è§†åŒ–** ç»“æœï¼ˆä¾‹å¦‚é¢„æµ‹å€¼ vs çœŸå®å€¼ã€æ®‹å·®å›¾ï¼‰ã€‚
    5.  æŸ¥çœ‹ **è¯„ä¼°æŒ‡æ ‡**ï¼ˆå¦‚ RÂ², MSE, MAEï¼‰å’Œç»“æœè§£è¯»ã€‚

    é€šè¿‡äº’åŠ¨æ“ä½œï¼Œç›´è§‚ç†è§£ä¸åŒå›å½’ç®—æ³•å¦‚ä½•æ‹Ÿåˆæ•°æ®ä»¥åŠå‚æ•°å˜åŒ–å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚
    """)
    st.markdown("---")

    # --- 1. ç”Ÿæˆåˆæˆæ•°æ®é›† ---
    st.subheader("1. ç”Ÿæˆåˆæˆæ•°æ®é›†")
    col_data1, col_data2 = st.columns(2)
    with col_data1:
        st.slider(
            "æ ·æœ¬æ•°é‡:", min_value=50, max_value=1000,
            value=st.session_state.reg_tut_n_samples, step=50, key="reg_tut_samples",
            help="ç”Ÿæˆæ•°æ®ç‚¹çš„æ€»æ•°ã€‚"
        )
        st.slider(
            "ç‰¹å¾æ•°é‡:", min_value=1, max_value=5,
            value=st.session_state.reg_tut_n_features, step=1, key="reg_tut_n_features",
            help="ç”Ÿæˆæ•°æ®çš„ç‰¹å¾ç»´åº¦ã€‚"
        )

        # --- Conditional Control for n_informative ---
        current_n_features = st.session_state.reg_tut_n_features

        if current_n_features <= 1:
            st.session_state.reg_tut_n_informative = 1
            st.markdown("**ä¿¡æ¯ç‰¹å¾æ•°:** 1 (å½“æ€»ç‰¹å¾æ•°ä¸º1æ—¶å›ºå®š)")
        else:
            max_informative = current_n_features
            current_informative_val = st.session_state.get('reg_tut_n_informative', 1)
            valid_informative_val = max(1, min(current_informative_val, max_informative))
            st.slider(
                "ä¿¡æ¯ç‰¹å¾æ•°:", min_value=1, max_value=max_informative,
                value=valid_informative_val, step=1, key="reg_tut_n_informative",
                help="çœŸæ­£ä¸ç›®æ ‡å€¼ç›¸å…³çš„ç‰¹å¾æ•°é‡ã€‚"
            )

    with col_data2:
        st.slider(
            "å™ªå£°æ°´å¹³ (noise):", min_value=0.0, max_value=50.0,
            value=st.session_state.reg_tut_noise, step=1.0, format="%.1f", key="reg_tut_noise",
            help="æ·»åŠ åˆ°ç›®æ ‡å€¼ä¸Šçš„é«˜æ–¯å™ªå£°çš„æ ‡å‡†å·®ã€‚"
        )
        st.slider(
            "åç½® (bias):", min_value=-50.0, max_value=50.0,
            value=st.session_state.reg_tut_bias, step=5.0, format="%.1f", key="reg_tut_bias",
            help="æ·»åŠ åˆ°ç›®æ ‡å€¼ä¸Šçš„å›ºå®šåç§»é‡ã€‚"
        )

    # --- ç”Ÿæˆæ•°æ®é›†æŒ‰é’® ---
    if st.button("ğŸ”„ ç”Ÿæˆ/æ›´æ–°æ•°æ®é›†", key="reg_tut_generate_data"):
        # ... (ç”Ÿæˆæ•°æ®é›†é€»è¾‘ä¿æŒä¸å˜ï¼Œè¯»å– state) ...
        X_raw, y_true = None, None
        with st.spinner("æ­£åœ¨ç”Ÿæˆæ•°æ®..."):
            try:
                random_state_data = 42
                n_samples = st.session_state.reg_tut_n_samples
                n_features = st.session_state.reg_tut_n_features
                n_informative = 1 if n_features <= 1 else st.session_state.reg_tut_n_informative
                n_informative = min(n_informative, n_features)
                noise = st.session_state.reg_tut_noise
                bias = st.session_state.reg_tut_bias

                X_raw, y_true = make_regression(
                    n_samples=n_samples, n_features=n_features, n_informative=n_informative,
                    noise=noise, bias=bias, random_state=random_state_data
                )
                if n_features == 1: X_raw = X_raw.reshape(-1, 1)

                st.session_state.reg_tut_data_X_raw = X_raw
                st.session_state.reg_tut_data_X = st.session_state.reg_tut_scaler.fit_transform(X_raw)
                st.session_state.reg_tut_data_y = y_true

                st.session_state.reg_tut_X_train, st.session_state.reg_tut_X_test, \
                st.session_state.reg_tut_y_train, st.session_state.reg_tut_y_test = train_test_split(
                    st.session_state.reg_tut_data_X, st.session_state.reg_tut_data_y,
                    test_size=0.3, random_state=random_state_data
                )
                st.session_state.reg_tut_model = None
                st.session_state.reg_tut_y_pred = None
                st.success("åˆæˆå›å½’æ•°æ®é›†å·²ç”Ÿæˆå¹¶åˆ†å‰²ã€‚")
            except Exception as data_err:
                st.error(f"ç”Ÿæˆæ•°æ®é›†æ—¶å‡ºé”™: {data_err}")
                print(traceback.format_exc())
                st.session_state.reg_tut_data_X = None


    # --- æ˜¾ç¤ºç”Ÿæˆçš„æ•°æ®é›† (ä»…å½“å•ç‰¹å¾æ—¶) ---
    # ä½¿ç”¨æœ¬åœ°å®šä¹‰çš„ç»˜å›¾å‡½æ•°
    if st.session_state.reg_tut_data_X is not None and st.session_state.reg_tut_n_features == 1:
        st.write("---")
        st.markdown("#### æ•°æ®é›†é¢„è§ˆï¼ˆå•ç‰¹å¾ vs ç›®æ ‡å€¼ï¼‰")
        try:
            fig_data, ax_data = create_figure_with_safe_dimensions(8, 5)
            ax_data.scatter(
                st.session_state.reg_tut_data_X,
                st.session_state.reg_tut_data_y,
                s=30, alpha=0.6, edgecolors='k', linewidth=0.5, label="æ•°æ®ç‚¹"
            )
            apply_plot_style(ax_data) # Use local function
            title_str = "åˆæˆå›å½’æ•°æ®é¢„è§ˆ"
            ax_data.set_title(title_str, fontproperties=FONT_PROP if FONT_PROP else None)
            ax_data.set_xlabel("ç‰¹å¾ (æ ‡å‡†åŒ–å)", fontproperties=FONT_PROP if FONT_PROP else None)
            ax_data.set_ylabel("ç›®æ ‡å€¼", fontproperties=FONT_PROP if FONT_PROP else None)
            legend = ax_data.legend(prop=FONT_PROP)
            if FONT_PROP:
                 for text in legend.get_texts(): text.set_fontproperties(FONT_PROP)
            st.pyplot(fig_data)
            plt.close(fig_data)
        except Exception as plot_err:
            st.warning(f"ç»˜åˆ¶æ•°æ®é›†å›¾è¡¨æ—¶å‡ºé”™: {plot_err}")
            print(traceback.format_exc())

    elif st.session_state.reg_tut_data_X is None:
        st.info("è¯·ç‚¹å‡» **â€œğŸ”„ ç”Ÿæˆ/æ›´æ–°æ•°æ®é›†â€** æŒ‰é’®æ¥åˆ›å»ºæ•°æ®ã€‚")
        return

    st.markdown("---")

    # --- 2. é€‰æ‹©å›å½’æ–¹æ³•ä¸å‚æ•° ---
    st.subheader("2. é€‰æ‹©å›å½’æ–¹æ³•ä¸å‚æ•°")
    reg_tut_method_options = ["Linear Regression", "Ridge", "Lasso", "SVR (æ”¯æŒå‘é‡å›å½’)", "Random Forest Regressor"]
    st.selectbox(
        "é€‰æ‹©å›å½’ç®—æ³•:", options=reg_tut_method_options, key="reg_tut_method_select",
        help="é€‰æ‹©è¦åº”ç”¨äºä¸Šæ–¹æ•°æ®çš„å›å½’ç®—æ³•ã€‚"
    )
    current_method = st.session_state.reg_tut_method_select

    # --- å‚æ•°è®¾ç½® (ä»£ç ä¸ä¸Šä¸€ç‰ˆæœ¬ç›¸åŒï¼Œç›´æ¥è¯»å–session stateå³å¯) ---
    if current_method == "Linear Regression":
        st.markdown("**ç®—æ³•è¯´æ˜:** çº¿æ€§å›å½’å°è¯•æ‰¾åˆ°ä¸€æ¡ç›´çº¿ï¼ˆæˆ–è¶…å¹³é¢ï¼‰æ¥æœ€ä½³æ‹Ÿåˆæ•°æ®ç‚¹ã€‚")
    elif current_method == "Ridge":
        st.slider("æ­£åˆ™åŒ–å¼ºåº¦ Alpha (Î±):", min_value=0.01, max_value=10.0, value=st.session_state.reg_tut_ridge_alpha, step=0.1, format="%.2f", key="reg_tut_ridge_alpha", help="æ§åˆ¶L2æ­£åˆ™åŒ–çš„å¼ºåº¦ã€‚")
        st.markdown("**ç®—æ³•è¯´æ˜:**å²­å›å½’æ˜¯çº¿æ€§å›å½’çš„ä¸€ç§å˜ä½“ï¼Œå¢åŠ äº†L2æ­£åˆ™åŒ–é¡¹ã€‚")
    elif current_method == "Lasso":
        st.slider("æ­£åˆ™åŒ–å¼ºåº¦ Alpha (Î±):", min_value=0.01, max_value=10.0, value=st.session_state.reg_tut_lasso_alpha, step=0.1, format="%.2f", key="reg_tut_lasso_alpha", help="æ§åˆ¶L1æ­£åˆ™åŒ–çš„å¼ºåº¦ã€‚")
        st.markdown("**ç®—æ³•è¯´æ˜:** Lasso å›å½’æ˜¯çº¿æ€§å›å½’çš„å˜ä½“ï¼Œå¢åŠ äº†L1æ­£åˆ™åŒ–é¡¹ã€‚")
    elif current_method == "SVR (æ”¯æŒå‘é‡å›å½’)":
        col_p1, col_p2, col_p3 = st.columns(3)
        with col_p1: st.slider("æ­£åˆ™åŒ–å¼ºåº¦ C:", min_value=0.1, max_value=10.0, value=st.session_state.reg_tut_svr_c, step=0.1, format="%.1f", key="reg_tut_svr_c", help="æ§åˆ¶è¿åé—´éš”è¾¹ç•Œçš„æƒ©ç½šç¨‹åº¦ã€‚")
        with col_p2: st.selectbox("æ ¸å‡½æ•° (kernel):", options=['rbf', 'linear', 'poly'], key="reg_tut_svr_kernel", help="'rbf'å’Œ'poly'å¯ä»¥å¤„ç†éçº¿æ€§å…³ç³»ã€‚")
        with col_p3: st.slider("Epsilon (Îµ):", min_value=0.01, max_value=1.0, value=st.session_state.reg_tut_svr_epsilon, step=0.01, format="%.2f", key="reg_tut_svr_epsilon", help="å®šä¹‰é—´éš”å¸¦çš„å®½åº¦ã€‚")
        st.markdown("**ç®—æ³•è¯´æ˜:** æ”¯æŒå‘é‡å›å½’è¯•å›¾æ‰¾åˆ°ä¸€ä¸ªå‡½æ•°ï¼Œä½¿å¾—å°½å¯èƒ½å¤šçš„æ ·æœ¬ç‚¹è½åœ¨é—´éš”å¸¦å†…ã€‚")
    elif current_method == "Random Forest Regressor":
        col_p1, col_p2 = st.columns(2)
        with col_p1: st.slider("æ ‘çš„æ•°é‡ (n_estimators):", min_value=10, max_value=200, value=st.session_state.reg_tut_rf_n_estimators, step=10, key="reg_tut_rf_n_estimators", help="æ£®æ—ä¸­å†³ç­–æ ‘çš„æ•°é‡ã€‚")
        with col_p2: st.slider("æ ‘çš„æœ€å¤§æ·±åº¦ (max_depth, 0è¡¨ç¤ºæ— é™åˆ¶):", min_value=0, max_value=20, value=st.session_state.reg_tut_rf_max_depth, step=1, key="reg_tut_rf_max_depth", help="é™åˆ¶å•æ£µå†³ç­–æ ‘çš„æœ€å¤§æ·±åº¦ã€‚0è¡¨ç¤ºä¸é™åˆ¶ã€‚")
        st.markdown("**ç®—æ³•è¯´æ˜:** éšæœºæ£®æ—å›å½’å™¨é€šè¿‡æ„å»ºå¤šæ£µå†³ç­–æ ‘å¹¶å¯¹å…¶é¢„æµ‹ç»“æœè¿›è¡Œå¹³å‡æ¥å·¥ä½œã€‚")

    # --- è®­ç»ƒæ¨¡å‹æŒ‰é’® ---
    if st.button("ğŸ§  è®­ç»ƒå¹¶è¯„ä¼°æ¨¡å‹", key="reg_tut_run_training", help="ä½¿ç”¨å½“å‰é€‰æ‹©çš„ç®—æ³•å’Œå‚æ•°è®­ç»ƒå›å½’æ¨¡å‹"):
        # ... (è®­ç»ƒæ¨¡å‹çš„é€»è¾‘ä¿æŒä¸å˜ï¼Œè¯»å– state) ...
        if st.session_state.reg_tut_X_train is None:
             st.error("è¯·å…ˆç”Ÿæˆæ•°æ®é›†ï¼")
        else:
            X_train_tut = st.session_state.reg_tut_X_train
            y_train_tut = st.session_state.reg_tut_y_train
            X_test_tut = st.session_state.reg_tut_X_test
            y_test_tut = st.session_state.reg_tut_y_test
            method_tut = st.session_state.reg_tut_method_select # Read selected method from state
            model_tut = None
            success_flag = False
            try:
                with st.spinner(f"æ­£åœ¨è®­ç»ƒ {method_tut}..."):
                    if method_tut == "Linear Regression": model_tut = LinearRegression()
                    elif method_tut == "Ridge": model_tut = Ridge(alpha=st.session_state.reg_tut_ridge_alpha)
                    elif method_tut == "Lasso": model_tut = Lasso(alpha=st.session_state.reg_tut_lasso_alpha)
                    elif method_tut == "SVR (æ”¯æŒå‘é‡å›å½’)": model_tut = SVR(C=st.session_state.reg_tut_svr_c, kernel=st.session_state.reg_tut_svr_kernel, epsilon=st.session_state.reg_tut_svr_epsilon)
                    elif method_tut == "Random Forest Regressor":
                        rf_depth_state = st.session_state.reg_tut_rf_max_depth
                        max_depth_param = None if rf_depth_state == 0 else rf_depth_state
                        model_tut = RandomForestRegressor(n_estimators=st.session_state.reg_tut_rf_n_estimators, max_depth=max_depth_param, random_state=42, n_jobs=-1)

                    if model_tut:
                         model_tut.fit(X_train_tut, y_train_tut)
                         st.session_state.reg_tut_model = model_tut
                         st.session_state.reg_tut_y_pred = model_tut.predict(X_test_tut)
                         success_flag = True
                if success_flag: st.success(f"{method_tut} æ¨¡å‹è®­ç»ƒå®Œæˆï¼è¯·æŸ¥çœ‹ä¸‹æ–¹è¯„ä¼°ç»“æœã€‚")
                else: st.error("æœªèƒ½åˆå§‹åŒ–æ‰€é€‰æ¨¡å‹ã€‚")
            except Exception as train_e:
                st.error(f"è®­ç»ƒ {method_tut} å‡ºé”™: {train_e}")
                print(traceback.format_exc())
                st.session_state.reg_tut_model = None
                st.session_state.reg_tut_y_pred = None

    st.markdown("---")

    # --- 3. æ˜¾ç¤ºè¯„ä¼°ç»“æœ ---
    if st.session_state.reg_tut_model is not None and st.session_state.reg_tut_y_pred is not None:
        st.subheader("3. æ¨¡å‹è¯„ä¼°ç»“æœï¼ˆåŸºäºæµ‹è¯•é›†ï¼‰")

        y_test = st.session_state.reg_tut_y_test
        y_pred = st.session_state.reg_tut_y_pred
        X_test = st.session_state.reg_tut_X_test

        # --- æ˜¾ç¤ºè¯„ä¼°æŒ‡æ ‡ ---
        try:
            r2 = r2_score(y_test, y_pred)
            mse = mean_squared_error(y_test, y_pred)
            mae = mean_absolute_error(y_test, y_pred)
            col_m1, col_m2, col_m3 = st.columns(3)
            with col_m1: st.metric("RÂ² åˆ†æ•° (R-squared)", f"{r2:.3f}", help="è§£é‡Šç›®æ ‡å˜é‡æ–¹å·®çš„æ¯”ä¾‹ã€‚è¶Šæ¥è¿‘1è¶Šå¥½ã€‚")
            with col_m2: st.metric("å‡æ–¹è¯¯å·® (MSE)", f"{mse:.3f}", help="é¢„æµ‹è¯¯å·®å¹³æ–¹çš„å¹³å‡å€¼ã€‚è¶Šå°è¶Šå¥½ã€‚")
            with col_m3: st.metric("å¹³å‡ç»å¯¹è¯¯å·® (MAE)", f"{mae:.3f}", help="é¢„æµ‹è¯¯å·®ç»å¯¹å€¼çš„å¹³å‡å€¼ã€‚è¶Šå°è¶Šå¥½ã€‚")
        except Exception as metric_e:
            st.error(f"è®¡ç®—è¯„ä¼°æŒ‡æ ‡æ—¶å‡ºé”™: {metric_e}")

        # --- æ˜¾ç¤ºå¯è§†åŒ–ç»“æœ (ä½¿ç”¨æœ¬æ–‡ä»¶å†…å®šä¹‰çš„ç»˜å›¾å‡½æ•°) ---
        col_viz1, col_viz2 = st.columns(2)
        with col_viz1:
            st.markdown("##### é¢„æµ‹å€¼ vs. çœŸå®å€¼")
            st.markdown("ç†æƒ³æƒ…å†µä¸‹ï¼Œç‚¹åº”èšé›†åœ¨å¯¹è§’çº¿é™„è¿‘ã€‚")
            try:
                fig_pred = plot_validation_results(y_test, y_pred, model_name=st.session_state.reg_tut_method_select)
                st.pyplot(fig_pred)
                plt.close(fig_pred)
            except Exception as pred_err:
                 st.warning(f"ç»˜åˆ¶é¢„æµ‹å¯¹æ¯”å›¾æ—¶å‡ºé”™: {pred_err}")
                 print(traceback.format_exc())
        with col_viz2:
            st.markdown("##### æ®‹å·®å›¾ (çœŸå®å€¼ - é¢„æµ‹å€¼)")
            st.markdown("ç†æƒ³æƒ…å†µä¸‹ï¼Œæ®‹å·®åº”éšæœºåˆ†å¸ƒåœ¨0çº¿å‘¨å›´ã€‚")
            try:
                 fig_res = plot_residuals(y_test, y_pred, model_name=st.session_state.reg_tut_method_select)
                 st.pyplot(fig_res)
                 plt.close(fig_res)
            except Exception as res_err:
                 st.warning(f"ç»˜åˆ¶æ®‹å·®å›¾æ—¶å‡ºé”™: {res_err}")
                 print(traceback.format_exc())

        # --- ç»“æœè§£è¯» ---
        st.markdown("#### ç»“æœè§£è¯»æç¤º")
        st.markdown("- **RÂ² åˆ†æ•°:** æ¥è¿‘ 1 è¡¨ç¤ºæ¨¡å‹æ‹Ÿåˆå¾—å¾ˆå¥½ã€‚æ¥è¿‘ 0 è¡¨ç¤ºæ•ˆæœç±»ä¼¼é¢„æµ‹å¹³å‡å€¼ã€‚è´Ÿæ•°è¡¨ç¤ºæ•ˆæœå¾ˆå·®ã€‚")
        st.markdown("- **MSE / MAE:** å€¼è¶Šå°è¡¨ç¤ºé¢„æµ‹è¶Šæ¥è¿‘çœŸå®å€¼ã€‚MSE å¯¹å¤§è¯¯å·®æ›´æ•æ„Ÿã€‚")
        st.markdown("- **é¢„æµ‹å€¼ vs. çœŸå®å€¼å›¾:** ç‚¹è¶Šé è¿‘å¯¹è§’çº¿ï¼ˆy=xï¼‰ï¼Œè¯´æ˜é¢„æµ‹è¶Šå‡†ç¡®ã€‚")
        st.markdown("- **æ®‹å·®å›¾:** ç‚¹éšæœºåˆ†å¸ƒåœ¨ 0 çº¿ä¸Šä¸‹æ˜¯å¥½çš„è¿¹è±¡ã€‚å¦‚æœå‘ˆç°æ¨¡å¼ï¼ˆæ›²çº¿ã€å–‡å­å½¢ï¼‰ï¼Œå¯èƒ½è¡¨ç¤ºæ¨¡å‹æœ‰é—®é¢˜ã€‚")

# --- å…è®¸ç›´æ¥è¿è¡Œæ­¤è„šæœ¬è¿›è¡Œæµ‹è¯• ---
if __name__ == "__main__":
    st.set_page_config(layout="wide", page_title="å›å½’æ•™å­¦æ¼”ç¤ºï¼ˆç‹¬ç«‹è¿è¡Œï¼‰")
    st.sidebar.info("è¿™æ˜¯å›å½’æ•™å­¦æ¨¡å—çš„ç‹¬ç«‹æµ‹è¯•è¿è¡Œã€‚")
    show_regression_tutorial_page()