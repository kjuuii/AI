# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import base64
from io import BytesIO
from sklearn.decomposition import PCA, TruncatedSVD, FastICA, FactorAnalysis
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.manifold import TSNE, Isomap
from sklearn.preprocessing import StandardScaler, LabelEncoder
import platform
import matplotlib.font_manager as fm
import datetime
import warnings

warnings.filterwarnings('ignore')

try:
    import umap

    UMAP_AVAILABLE = True
except ImportError:
    UMAP_AVAILABLE = False
    st.warning("UMAPåº“æœªå®‰è£…ï¼ŒUMAPåŠŸèƒ½ä¸å¯ç”¨ã€‚è¯·è¿è¡Œï¼špip install umap-learn")


# --- å­—ä½“è®¾ç½® ---
def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ"""
    system = platform.system()
    font_candidates = []
    if system == 'Windows':
        font_candidates = ['Microsoft YaHei', 'SimHei', 'SimSun', 'Arial Unicode MS']
    elif system == 'Darwin':
        font_candidates = ['PingFang SC', 'Heiti SC', 'STHeiti', 'Apple LiGothic Medium']
    else:
        font_candidates = ['Noto Sans CJK SC', 'WenQuanYi Micro Hei', 'Droid Sans Fallback']
    font_candidates.extend(['DejaVu Sans', 'Arial', 'Helvetica'])

    font_prop = None
    for font_name in font_candidates:
        try:
            font_path = fm.findfind(fm.FontProperties(family=font_name))
            if os.path.exists(font_path) and 'DejaVuSans' not in font_path:
                print(f"å­—ä½“æ—¥å¿—: ä½¿ç”¨å­—ä½“ '{font_name}' åœ¨è·¯å¾„: {font_path}")
                plt.rcParams['font.family'] = 'sans-serif'
                plt.rcParams['font.sans-serif'] = [font_name] + plt.rcParams['font.sans-serif']
                font_prop = fm.FontProperties(family=font_name)
                break
        except Exception as e:
            print(f"å­—ä½“æ—¥å¿—: å°è¯•å­—ä½“ {font_name} å¤±è´¥: {e}")

    if not font_prop:
        print("å­—ä½“æ—¥å¿—: æœªæ‰¾åˆ°åˆé€‚çš„ä¸­æ–‡å­—ä½“ï¼Œç»˜å›¾ä¸­çš„ä¸­æ–‡å¯èƒ½æ— æ³•æ­£å¸¸æ˜¾ç¤ºã€‚")
    plt.rcParams['axes.unicode_minus'] = False
    return font_prop


FONT_PROP = setup_chinese_font()


# --- ç»˜å›¾è¾…åŠ©å‡½æ•° ---
def apply_plot_style(ax):
    """åº”ç”¨ç»Ÿä¸€çš„ç»˜å›¾æ ·å¼"""
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.grid(True, linestyle='--', alpha=0.6, color='#bdc3c7')
    ax.tick_params(axis='both', which='major', labelsize=9, colors='#34495e')
    ax.xaxis.label.set_fontsize(10);
    ax.yaxis.label.set_fontsize(10)
    ax.title.set_fontsize(12);
    ax.title.set_fontweight('bold')
    ax.xaxis.label.set_fontweight('bold');
    ax.yaxis.label.set_fontweight('bold')
    return ax


# --- é™ç»´ç®—æ³•ä¿¡æ¯ ---
ALGORITHM_INFO = {
    "PCA": {
        "name": "ä¸»æˆåˆ†åˆ†æ",
        "description": "é€šè¿‡æ­£äº¤å˜æ¢å°†æ•°æ®æŠ•å½±åˆ°ä¸»æˆåˆ†æ–¹å‘",
        "suitable_for": [
            "â€¢ é«˜ç»´çº¿æ€§ç›¸å…³æ•°æ®",
            "â€¢ ç‰¹å¾å‹ç¼©å’Œå™ªå£°é™ä½",
            "â€¢ æ•°æ®é¢„å¤„ç†å’Œå¯è§†åŒ–",
            "â€¢ éœ€è¦è§£é‡Šä¸»æˆåˆ†å«ä¹‰çš„åœºæ™¯"
        ],
        "pros": [
            "â€¢ çº¿æ€§å˜æ¢ï¼Œè®¡ç®—ç®€å•å¿«é€Ÿ",
            "â€¢ ä¿ç•™æœ€å¤§æ–¹å·®ä¿¡æ¯",
            "â€¢ å¯ä»¥è§£é‡Šä¸»æˆåˆ†å«ä¹‰",
            "â€¢ é€‚åˆçº¿æ€§ç»“æ„æ•°æ®"
        ],
        "cons": [
            "â€¢ å¯¹éçº¿æ€§ç»“æ„æ•ˆæœå·®",
            "â€¢ å—å¼‚å¸¸å€¼å½±å“å¤§",
            "â€¢ éœ€è¦æ ‡å‡†åŒ–é¢„å¤„ç†",
            "â€¢ ä¸»æˆåˆ†è§£é‡Šéœ€è¦ä¸“ä¸šçŸ¥è¯†"
        ],
        "params": ["n_components"]
    },
    "TSNE": {
        "name": "t-SNE",
        "description": "åŸºäºæ¦‚ç‡åˆ†å¸ƒçš„éçº¿æ€§é™ç»´æŠ€æœ¯",
        "suitable_for": [
            "â€¢ é«˜ç»´æ•°æ®å¯è§†åŒ–",
            "â€¢ å¤æ‚éçº¿æ€§ç»“æ„æ•°æ®",
            "â€¢ èšç±»ç»“æ„å±•ç¤º",
            "â€¢ ç§‘å­¦ç ”ç©¶å’Œæ•°æ®æ¢ç´¢"
        ],
        "pros": [
            "â€¢ éå¸¸é€‚åˆå¯è§†åŒ–",
            "â€¢ èƒ½ä¿æŒå±€éƒ¨é‚»åŸŸç»“æ„",
            "â€¢ å¤„ç†éçº¿æ€§æ•°æ®å‡ºè‰²",
            "â€¢ å¯¹èšç±»ç»“æ„å±•ç¤ºæ¸…æ™°"
        ],
        "cons": [
            "â€¢ è®¡ç®—å¤æ‚åº¦é«˜",
            "â€¢ è¶…å‚æ•°æ•æ„Ÿ",
            "â€¢ ä¸é€‚åˆæ–°æ•°æ®æŠ•å½±",
            "â€¢ ç»“æœå¯èƒ½ä¸ç¨³å®š"
        ],
        "params": ["n_components", "perplexity", "learning_rate", "n_iter"]
    },
    "UMAP": {
        "name": "UMAP",
        "description": "å‡åŒ€æµå½¢é€¼è¿‘æŠ•å½±ï¼Œç°ä»£éçº¿æ€§é™ç»´ç®—æ³•",
        "suitable_for": [
            "â€¢ å¤§è§„æ¨¡æ•°æ®é™ç»´",
            "â€¢ ä¿æŒå…¨å±€ç»“æ„",
            "â€¢ èšç±»å’Œåˆ†ç±»é¢„å¤„ç†",
            "â€¢ å®æ—¶æ•°æ®å¤„ç†"
        ],
        "pros": [
            "â€¢ æ¯”t-SNEé€Ÿåº¦å¿«",
            "â€¢ ä¿æŒå…¨å±€å’Œå±€éƒ¨ç»“æ„",
            "â€¢ æ”¯æŒæ–°æ•°æ®æŠ•å½±",
            "â€¢ å‚æ•°è¾ƒå°‘ä¸”ç¨³å®š"
        ],
        "cons": [
            "â€¢ éœ€è¦é¢å¤–å®‰è£…åº“",
            "â€¢ ç†è®ºè¾ƒæ–°ï¼Œæ–‡æ¡£è¾ƒå°‘",
            "â€¢ å¯¹å¯†åº¦è¾ƒæ•æ„Ÿ"
        ],
        "params": ["n_components", "n_neighbors", "min_dist"]
    },
    "LDA": {
        "name": "çº¿æ€§åˆ¤åˆ«åˆ†æ",
        "description": "æœ‰ç›‘ç£çš„çº¿æ€§é™ç»´ç®—æ³•",
        "suitable_for": [
            "â€¢ åˆ†ç±»é¢„å¤„ç†",
            "â€¢ æœ‰æ ‡ç­¾çš„æ•°æ®",
            "â€¢ ç‰¹å¾é€‰æ‹©",
            "â€¢ æ¨¡å¼è¯†åˆ«ä»»åŠ¡"
        ],
        "pros": [
            "â€¢ æœ‰ç›‘ç£ï¼Œæ•ˆæœæ›´å¥½",
            "â€¢ æœ€å¤§åŒ–ç±»é—´å·®å¼‚",
            "â€¢ è®¡ç®—æ•ˆç‡é«˜",
            "â€¢ ç›´æ¥ç”¨äºåˆ†ç±»"
        ],
        "cons": [
            "â€¢ éœ€è¦æ ‡ç­¾ä¿¡æ¯",
            "â€¢ å‡è®¾é«˜æ–¯åˆ†å¸ƒ",
            "â€¢ çº¿æ€§è¾¹ç•Œé™åˆ¶",
            "â€¢ ç»´åº¦å—ç±»åˆ«æ•°é™åˆ¶"
        ],
        "params": ["n_components"]
    },
    "ICA": {
        "name": "ç‹¬ç«‹æˆåˆ†åˆ†æ",
        "description": "ç›²æºåˆ†ç¦»æŠ€æœ¯ï¼ŒæŒ–æ˜ç‹¬ç«‹ä¿¡å·",
        "suitable_for": [
            "â€¢ ä¿¡å·å¤„ç†",
            "â€¢ ç‰¹å¾æå–",
            "â€¢ æ•°æ®å»å™ª",
            "â€¢ å›¾åƒå¤„ç†"
        ],
        "pros": [
            "â€¢ æ‰¾åˆ°ç»Ÿè®¡ç‹¬ç«‹çš„æˆåˆ†",
            "â€¢ é€‚åˆä¿¡å·åˆ†ç¦»",
            "â€¢ å¤„ç†éé«˜æ–¯æ•°æ®",
            "â€¢ å¯ç”¨äºç‰¹å¾æå–"
        ],
        "cons": [
            "â€¢ éœ€è¦å‡è®¾ç»Ÿè®¡ç‹¬ç«‹",
            "â€¢ å¯¹å¼‚å¸¸å€¼æ•æ„Ÿ",
            "â€¢ ç»“æœå¯èƒ½éœ€è¦è§£é‡Š"
        ],
        "params": ["n_components", "max_iter"]
    },
    "Isomap": {
        "name": "ç­‰è·æ˜ å°„",
        "description": "åŸºäºæµ‹åœ°è·ç¦»çš„éçº¿æ€§é™ç»´",
        "suitable_for": [
            "â€¢ æµå½¢å­¦ä¹ ",
            "â€¢ éçº¿æ€§æ•°æ®ç»“æ„",
            "â€¢ ä¿æŒæµ‹åœ°è·ç¦»",
            "â€¢ æœ‰å†…åœ¨ä½ç»´ç»“æ„çš„æ•°æ®"
        ],
        "pros": [
            "â€¢ ä¿æŒæµ‹åœ°è·ç¦»",
            "â€¢ æ•æ‰éçº¿æ€§ç»“æ„",
            "â€¢ ç†è®ºåŸºç¡€æ‰å®",
            "â€¢ é€‚åˆæµå½¢æ•°æ®"
        ],
        "cons": [
            "â€¢ éœ€è¦é€‰æ‹©é‚»å±…æ•°",
            "â€¢ å¯¹å¼‚å¸¸å€¼æ•æ„Ÿ",
            "â€¢ è®¡ç®—å¤æ‚åº¦é«˜",
            "â€¢ éœ€è¦æ•°æ®æœ‰æµå½¢ç»“æ„"
        ],
        "params": ["n_components", "n_neighbors"]
    }
}


# --- Streamlit UI å‡½æ•° ---
def initialize_reduction_session_state():
    """åˆå§‹åŒ–é™ç»´é¡µé¢çš„ä¼šè¯çŠ¶æ€"""
    defaults = {
        'reduction_data': None,
        'reduction_original_data': None,
        'reduction_column_names': [],
        'reduction_selected_features': [],
        'reduction_target_column': None,
        'reduction_has_target': False,
        'reduction_results': None,
        'reduction_algorithm': 'PCA',
        'reduction_normalize': True,
        # PCAå‚æ•°
        'reduction_pca_components': 2,
        # t-SNEå‚æ•°
        'reduction_tsne_components': 2,
        'reduction_tsne_perplexity': 30.0,
        'reduction_tsne_learning_rate': 200.0,
        'reduction_tsne_n_iter': 1000,
        # UMAPå‚æ•°
        'reduction_umap_components': 2,
        'reduction_umap_n_neighbors': 15,
        'reduction_umap_min_dist': 0.1,
        # LDAå‚æ•°
        'reduction_lda_components': 2,
        # ICAå‚æ•°
        'reduction_ica_components': 2,
        'reduction_ica_max_iter': 200,
        # Isomapå‚æ•°
        'reduction_isomap_components': 2,
        'reduction_isomap_n_neighbors': 5,
    }

    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


def show_data_reduction_page():
    """æ˜¾ç¤ºæ•°æ®é™ç»´é¡µé¢"""
    initialize_reduction_session_state()

    st.title("ğŸ“‰ æ•°æ®é™ç»´")

    # ç®—æ³•é€‰æ‹©åŒºåŸŸ
    st.markdown("## ğŸ“š é™ç»´ç®—æ³•é€‰æ‹©ä¸ä»‹ç»")

    algo_col1, algo_col2 = st.columns([1, 2])

    with algo_col1:
        available_algorithms = list(ALGORITHM_INFO.keys())
        if not UMAP_AVAILABLE:
            available_algorithms.remove("UMAP")

        st.session_state.reduction_algorithm = st.selectbox(
            "é€‰æ‹©é™ç»´ç®—æ³•",
            options=available_algorithms,
            index=available_algorithms.index(
                st.session_state.reduction_algorithm) if st.session_state.reduction_algorithm in available_algorithms else 0,
            key="reduction_algorithm_select"
        )

    with algo_col2:
        algo_info = ALGORITHM_INFO[st.session_state.reduction_algorithm]
        st.markdown(f"### {algo_info['name']} ç®—æ³•")
        st.markdown(f"**æè¿°**: {algo_info['description']}")

    # è¯¦ç»†ä»‹ç»
    info_col1, info_col2 = st.columns(2)

    with info_col1:
        st.markdown("#### ğŸ¯ é€‚ç”¨åœºæ™¯")
        for item in algo_info['suitable_for']:
            st.markdown(item)

    with info_col2:
        st.markdown("#### âœ… ä¼˜ç‚¹")
        for item in algo_info['pros']:
            st.markdown(item)

        st.markdown("#### âŒ ç¼ºç‚¹")
        for item in algo_info['cons']:
            st.markdown(item)

    st.markdown("---")

    # åˆ›å»ºé€‰é¡¹å¡
    tab1, tab2, tab3 = st.tabs(["ğŸ“ æ•°æ®å¯¼å…¥", "âš™ï¸ å‚æ•°è®¾ç½®", "ğŸ“ˆ ç»“æœå±•ç¤º"])

    with tab1:
        create_reduction_data_import_section()

    with tab2:
        create_reduction_params_section()

    with tab3:
        create_reduction_results_section()


def create_reduction_data_import_section():
    """åˆ›å»ºæ•°æ®å¯¼å…¥å’Œç‰¹å¾é€‰æ‹©éƒ¨åˆ†"""
    st.header("1. æ•°æ®å¯¼å…¥ä¸ç‰¹å¾é€‰æ‹©")

    uploaded_file = st.file_uploader("ä¸Šä¼ æ•°æ®æ–‡ä»¶ (CSV/Excel)",
                                     type=["csv", "xlsx", "xls"], key="reduction_uploader")

    if uploaded_file:
        if st.button("åŠ è½½æ•°æ®", key="reduction_load_btn"):
            with st.spinner("æ­£åœ¨åŠ è½½å’Œå¤„ç†æ•°æ®..."):
                try:
                    # åŠ è½½æ•°æ®
                    if uploaded_file.name.lower().endswith('.csv'):
                        data_original = pd.read_csv(uploaded_file)
                    else:
                        data_original = pd.read_excel(uploaded_file)

                    # å¤„ç†ç¼ºå¤±å€¼
                    initial_rows = len(data_original)
                    data_cleaned = data_original.dropna()
                    cleaned_rows = len(data_cleaned)

                    if cleaned_rows < initial_rows:
                        st.warning(f"ç§»é™¤äº† {initial_rows - cleaned_rows} è¡ŒåŒ…å«ç¼ºå¤±å€¼çš„æ•°æ®ã€‚")

                    if data_cleaned.empty:
                        st.error("å¤„ç†ç¼ºå¤±å€¼åæ•°æ®ä¸ºç©ºã€‚")
                        return

                    # åˆ†ç¦»æ•°å€¼åˆ—å’Œå…¶ä»–åˆ—
                    numeric_cols = data_cleaned.select_dtypes(include=np.number).columns.tolist()
                    categorical_cols = data_cleaned.select_dtypes(exclude=np.number).columns.tolist()

                    if not numeric_cols:
                        st.error("ä¸Šä¼ çš„æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æ•°å€¼åˆ—ã€‚")
                        return

                    # å­˜å‚¨æ•°æ®
                    st.session_state.reduction_data = data_cleaned
                    st.session_state.reduction_original_data = data_original
                    st.session_state.reduction_column_names = data_cleaned.columns.tolist()
                    st.session_state.reduction_selected_features = numeric_cols
                    st.session_state.reduction_results = None

                    st.success(f"æˆåŠŸåŠ è½½æ•°æ®: {cleaned_rows} è¡Œ, {len(data_cleaned.columns)} åˆ—")
                    st.info(f"æ‰¾åˆ° {len(numeric_cols)} ä¸ªæ•°å€¼åˆ—, {len(categorical_cols)} ä¸ªéæ•°å€¼åˆ—")

                except Exception as e:
                    st.error(f"åŠ è½½æ•°æ®æ—¶å‡ºé”™: {e}")

    # æ•°æ®é¢„è§ˆå’Œç‰¹å¾é€‰æ‹©
    if st.session_state.reduction_data is not None:
        st.subheader("æ•°æ®é¢„è§ˆ")
        st.dataframe(st.session_state.reduction_data.head())

        # ç‰¹å¾é€‰æ‹©
        st.subheader("ç‰¹å¾é€‰æ‹©")

        # æ•°å€¼ç‰¹å¾é€‰æ‹©
        numeric_cols = st.session_state.reduction_data.select_dtypes(include=np.number).columns.tolist()
        st.session_state.reduction_selected_features = st.multiselect(
            "é€‰æ‹©ç”¨äºé™ç»´çš„ç‰¹å¾åˆ—",
            numeric_cols,
            default=[col for col in st.session_state.reduction_selected_features if col in numeric_cols],
            key="reduction_feature_select"
        )

        # ç›®æ ‡åˆ—é€‰æ‹©ï¼ˆç”¨äºæœ‰ç›‘ç£ç®—æ³•ï¼‰
        if st.session_state.reduction_algorithm == "LDA":
            st.session_state.reduction_has_target = True
            all_cols = st.session_state.reduction_data.columns.tolist()
            non_feature_cols = [col for col in all_cols if col not in st.session_state.reduction_selected_features]

            if non_feature_cols:
                st.session_state.reduction_target_column = st.selectbox(
                    "é€‰æ‹©ç›®æ ‡åˆ—ï¼ˆç”¨äºLDAï¼‰",
                    options=[None] + non_feature_cols,
                    index=([None] + non_feature_cols).index(
                        st.session_state.reduction_target_column) if st.session_state.reduction_target_column in [
                        None] + non_feature_cols else 0,
                    key="reduction_target_select"
                )
            else:
                st.warning("æ²¡æœ‰å¯ç”¨ä½œç›®æ ‡åˆ—çš„åˆ—ã€‚")
        else:
            st.session_state.reduction_has_target = False
            st.session_state.reduction_target_column = None

        if not st.session_state.reduction_selected_features:
            st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾åˆ—ã€‚")
        else:
            st.info(f"å·²é€‰æ‹© {len(st.session_state.reduction_selected_features)} ä¸ªç‰¹å¾")


def create_reduction_params_section():
    """åˆ›å»ºå‚æ•°è®¾ç½®éƒ¨åˆ†"""
    st.header("2. å‚æ•°è®¾ç½®")

    if st.session_state.reduction_data is None:
        st.info("è¯·å…ˆåœ¨æ•°æ®å¯¼å…¥é€‰é¡¹å¡ä¸­åŠ è½½æ•°æ®ã€‚")
        return

    if not st.session_state.reduction_selected_features:
        st.warning("è¯·å…ˆåœ¨æ•°æ®å¯¼å…¥é€‰é¡¹å¡ä¸­é€‰æ‹©ç‰¹å¾åˆ—ã€‚")
        return

    # é¢„å¤„ç†é€‰é¡¹
    st.subheader("é¢„å¤„ç†")
    st.session_state.reduction_normalize = st.checkbox(
        "æ ‡å‡†åŒ–ç‰¹å¾ (æ¨è)",
        value=st.session_state.reduction_normalize,
        key="reduction_norm_cb"
    )

    # ç®—æ³•ç‰¹å®šå‚æ•°
    st.subheader(f"{st.session_state.reduction_algorithm} ç®—æ³•å‚æ•°")

    # æ£€æŸ¥LDAçš„ç‰¹æ®Šè¦æ±‚
    if st.session_state.reduction_algorithm == "LDA":
        if not st.session_state.reduction_target_column:
            st.error("LDAç®—æ³•éœ€è¦ç›®æ ‡åˆ—ã€‚è¯·åœ¨æ•°æ®å¯¼å…¥é€‰é¡¹å¡ä¸­é€‰æ‹©ç›®æ ‡åˆ—ã€‚")
            return

    # æ ¹æ®ç®—æ³•æ˜¾ç¤ºå‚æ•°è®¾ç½®
    if st.session_state.reduction_algorithm == "PCA":
        create_pca_params()
    elif st.session_state.reduction_algorithm == "TSNE":
        create_tsne_params()
    elif st.session_state.reduction_algorithm == "UMAP":
        create_umap_params()
    elif st.session_state.reduction_algorithm == "LDA":
        create_lda_params()
    elif st.session_state.reduction_algorithm == "ICA":
        create_ica_params()
    elif st.session_state.reduction_algorithm == "Isomap":
        create_isomap_params()

    # è¿è¡ŒæŒ‰é’®
    can_run = st.session_state.reduction_data is not None and st.session_state.reduction_selected_features
    if st.session_state.reduction_algorithm == "LDA":
        can_run = can_run and st.session_state.reduction_target_column is not None

    if st.button(f"è¿è¡Œ {st.session_state.reduction_algorithm} é™ç»´",
                 type="primary", key="run_reduction_btn", disabled=not can_run):
        run_dimension_reduction()


def create_pca_params():
    """åˆ›å»ºPCAå‚æ•°è®¾ç½®"""
    st.markdown("é€‰æ‹©ä¸»æˆåˆ†æ•°é‡ã€‚å»ºè®®å…ˆæŸ¥çœ‹æ–¹å·®è§£é‡Šç‡ï¼Œç„¶åé€‰æ‹©åˆé€‚çš„æˆåˆ†æ•°ã€‚")

    max_components = min(
        len(st.session_state.reduction_selected_features),
        len(st.session_state.reduction_data.dropna())
    )

    st.session_state.reduction_pca_components = st.slider(
        "ä¸»æˆåˆ†æ•°é‡",
        min_value=1,
        max_value=max_components,
        value=min(st.session_state.reduction_pca_components, max_components),
        key="pca_components_slider"
    )


def create_tsne_params():
    """åˆ›å»ºt-SNEå‚æ•°è®¾ç½®"""
    col1, col2 = st.columns(2)

    with col1:
        st.session_state.reduction_tsne_components = st.selectbox(
            "é™ç»´ç›®æ ‡ç»´åº¦",
            options=[2, 3],
            index=[2, 3].index(st.session_state.reduction_tsne_components),
            key="tsne_components_select"
        )

        st.session_state.reduction_tsne_perplexity = st.number_input(
            "Perplexity",
            min_value=5.0,
            max_value=100.0,
            value=st.session_state.reduction_tsne_perplexity,
            step=1.0,
            key="tsne_perplexity_input",
            help="æ§åˆ¶å±€éƒ¨å’Œå…¨å±€ç»“æ„çš„å¹³è¡¡ï¼Œé€šå¸¸åœ¨5-50ä¹‹é—´"
        )

    with col2:
        st.session_state.reduction_tsne_learning_rate = st.number_input(
            "å­¦ä¹ ç‡",
            min_value=10.0,
            max_value=1000.0,
            value=st.session_state.reduction_tsne_learning_rate,
            step=10.0,
            key="tsne_lr_input",
            help="æ§åˆ¶ä¼˜åŒ–æ­¥é•¿ï¼Œé€šå¸¸åœ¨10-1000ä¹‹é—´"
        )

        st.session_state.reduction_tsne_n_iter = st.number_input(
            "è¿­ä»£æ¬¡æ•°",
            min_value=250,
            max_value=5000,
            value=st.session_state.reduction_tsne_n_iter,
            step=250,
            key="tsne_iter_input",
            help="ä¼˜åŒ–è¿­ä»£æ¬¡æ•°ï¼Œè‡³å°‘250æ¬¡"
        )


def create_umap_params():
    """åˆ›å»ºUMAPå‚æ•°è®¾ç½®"""
    if not UMAP_AVAILABLE:
        st.error("UMAPåº“æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…ï¼špip install umap-learn")
        return

    col1, col2, col3 = st.columns(3)

    with col1:
        st.session_state.reduction_umap_components = st.selectbox(
            "é™ç»´ç›®æ ‡ç»´åº¦",
            options=[2, 3],
            index=[2, 3].index(st.session_state.reduction_umap_components),
            key="umap_components_select"
        )

    with col2:
        st.session_state.reduction_umap_n_neighbors = st.number_input(
            "é‚»å±…æ•°é‡",
            min_value=2,
            max_value=100,
            value=st.session_state.reduction_umap_n_neighbors,
            step=1,
            key="umap_neighbors_input",
            help="æ§åˆ¶å±€éƒ¨ç»“æ„ä¿æŒçš„ç¨‹åº¦"
        )

    with col3:
        st.session_state.reduction_umap_min_dist = st.number_input(
            "æœ€å°è·ç¦»",
            min_value=0.0,
            max_value=1.0,
            value=st.session_state.reduction_umap_min_dist,
            step=0.01,
            format="%.3f",
            key="umap_mindist_input",
            help="æ§åˆ¶é™ç»´åç‚¹çš„é—´éš”"
        )


def create_lda_params():
    """åˆ›å»ºLDAå‚æ•°è®¾ç½®"""
    if not st.session_state.reduction_target_column:
        st.error("è¯·å…ˆåœ¨æ•°æ®å¯¼å…¥é€‰é¡¹å¡ä¸­é€‰æ‹©ç›®æ ‡åˆ—ã€‚")
        return

    # è®¡ç®—æœ€å¤§å¯èƒ½çš„æˆåˆ†æ•°
    target_values = st.session_state.reduction_data[st.session_state.reduction_target_column].unique()
    max_components = min(
        len(target_values) - 1,  # LDAæœ€å¤šå¯æœ‰ç±»åˆ«æ•°-1ä¸ªæˆåˆ†
        len(st.session_state.reduction_selected_features)
    )

    if max_components <= 0:
        st.error("ç›®æ ‡åˆ—çš„ç±»åˆ«æ•°å¤ªå°‘ï¼Œæ— æ³•è¿›è¡ŒLDAé™ç»´ã€‚")
        return

    st.session_state.reduction_lda_components = st.slider(
        "é™ç»´ç›®æ ‡ç»´åº¦",
        min_value=1,
        max_value=max_components,
        value=min(st.session_state.reduction_lda_components, max_components),
        key="lda_components_slider"
    )

    st.info(f"ç›®æ ‡åˆ— '{st.session_state.reduction_target_column}' æœ‰ {len(target_values)} ä¸ªç±»åˆ«")


def create_ica_params():
    """åˆ›å»ºICAå‚æ•°è®¾ç½®"""
    col1, col2 = st.columns(2)

    with col1:
        max_components = len(st.session_state.reduction_selected_features)
        st.session_state.reduction_ica_components = st.slider(
            "ç‹¬ç«‹æˆåˆ†æ•°é‡",
            min_value=1,
            max_value=max_components,
            value=min(st.session_state.reduction_ica_components, max_components),
            key="ica_components_slider"
        )

    with col2:
        st.session_state.reduction_ica_max_iter = st.number_input(
            "æœ€å¤§è¿­ä»£æ¬¡æ•°",
            min_value=100,
            max_value=1000,
            value=st.session_state.reduction_ica_max_iter,
            step=50,
            key="ica_maxiter_input"
        )


def create_isomap_params():
    """åˆ›å»ºIsomapå‚æ•°è®¾ç½®"""
    col1, col2 = st.columns(2)

    with col1:
        max_components = len(st.session_state.reduction_selected_features)
        st.session_state.reduction_isomap_components = st.slider(
            "é™ç»´ç›®æ ‡ç»´åº¦",
            min_value=1,
            max_value=max_components,
            value=min(st.session_state.reduction_isomap_components, max_components),
            key="isomap_components_slider"
        )

    with col2:
        max_neighbors = len(st.session_state.reduction_data) - 1
        st.session_state.reduction_isomap_n_neighbors = st.number_input(
            "é‚»å±…æ•°é‡",
            min_value=2,
            max_value=min(100, max_neighbors),
            value=min(st.session_state.reduction_isomap_n_neighbors, max_neighbors),
            step=1,
            key="isomap_neighbors_input",
            help="æ„å»ºé‚»åŸŸå›¾æ‰€éœ€çš„é‚»å±…æ•°é‡"
        )


def run_dimension_reduction():
    """æ‰§è¡Œé™ç»´æ“ä½œ"""
    if st.session_state.reduction_data is None or not st.session_state.reduction_selected_features:
        st.error("è¯·å…ˆåŠ è½½æ•°æ®å¹¶é€‰æ‹©ç‰¹å¾ã€‚")
        return

    with st.spinner(f"æ­£åœ¨è¿è¡Œ {st.session_state.reduction_algorithm} é™ç»´..."):
        try:
            # å‡†å¤‡æ•°æ®
            X = st.session_state.reduction_data[st.session_state.reduction_selected_features].values

            # æ ‡å‡†åŒ–
            if st.session_state.reduction_normalize:
                scaler = StandardScaler()
                X = scaler.fit_transform(X)

            # å¯¹äºLDAï¼Œå‡†å¤‡ç›®æ ‡å˜é‡
            if st.session_state.reduction_algorithm == "LDA":
                y = st.session_state.reduction_data[st.session_state.reduction_target_column].values
                # å¦‚æœç›®æ ‡å˜é‡æ˜¯æ–‡æœ¬ï¼Œéœ€è¦ç¼–ç 
                if y.dtype == object:
                    label_encoder = LabelEncoder()
                    y = label_encoder.fit_transform(y)
                else:
                    label_encoder = None
            else:
                y = None
                label_encoder = None

            # æ‰§è¡Œé™ç»´
            if st.session_state.reduction_algorithm == "PCA":
                X_reduced, model = run_pca(X)
            elif st.session_state.reduction_algorithm == "TSNE":
                X_reduced, model = run_tsne(X)
            elif st.session_state.reduction_algorithm == "UMAP":
                X_reduced, model = run_umap_reduction(X)
            elif st.session_state.reduction_algorithm == "LDA":
                X_reduced, model = run_lda(X, y)
            elif st.session_state.reduction_algorithm == "ICA":
                X_reduced, model = run_ica(X)
            elif st.session_state.reduction_algorithm == "Isomap":
                X_reduced, model = run_isomap(X)

            # ä¿å­˜ç»“æœ
            st.session_state.reduction_results = {
                'X_reduced': X_reduced,
                'X_original': X,
                'model': model,
                'algorithm': st.session_state.reduction_algorithm,
                'feature_names': st.session_state.reduction_selected_features,
                'target': y,
                'target_column': st.session_state.reduction_target_column,
                'label_encoder': label_encoder,
                'n_components': X_reduced.shape[1]
            }

            st.success(f"{st.session_state.reduction_algorithm} é™ç»´å®Œæˆï¼")
            st.success(f"åŸå§‹ç»´åº¦: {X.shape[1]} â†’ é™ç»´åç»´åº¦: {X_reduced.shape[1]}")

        except Exception as e:
            st.error(f"è¿è¡Œ {st.session_state.reduction_algorithm} æ—¶å‡ºé”™: {e}")
            import traceback
            st.code(traceback.format_exc())


def run_pca(X):
    """è¿è¡ŒPCAé™ç»´"""
    pca = PCA(n_components=st.session_state.reduction_pca_components)
    X_reduced = pca.fit_transform(X)
    return X_reduced, pca


def run_tsne(X):
    """è¿è¡Œt-SNEé™ç»´"""
    tsne = TSNE(
        n_components=st.session_state.reduction_tsne_components,
        perplexity=st.session_state.reduction_tsne_perplexity,
        learning_rate=st.session_state.reduction_tsne_learning_rate,
        n_iter=st.session_state.reduction_tsne_n_iter,
        random_state=42
    )
    X_reduced = tsne.fit_transform(X)
    return X_reduced, tsne


def run_umap_reduction(X):
    """è¿è¡ŒUMAPé™ç»´"""
    if not UMAP_AVAILABLE:
        raise ImportError("UMAPæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…ï¼špip install umap-learn")

    reducer = umap.UMAP(
        n_components=st.session_state.reduction_umap_components,
        n_neighbors=st.session_state.reduction_umap_n_neighbors,
        min_dist=st.session_state.reduction_umap_min_dist,
        random_state=42
    )
    X_reduced = reducer.fit_transform(X)
    return X_reduced, reducer


def run_lda(X, y):
    """è¿è¡ŒLDAé™ç»´"""
    lda = LinearDiscriminantAnalysis(n_components=st.session_state.reduction_lda_components)
    X_reduced = lda.fit_transform(X, y)
    return X_reduced, lda


def run_ica(X):
    """è¿è¡ŒICAé™ç»´"""
    ica = FastICA(
        n_components=st.session_state.reduction_ica_components,
        max_iter=st.session_state.reduction_ica_max_iter,
        random_state=42
    )
    X_reduced = ica.fit_transform(X)
    return X_reduced, ica


def run_isomap(X):
    """è¿è¡ŒIsomapé™ç»´"""
    isomap = Isomap(
        n_components=st.session_state.reduction_isomap_components,
        n_neighbors=st.session_state.reduction_isomap_n_neighbors
    )
    X_reduced = isomap.fit_transform(X)
    return X_reduced, isomap


def create_reduction_results_section():
    """åˆ›å»ºç»“æœå±•ç¤ºéƒ¨åˆ†"""
    st.header("3. ç»“æœå±•ç¤º")

    results = st.session_state.get('reduction_results')

    if results is None:
        st.info("è¯·å…ˆè¿è¡Œé™ç»´ç®—æ³•ã€‚")
        return

    X_reduced = results['X_reduced']
    model = results['model']
    algorithm = results['algorithm']
    feature_names = results['feature_names']
    target = results.get('target')
    target_column = results.get('target_column')
    n_components = results['n_components']

    # æ˜¾ç¤ºé™ç»´æ‘˜è¦
    st.subheader("é™ç»´ç»“æœæ‘˜è¦")
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("åŸå§‹ç»´åº¦", len(feature_names))
    with col2:
        st.metric("é™ç»´åç»´åº¦", n_components)
    with col3:
        st.metric("é™ç»´ç®—æ³•", algorithm)

    # ç®—æ³•ç‰¹å®šçš„æŒ‡æ ‡
    if algorithm == "PCA":
        st.subheader("ä¸»æˆåˆ†åˆ†æç»“æœ")
        explained_variance_ratio = model.explained_variance_ratio_
        cumulative_variance = np.cumsum(explained_variance_ratio)

        # æ–¹å·®è§£é‡Šç‡å›¾è¡¨
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio,
               alpha=0.7, label='ä¸ªä½“è§£é‡Šæ–¹å·®')
        ax.plot(range(1, len(cumulative_variance) + 1), cumulative_variance,
                'ro-', label='ç´¯ç§¯è§£é‡Šæ–¹å·®')

        ax.set_xlabel('ä¸»æˆåˆ†')
        ax.set_ylabel('è§£é‡Šæ–¹å·®æ¯”ç‡')
        ax.set_title('ä¸»æˆåˆ†æ–¹å·®è§£é‡Šç‡')
        ax.legend()
        apply_plot_style(ax)

        if FONT_PROP:
            ax.set_xlabel('ä¸»æˆåˆ†', fontproperties=FONT_PROP)
            ax.set_ylabel('è§£é‡Šæ–¹å·®æ¯”ç‡', fontproperties=FONT_PROP)
            ax.set_title('ä¸»æˆåˆ†æ–¹å·®è§£é‡Šç‡', fontproperties=FONT_PROP)
            ax.legend(prop=FONT_PROP)

        st.pyplot(fig)
        plt.close()

        # æ˜¾ç¤ºå…·ä½“æ•°å€¼
        variance_df = pd.DataFrame({
            'ä¸»æˆåˆ†': [f'PC{i + 1}' for i in range(len(explained_variance_ratio))],
            'è§£é‡Šæ–¹å·®æ¯”ç‡': explained_variance_ratio,
            'ç´¯ç§¯è§£é‡Šæ–¹å·®': cumulative_variance
        })
        st.dataframe(variance_df.round(4))

    # é™ç»´ç»“æœå¯è§†åŒ–
    st.subheader("é™ç»´ç»“æœå¯è§†åŒ–")

    if n_components == 2:
        plot_2d_reduction(X_reduced, target, target_column, algorithm)
    elif n_components == 3:
        plot_3d_reduction(X_reduced, target, target_column, algorithm)
    else:
        st.info("å½“å‰åªæ”¯æŒ2Då’Œ3Då¯è§†åŒ–ã€‚")

    # é™ç»´æ•°æ®ä¸‹è½½
    st.subheader("æ•°æ®ä¸‹è½½")

    # åˆ›å»ºé™ç»´åçš„DataFrame
    component_names = [f'{algorithm}_Component_{i + 1}' for i in range(n_components)]
    reduced_df = pd.DataFrame(X_reduced, columns=component_names)

    # æ·»åŠ åŸå§‹æ•°æ®çš„éç‰¹å¾åˆ—
    original_data = st.session_state.reduction_data.reset_index(drop=True)
    for col in original_data.columns:
        if col not in feature_names:
            reduced_df[col] = original_data[col]

    # ä¸‹è½½æŒ‰é’®
    csv_link = get_download_link(
        reduced_df,
        f"dimensionality_reduction_{algorithm}_{datetime.datetime.now().strftime('%Y%m%d%H%M')}.csv",
        "ä¸‹è½½é™ç»´åæ•°æ® (CSV)"
    )
    st.markdown(csv_link, unsafe_allow_html=True)

    # æ˜¾ç¤ºé™ç»´åæ•°æ®é¢„è§ˆ
    st.subheader("é™ç»´åæ•°æ®é¢„è§ˆ")
    st.dataframe(reduced_df.head())


def plot_2d_reduction(X_reduced, target, target_column, algorithm):
    """ç»˜åˆ¶2Dé™ç»´ç»“æœ"""
    fig, ax = plt.subplots(figsize=(10, 8))

    if target is not None:
        # æœ‰ç›®æ ‡å˜é‡ï¼Œç”¨é¢œè‰²åŒºåˆ†
        scatter = ax.scatter(X_reduced[:, 0], X_reduced[:, 1], c=target, cmap='viridis', alpha=0.7)
        plt.colorbar(scatter, label=target_column or 'Target')
    else:
        # æ— ç›®æ ‡å˜é‡ï¼Œç»Ÿä¸€é¢œè‰²
        ax.scatter(X_reduced[:, 0], X_reduced[:, 1], alpha=0.7, color='#3498db')

    ax.set_xlabel(f'{algorithm} Component 1')
    ax.set_ylabel(f'{algorithm} Component 2')
    ax.set_title(f'{algorithm} é™ç»´ç»“æœ (2D)')

    apply_plot_style(ax)

    if FONT_PROP:
        ax.set_xlabel(f'{algorithm} æˆåˆ† 1', fontproperties=FONT_PROP)
        ax.set_ylabel(f'{algorithm} æˆåˆ† 2', fontproperties=FONT_PROP)
        ax.set_title(f'{algorithm} é™ç»´ç»“æœ (2D)', fontproperties=FONT_PROP)

    st.pyplot(fig)
    plt.close()


def plot_3d_reduction(X_reduced, target, target_column, algorithm):
    """ç»˜åˆ¶3Dé™ç»´ç»“æœ"""
    fig = plt.figure(figsize=(12, 10))
    ax = fig.add_subplot(111, projection='3d')

    if target is not None:
        # æœ‰ç›®æ ‡å˜é‡ï¼Œç”¨é¢œè‰²åŒºåˆ†
        scatter = ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2],
                             c=target, cmap='viridis', alpha=0.7)
        fig.colorbar(scatter, label=target_column or 'Target')
    else:
        # æ— ç›®æ ‡å˜é‡ï¼Œç»Ÿä¸€é¢œè‰²
        ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2],
                   alpha=0.7, color='#3498db')

    ax.set_xlabel(f'{algorithm} Component 1')
    ax.set_ylabel(f'{algorithm} Component 2')
    ax.set_zlabel(f'{algorithm} Component 3')
    ax.set_title(f'{algorithm} é™ç»´ç»“æœ (3D)')

    if FONT_PROP:
        ax.set_xlabel(f'{algorithm} æˆåˆ† 1', fontproperties=FONT_PROP)
        ax.set_ylabel(f'{algorithm} æˆåˆ† 2', fontproperties=FONT_PROP)
        ax.set_zlabel(f'{algorithm} æˆåˆ† 3', fontproperties=FONT_PROP)
        ax.set_title(f'{algorithm} é™ç»´ç»“æœ (3D)', fontproperties=FONT_PROP)

    st.pyplot(fig)
    plt.close()


def get_download_link(df, filename, text):
    """ç”ŸæˆCSVä¸‹è½½é“¾æ¥"""
    csv = df.to_csv(index=False, encoding='utf-8-sig')
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">{text}</a>'
    return href


# --- ä¸»å‡½æ•°å…¥å£ (ç”¨äºç‹¬ç«‹æµ‹è¯•) ---
if __name__ == "__main__":
    st.set_page_config(page_title="æ•°æ®é™ç»´", layout="wide")
    show_data_reduction_page()