# -*- coding: utf-8 -*-
"""
Feature Extraction Module for Streamlit App
Enhanced version with batch processing, feature selection, and data merging
"""
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import traceback
import io
import os
import glob
import pickle
import warnings
from datetime import datetime
from scipy.stats import skew, kurtosis, entropy
from scipy.signal import find_peaks, welch, butter, filtfilt
from scipy.fft import fft, fftfreq

# å±è”½è­¦å‘Š
warnings.filterwarnings('ignore')

# --- å°è¯•å¯¼å…¥å­—ä½“å·¥å…· ---
try:
    from font_utils import apply_plot_style, FONT_PROP, create_figure_with_safe_dimensions

    print("å­—ä½“å·¥å…·ä» font_utils æˆåŠŸåŠ è½½ (in feature_extraction)")
except ImportError:
    print("è­¦å‘Š: æ— æ³•ä» font_utils å¯¼å…¥ï¼Œå°†åœ¨ feature_extraction ä¸­ä½¿ç”¨å¤‡ç”¨ç»˜å›¾è®¾ç½®ã€‚")
    FONT_PROP = None


    def apply_plot_style(ax):
        ax.grid(True, linestyle='--', alpha=0.6)
        return ax


    def create_figure_with_safe_dimensions(w, h, dpi=80):
        fig, ax = plt.subplots(figsize=(w, h), dpi=dpi)
        return fig, ax

# --- å…¨å±€å‚æ•° ---
SAMPLE_RATE = 625
RANDOM_SEED = 42

# --- ç‰¹å¾å®šä¹‰ ---
FEATURE_DEFINITIONS = {
    "Basic Statistical Features": {
        "description": "åŸºç¡€ç»Ÿè®¡ç‰¹å¾æå–",
        "features": {
            "mean": "å‡å€¼ - æ•°æ®çš„å¹³å‡å€¼",
            "std": "æ ‡å‡†å·® - æ•°æ®çš„ç¦»æ•£ç¨‹åº¦",
            "min": "æœ€å°å€¼ - æ•°æ®çš„æœ€å°å€¼",
            "max": "æœ€å¤§å€¼ - æ•°æ®çš„æœ€å¤§å€¼",
            "median": "ä¸­ä½æ•° - æ•°æ®çš„ä¸­é—´å€¼",
            "q25": "ä¸‹å››åˆ†ä½æ•° - 25%åˆ†ä½ç‚¹",
            "q75": "ä¸Šå››åˆ†ä½æ•° - 75%åˆ†ä½ç‚¹",
            "skew": "ååº¦ - åˆ†å¸ƒçš„ä¸å¯¹ç§°æ€§",
            "kurtosis": "å³°åº¦ - åˆ†å¸ƒçš„å°–é”ç¨‹åº¦"
        }
    },
    "Advanced Statistical Features": {
        "description": "é«˜çº§ç»Ÿè®¡ç‰¹å¾æå–",
        "features": {
            "cv": "å˜å¼‚ç³»æ•° - æ ‡å‡†å·®ä¸å‡å€¼çš„æ¯”ç‡",
            "energy": "èƒ½é‡ - ä¿¡å·çš„æ€»èƒ½é‡",
            "entropy": "ç†µ - ä¿¡å·çš„å¤æ‚åº¦",
            "peak_to_peak": "å³°å³°å€¼ - æœ€å¤§å€¼ä¸æœ€å°å€¼ä¹‹å·®",
            "rms": "å‡æ–¹æ ¹ - æœ‰æ•ˆå€¼",
            "abs_mean": "ç»å¯¹å€¼å‡å€¼ - ç»å¯¹å€¼çš„å¹³å‡"
        }
    },
    "Time Domain Features": {
        "description": "æ—¶åŸŸç‰¹å¾æå–",
        "features": {
            "num_peaks": "å³°å€¼æ•°é‡ - å±€éƒ¨æœ€å¤§å€¼ä¸ªæ•°",
            "num_valleys": "è°·å€¼æ•°é‡ - å±€éƒ¨æœ€å°å€¼ä¸ªæ•°",
            "zero_crossing_rate": "è¿‡é›¶ç‡ - ä¿¡å·ç©¿è¶Šé›¶ç‚¹çš„é¢‘ç‡",
            "waveform_factor": "æ³¢å½¢å› å­ - æœ‰æ•ˆå€¼ä¸å¹³å‡å€¼ä¹‹æ¯”",
            "crest_factor": "å³°å€¼å› å­ - å³°å€¼ä¸æœ‰æ•ˆå€¼ä¹‹æ¯”",
            "impulse_factor": "è„‰å†²å› å­ - å³°å€¼ä¸å¹³å‡å€¼ä¹‹æ¯”"
        }
    },
    "Frequency Domain Features": {
        "description": "é¢‘åŸŸç‰¹å¾æå–",
        "features": {
            "main_freq": "ä¸»é¢‘ç‡ - æœ€å¼ºé¢‘ç‡æˆåˆ†",
            "main_freq_amp": "ä¸»é¢‘å¹…å€¼ - ä¸»é¢‘çš„æŒ¯å¹…",
            "spectral_centroid": "é¢‘è°±è´¨å¿ƒ - é¢‘è°±çš„é‡å¿ƒ",
            "spectral_energy": "é¢‘è°±èƒ½é‡ - é¢‘åŸŸæ€»èƒ½é‡",
            "spectral_entropy": "é¢‘è°±ç†µ - é¢‘è°±å¤æ‚åº¦"
        }
    },
    "Rolling Window Features": {
        "description": "æ»‘åŠ¨çª—å£ç‰¹å¾æå–",
        "features": {
            "rolling_mean_avg": "æ»‘åŠ¨å‡å€¼çš„å¹³å‡ - å±€éƒ¨å‡å€¼çš„æ•´ä½“å¹³å‡",
            "rolling_mean_std": "æ»‘åŠ¨å‡å€¼çš„æ ‡å‡†å·® - å±€éƒ¨å‡å€¼çš„å˜åŒ–ç¨‹åº¦",
            "rolling_std_avg": "æ»‘åŠ¨æ ‡å‡†å·®çš„å¹³å‡ - å±€éƒ¨å˜åŒ–çš„å¹³å‡ç¨‹åº¦",
            "rolling_std_std": "æ»‘åŠ¨æ ‡å‡†å·®çš„æ ‡å‡†å·® - å±€éƒ¨å˜åŒ–çš„ç¨³å®šæ€§",
            "rolling_min_avg": "æ»‘åŠ¨æœ€å°å€¼çš„å¹³å‡ - å±€éƒ¨æœ€å°å€¼çš„å¹³å‡",
            "rolling_max_avg": "æ»‘åŠ¨æœ€å¤§å€¼çš„å¹³å‡ - å±€éƒ¨æœ€å¤§å€¼çš„å¹³å‡",
            "rolling_range_avg": "æ»‘åŠ¨èŒƒå›´çš„å¹³å‡ - å±€éƒ¨æ³¢åŠ¨èŒƒå›´çš„å¹³å‡"
        }
    },
    "Enhanced Signal Features": {
        "description": "å¢å¼ºä¿¡å·ç‰¹å¾",
        "features": {
            "startup_max": "å¯åŠ¨å³°å€¼ - å¯åŠ¨é˜¶æ®µçš„æœ€å¤§å€¼",
            "startup_time": "å¯åŠ¨æ—¶é—´ - è¾¾åˆ°å³°å€¼çš„æ—¶é—´",
            "steady_mean": "ç¨³æ€å‡å€¼ - ç¨³å®šé˜¶æ®µçš„å¹³å‡å€¼",
            "steady_std": "ç¨³æ€æ ‡å‡†å·® - ç¨³å®šé˜¶æ®µçš„æ³¢åŠ¨",
            "autocorr_lag10": "è‡ªç›¸å…³ç³»æ•° - 10ä¸ªå»¶è¿Ÿçš„ç›¸å…³æ€§"
        }
    }
}

# --- ç‰¹å¾æå–æ–¹æ³•ä¼˜ç¼ºç‚¹ ---
FEATURE_METHODS_INFO = {
    "Basic Statistical Features": {
        "pros": [
            "âœ… è®¡ç®—é€Ÿåº¦å¿«ï¼Œæ•ˆç‡é«˜",
            "âœ… é€šç”¨æ€§å¼ºï¼Œé€‚ç”¨äºæ‰€æœ‰æ•°å€¼æ•°æ®",
            "âœ… ç»“æœç¨³å®šï¼Œå¯è§£é‡Šæ€§å¼º"
        ],
        "cons": [
            "âŒ å¯èƒ½å¿½ç•¥æ—¶åºä¿¡æ¯",
            "âŒ æ— æ³•æ•æ‰å¤æ‚çš„æ¨¡å¼"
        ],
        "suitable_for": "é€‚ç”¨äºå¿«é€Ÿæ•°æ®æ¢ç´¢ã€åŸºç¡€åˆ†æ"
    },
    "Advanced Statistical Features": {
        "pros": [
            "âœ… åŒ…å«æ›´å¤šç»Ÿè®¡ä¿¡æ¯",
            "âœ… èƒ½æ•æ‰æ•°æ®åˆ†å¸ƒç‰¹æ€§"
        ],
        "cons": [
            "âŒ è®¡ç®—å¤æ‚åº¦å¢åŠ ",
            "âŒ æŸäº›ç‰¹å¾å¯èƒ½å­˜åœ¨ç›¸å…³æ€§"
        ],
        "suitable_for": "é€‚ç”¨äºåˆ†å¸ƒåˆ†æã€å¼‚å¸¸æ£€æµ‹"
    },
    "Time Domain Features": {
        "pros": [
            "âœ… ä¿ç•™æ—¶åºä¿¡æ¯",
            "âœ… èƒ½è¯†åˆ«è¶‹åŠ¿å’Œæ¨¡å¼"
        ],
        "cons": [
            "âŒ éœ€è¦æ—¶åºæ•°æ®",
            "âŒ å¯¹é‡‡æ ·ç‡æ•æ„Ÿ"
        ],
        "suitable_for": "é€‚ç”¨äºæ—¶é—´åºåˆ—ã€ä¿¡å·å¤„ç†"
    },
    "Frequency Domain Features": {
        "pros": [
            "âœ… æ­ç¤ºå‘¨æœŸæ€§æ¨¡å¼",
            "âœ… é€‚åˆæŒ¯åŠ¨ä¿¡å·åˆ†æ"
        ],
        "cons": [
            "âŒ éœ€è¦è¶³å¤Ÿçš„æ•°æ®é•¿åº¦",
            "âŒ ä¸¢å¤±æ—¶é—´ä¿¡æ¯"
        ],
        "suitable_for": "é€‚ç”¨äºæŒ¯åŠ¨åˆ†æã€æ•…éšœè¯Šæ–­"
    },
    "Rolling Window Features": {
        "pros": [
            "âœ… æ•æ‰å±€éƒ¨å˜åŒ–",
            "âœ… é€‚åˆéå¹³ç¨³ä¿¡å·"
        ],
        "cons": [
            "âŒ çª—å£å¤§å°é€‰æ‹©æ•æ„Ÿ",
            "âŒ ç‰¹å¾æ•°é‡å¤š"
        ],
        "suitable_for": "é€‚ç”¨äºå˜åŒ–ä¿¡å·ã€è¶‹åŠ¿æ£€æµ‹"
    },
    "Enhanced Signal Features": {
        "pros": [
            "âœ… ç»¼åˆæ—¶é¢‘åŸŸä¿¡æ¯",
            "âœ… ç‰©ç†æ„ä¹‰æ˜ç¡®"
        ],
        "cons": [
            "âŒ è®¡ç®—å¤æ‚åº¦é«˜",
            "âŒ éœ€è¦é¢„å®šä¹‰å‚æ•°"
        ],
        "suitable_for": "é€‚ç”¨äºç”µæœºä¿¡å·ã€è®¾å¤‡ç›‘æ§"
    }
}


# --- çŠ¶æ€åˆå§‹åŒ– ---
def initialize_feature_extraction_state():
    """Initialize session state variables specific to feature extraction."""
    defaults = {
        'fe_uploaded_data': None,
        'fe_batch_data': {},  # å­˜å‚¨æ‰¹é‡æ•°æ®
        'fe_active_data': None,
        'fe_active_data_source': None,
        'fe_selected_columns': [],
        'fe_selected_methods': [],
        'fe_selected_features': {},  # å­˜å‚¨æ¯ä¸ªæ–¹æ³•é€‰ä¸­çš„ç‰¹å¾
        'fe_extracted_features': None,
        'fe_extraction_params': {},
        'fe_original_data': None,  # å­˜å‚¨åŸå§‹æ•°æ®ç”¨äºåˆå¹¶
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


# --- ç‰¹å¾æå–å‡½æ•°ï¼ˆå¯é€‰ç‰¹å¾ç‰ˆæœ¬ï¼‰---
def extract_basic_statistical_features(data, columns, selected_features=None):
    """æå–åŸºç¡€ç»Ÿè®¡ç‰¹å¾ï¼ˆå¯é€‰ç‰¹å¾ï¼‰"""
    if selected_features is None:
        selected_features = list(FEATURE_DEFINITIONS["Basic Statistical Features"]["features"].keys())

    features = []
    feature_names = []

    for col in columns:
        col_data = data[col].dropna()
        if len(col_data) > 0:
            col_features = {}

            if "mean" in selected_features:
                col_features[f'{col}_mean'] = col_data.mean()
            if "std" in selected_features:
                col_features[f'{col}_std'] = col_data.std()
            if "min" in selected_features:
                col_features[f'{col}_min'] = col_data.min()
            if "max" in selected_features:
                col_features[f'{col}_max'] = col_data.max()
            if "median" in selected_features:
                col_features[f'{col}_median'] = col_data.median()
            if "q25" in selected_features:
                col_features[f'{col}_q25'] = col_data.quantile(0.25)
            if "q75" in selected_features:
                col_features[f'{col}_q75'] = col_data.quantile(0.75)
            if "skew" in selected_features:
                col_features[f'{col}_skew'] = skew(col_data)
            if "kurtosis" in selected_features:
                col_features[f'{col}_kurtosis'] = kurtosis(col_data)

            features.append(col_features)

    # åˆå¹¶æ‰€æœ‰ç‰¹å¾
    if features:
        combined_features = {}
        for feature_dict in features:
            combined_features.update(feature_dict)
        return pd.DataFrame([combined_features])
    else:
        return pd.DataFrame()


def extract_advanced_statistical_features(data, columns, selected_features=None):
    """æå–é«˜çº§ç»Ÿè®¡ç‰¹å¾ï¼ˆå¯é€‰ç‰¹å¾ï¼‰"""
    if selected_features is None:
        selected_features = list(FEATURE_DEFINITIONS["Advanced Statistical Features"]["features"].keys())

    features = []

    for col in columns:
        col_data = data[col].dropna()
        if len(col_data) > 0:
            col_features = {}
            mean_val = col_data.mean()
            std_val = col_data.std()

            if "cv" in selected_features:
                col_features[f'{col}_cv'] = std_val / (mean_val + 1e-10)
            if "energy" in selected_features:
                col_features[f'{col}_energy'] = np.sum(col_data ** 2)
            if "entropy" in selected_features:
                hist, _ = np.histogram(col_data, bins=10)
                hist = hist / hist.sum()
                col_features[f'{col}_entropy'] = entropy(hist + 1e-10)
            if "peak_to_peak" in selected_features:
                col_features[f'{col}_peak_to_peak'] = col_data.max() - col_data.min()
            if "rms" in selected_features:
                col_features[f'{col}_rms'] = np.sqrt(np.mean(col_data ** 2))
            if "abs_mean" in selected_features:
                col_features[f'{col}_abs_mean'] = np.mean(np.abs(col_data))

            features.append(col_features)

    if features:
        combined_features = {}
        for feature_dict in features:
            combined_features.update(feature_dict)
        return pd.DataFrame([combined_features])
    else:
        return pd.DataFrame()


def extract_time_domain_features(data, columns, sample_rate=625, selected_features=None):
    """æå–æ—¶åŸŸç‰¹å¾ï¼ˆå¯é€‰ç‰¹å¾ï¼‰"""
    if selected_features is None:
        selected_features = list(FEATURE_DEFINITIONS["Time Domain Features"]["features"].keys())

    features = []

    for col in columns:
        col_data = data[col].dropna().values
        if len(col_data) > 10:
            col_features = {}

            if "num_peaks" in selected_features or "num_valleys" in selected_features:
                peaks, _ = find_peaks(col_data, distance=sample_rate // 10)
                valleys, _ = find_peaks(-col_data, distance=sample_rate // 10)

                if "num_peaks" in selected_features:
                    col_features[f'{col}_num_peaks'] = len(peaks)
                if "num_valleys" in selected_features:
                    col_features[f'{col}_num_valleys'] = len(valleys)

            if "zero_crossing_rate" in selected_features:
                zero_crossings = np.sum(np.diff(np.sign(col_data)) != 0)
                col_features[f'{col}_zero_crossing_rate'] = zero_crossings / len(col_data)

            if "waveform_factor" in selected_features:
                col_features[f'{col}_waveform_factor'] = np.sqrt(np.mean(col_data ** 2)) / (
                            np.mean(np.abs(col_data)) + 1e-10)

            if "crest_factor" in selected_features:
                col_features[f'{col}_crest_factor'] = np.max(np.abs(col_data)) / (
                            np.sqrt(np.mean(col_data ** 2)) + 1e-10)

            if "impulse_factor" in selected_features:
                col_features[f'{col}_impulse_factor'] = np.max(np.abs(col_data)) / (np.mean(np.abs(col_data)) + 1e-10)

            features.append(col_features)

    if features:
        combined_features = {}
        for feature_dict in features:
            combined_features.update(feature_dict)
        return pd.DataFrame([combined_features])
    else:
        return pd.DataFrame()


def extract_frequency_domain_features(data, columns, sample_rate=625, selected_features=None):
    """æå–é¢‘åŸŸç‰¹å¾ï¼ˆå¯é€‰ç‰¹å¾ï¼‰"""
    if selected_features is None:
        selected_features = list(FEATURE_DEFINITIONS["Frequency Domain Features"]["features"].keys())

    features = []

    for col in columns:
        col_data = data[col].dropna().values
        if len(col_data) > 10:
            col_features = {}

            # FFT
            fft_vals = np.abs(fft(col_data))
            freqs = fftfreq(len(col_data), 1 / sample_rate)

            # åªå–æ­£é¢‘ç‡éƒ¨åˆ†
            positive_freq_idx = freqs > 0
            fft_vals = fft_vals[positive_freq_idx]
            freqs = freqs[positive_freq_idx]

            if len(fft_vals) > 0:
                if "main_freq" in selected_features or "main_freq_amp" in selected_features:
                    main_freq_idx = np.argmax(fft_vals)
                    if "main_freq" in selected_features:
                        col_features[f'{col}_main_freq'] = freqs[main_freq_idx]
                    if "main_freq_amp" in selected_features:
                        col_features[f'{col}_main_freq_amp'] = fft_vals[main_freq_idx]

                if "spectral_centroid" in selected_features:
                    col_features[f'{col}_spectral_centroid'] = np.sum(freqs * fft_vals) / (np.sum(fft_vals) + 1e-10)

                if "spectral_energy" in selected_features:
                    col_features[f'{col}_spectral_energy'] = np.sum(fft_vals ** 2)

                if "spectral_entropy" in selected_features:
                    normalized_fft = fft_vals / (np.sum(fft_vals) + 1e-10)
                    col_features[f'{col}_spectral_entropy'] = entropy(normalized_fft + 1e-10)

            features.append(col_features)

    if features:
        combined_features = {}
        for feature_dict in features:
            combined_features.update(feature_dict)
        return pd.DataFrame([combined_features])
    else:
        return pd.DataFrame()


def extract_rolling_window_features(data, columns, window_size=20, selected_features=None):
    """æå–æ»‘åŠ¨çª—å£ç‰¹å¾ï¼ˆå¯é€‰ç‰¹å¾ï¼‰"""
    if selected_features is None:
        selected_features = list(FEATURE_DEFINITIONS["Rolling Window Features"]["features"].keys())

    features = []

    for col in columns:
        col_data = data[col].dropna()
        if len(col_data) > window_size:
            col_features = {}

            rolling_mean = col_data.rolling(window=window_size).mean().dropna()
            rolling_std = col_data.rolling(window=window_size).std().dropna()
            rolling_min = col_data.rolling(window=window_size).min().dropna()
            rolling_max = col_data.rolling(window=window_size).max().dropna()

            if len(rolling_mean) > 0:
                if "rolling_mean_avg" in selected_features:
                    col_features[f'{col}_rolling_mean_avg'] = rolling_mean.mean()
                if "rolling_mean_std" in selected_features:
                    col_features[f'{col}_rolling_mean_std'] = rolling_mean.std()
                if "rolling_std_avg" in selected_features:
                    col_features[f'{col}_rolling_std_avg'] = rolling_std.mean()
                if "rolling_std_std" in selected_features:
                    col_features[f'{col}_rolling_std_std'] = rolling_std.std()
                if "rolling_min_avg" in selected_features:
                    col_features[f'{col}_rolling_min_avg'] = rolling_min.mean()
                if "rolling_max_avg" in selected_features:
                    col_features[f'{col}_rolling_max_avg'] = rolling_max.mean()
                if "rolling_range_avg" in selected_features:
                    col_features[f'{col}_rolling_range_avg'] = (rolling_max - rolling_min).mean()

            features.append(col_features)

    if features:
        combined_features = {}
        for feature_dict in features:
            combined_features.update(feature_dict)
        return pd.DataFrame([combined_features])
    else:
        return pd.DataFrame()


def extract_enhanced_signal_features(data, columns, sample_rate=625, selected_features=None):
    """æå–å¢å¼ºä¿¡å·ç‰¹å¾ï¼ˆå¯é€‰ç‰¹å¾ï¼‰"""
    if selected_features is None:
        selected_features = list(FEATURE_DEFINITIONS["Enhanced Signal Features"]["features"].keys())

    features = []

    for col in columns:
        col_data = data[col].dropna().values
        if len(col_data) > 100:
            col_features = {}

            # å¯åŠ¨æ£€æµ‹ï¼ˆå‰20%æ•°æ®ï¼‰
            startup_samples = min(int(0.2 * len(col_data)), len(col_data))
            startup_data = col_data[:startup_samples]
            steady_data = col_data[startup_samples:]

            if "startup_max" in selected_features:
                col_features[f'{col}_startup_max'] = np.max(np.abs(startup_data))

            if "startup_time" in selected_features:
                col_features[f'{col}_startup_time'] = np.argmax(np.abs(startup_data)) / sample_rate

            if "steady_mean" in selected_features:
                col_features[f'{col}_steady_mean'] = np.mean(steady_data)

            if "steady_std" in selected_features:
                col_features[f'{col}_steady_std'] = np.std(steady_data)

            if "autocorr_lag10" in selected_features:
                if len(steady_data) > 20:
                    autocorr = np.correlate(steady_data, steady_data, mode='same')
                    autocorr = autocorr[len(autocorr) // 2:]
                    autocorr = autocorr / (autocorr[0] + 1e-10)
                    col_features[f'{col}_autocorr_lag10'] = autocorr[min(10, len(autocorr) - 1)]
                else:
                    col_features[f'{col}_autocorr_lag10'] = 0

            features.append(col_features)

    if features:
        combined_features = {}
        for feature_dict in features:
            combined_features.update(feature_dict)
        return pd.DataFrame([combined_features])
    else:
        return pd.DataFrame()


# --- æ‰¹é‡å¤„ç†å‡½æ•° ---
def load_folder_data(folder_path, file_pattern="*.xlsx"):
    """åŠ è½½æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰Excelæ–‡ä»¶"""
    all_data = {}
    file_paths = glob.glob(os.path.join(folder_path, file_pattern))

    if not file_paths:
        file_paths = glob.glob(os.path.join(folder_path, "*.xls"))

    for file_path in file_paths:
        try:
            filename = os.path.basename(file_path)
            df = pd.read_excel(file_path)
            all_data[filename] = df
        except Exception as e:
            st.warning(f"æ— æ³•è¯»å–æ–‡ä»¶ {filename}: {e}")

    return all_data


# --- ä¸»é¡µé¢å‡½æ•° ---
def show_feature_extraction_page():
    """æ˜¾ç¤ºç‰¹å¾æå–é¡µé¢çš„ä¸»å‡½æ•° - ä¼˜åŒ–ç‰ˆ"""
    # åˆå§‹åŒ–çŠ¶æ€
    initialize_feature_extraction_state()

    # ä½¿ç”¨ç¼“å­˜è£…é¥°å™¨ä¼˜åŒ–æ•°æ®åŠ è½½
    @st.cache_data
    def load_data_cached(file_path):
        """ç¼“å­˜æ–‡ä»¶åŠ è½½"""
        if file_path.endswith('.csv'):
            return pd.read_csv(file_path)
        else:
            return pd.read_excel(file_path)

    # é¡µé¢æ ‡é¢˜
    st.title("ğŸ” é«˜çº§ç‰¹å¾æå–")
    st.markdown("---")

    # é¡µé¢è¯´æ˜
    with st.expander("â„¹ï¸ åŠŸèƒ½è¯´æ˜", expanded=False):
        st.markdown("""
        **é«˜çº§ç‰¹å¾æå–æ¨¡å—**æ”¯æŒï¼š

        ğŸ¯ **æ ¸å¿ƒåŠŸèƒ½**:
        - æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰Excelæ–‡ä»¶
        - è‡ªå®šä¹‰é€‰æ‹©æ¯ä¸ªæ–¹æ³•ä¸­çš„å…·ä½“ç‰¹å¾
        - æ”¯æŒä¸åŸå§‹æ•°æ®åˆå¹¶å¯¼å‡º
        - å¤šç§ç‰¹å¾æå–æ–¹æ³•ç»„åˆä½¿ç”¨
        """)

    # ä¸»è¦å†…å®¹åŒºåŸŸ
    col1, col2 = st.columns([1, 2])

    with col1:
        st.subheader("ğŸ›ï¸ æ§åˆ¶é¢æ¿")

        # æ•°æ®ä¸Šä¼ éƒ¨åˆ†ä½¿ç”¨formå‡å°‘åˆ·æ–°
        with st.container():
            st.markdown("### ğŸ“ æ•°æ®æº")

            data_source = st.radio(
                "é€‰æ‹©æ•°æ®æº:",
                ["ä¸Šä¼ å•ä¸ªæ–‡ä»¶", "æ‰¹é‡å¯¼å…¥æ–‡ä»¶å¤¹", "ä½¿ç”¨ç¤ºä¾‹æ•°æ®"],
                key="fe_data_source",
                label_visibility="collapsed"
            )

            if data_source == "ä¸Šä¼ å•ä¸ªæ–‡ä»¶":
                uploaded_file = st.file_uploader(
                    "ä¸Šä¼ æ•°æ®æ–‡ä»¶",
                    type=['csv', 'xlsx', 'xls'],
                    help="æ”¯æŒCSVå’ŒExcelæ ¼å¼æ–‡ä»¶",
                    key="fe_file_uploader"
                )

                if uploaded_file is not None:
                    # ä½¿ç”¨å”¯ä¸€é”®é¿å…é‡å¤å¤„ç†
                    file_key = f"{uploaded_file.name}_{uploaded_file.size}"
                    if 'last_processed_file' not in st.session_state or st.session_state.last_processed_file != file_key:
                        try:
                            if uploaded_file.name.endswith('.csv'):
                                df = pd.read_csv(uploaded_file)
                            else:
                                df = pd.read_excel(uploaded_file)

                            st.session_state.fe_active_data = df
                            st.session_state.fe_original_data = df.copy()
                            st.session_state.last_processed_file = file_key
                            st.success(f"âœ… æˆåŠŸåŠ è½½: {df.shape}")
                        except Exception as e:
                            st.error(f"æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")

            elif data_source == "æ‰¹é‡å¯¼å…¥æ–‡ä»¶å¤¹":
                with st.form("batch_import_form"):
                    st.markdown("#### ğŸ“‚ æ‰¹é‡å¯¼å…¥è®¾ç½®")

                    folder_path = st.text_input(
                        "è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„:",
                        placeholder="ä¾‹å¦‚: C:/Users/data/excel_files",
                        help="è¾“å…¥åŒ…å«Excelæ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„"
                    )

                    file_pattern = st.selectbox(
                        "æ–‡ä»¶ç±»å‹:",
                        ["*.xlsx", "*.xls", "*.csv", "*.*"],
                        help="é€‰æ‹©è¦å¯¼å…¥çš„æ–‡ä»¶ç±»å‹"
                    )

                    submitted = st.form_submit_button("ğŸ”„ æ‰«ææ–‡ä»¶å¤¹")

                    if submitted and folder_path and os.path.exists(folder_path):
                        with st.spinner("æ­£åœ¨åŠ è½½æ–‡ä»¶..."):
                            batch_data = load_folder_data(folder_path, file_pattern)
                            if batch_data:
                                st.session_state.fe_batch_data = batch_data
                                st.success(f"âœ… æˆåŠŸåŠ è½½ {len(batch_data)} ä¸ªæ–‡ä»¶")

            elif data_source == "ä½¿ç”¨ç¤ºä¾‹æ•°æ®":
                if st.button("ç”Ÿæˆç¤ºä¾‹æ•°æ®", key="gen_sample_data"):
                    np.random.seed(42)
                    n_samples = 1000
                    time = np.linspace(0, 10, n_samples)

                    df = pd.DataFrame({
                        'Time': time,
                        'Signal_1': np.sin(2 * np.pi * time) + np.random.randn(n_samples) * 0.1,
                        'Signal_2': np.cos(2 * np.pi * time * 0.5) + np.random.randn(n_samples) * 0.1,
                        'Signal_3': np.sin(2 * np.pi * time * 2) * np.exp(-time / 5) + np.random.randn(
                            n_samples) * 0.05,
                        'Voltage': 220 + 5 * np.sin(2 * np.pi * time * 0.1) + np.random.randn(n_samples),
                        'Current': 10 * (1 - np.exp(-time / 2)) + np.random.randn(n_samples) * 0.5
                    })

                    st.session_state.fe_active_data = df
                    st.session_state.fe_original_data = df.copy()
                    st.success("âœ… ç¤ºä¾‹æ•°æ®å·²ç”Ÿæˆ")

    with col2:
        st.subheader("ğŸ“Š ç‰¹å¾æå–è®¾ç½®")

        if st.session_state.fe_active_data is not None:
            data = st.session_state.fe_active_data

            # æ•°æ®é¢„è§ˆ
            with st.expander("æ•°æ®é¢„è§ˆ", expanded=False):
                st.dataframe(data.head())

                col1_info, col2_info, col3_info = st.columns(3)
                with col1_info:
                    st.metric("æ•°æ®è¡Œæ•°", len(data))
                with col2_info:
                    st.metric("æ•°æ®åˆ—æ•°", len(data.columns))
                with col3_info:
                    numeric_cols = data.select_dtypes(include=[np.number]).columns
                    st.metric("æ•°å€¼åˆ—æ•°", len(numeric_cols))

            # åˆ—é€‰æ‹© - ä½¿ç”¨formé¿å…åˆ·æ–°
            st.markdown("### ğŸ¯ é€‰æ‹©è¦å¤„ç†çš„åˆ—")
            numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()

            if numeric_columns:
                with st.form("column_selection_form"):
                    quick_select = st.radio(
                        "å¿«é€Ÿé€‰æ‹©:",
                        ["è‡ªå®šä¹‰é€‰æ‹©", "é€‰æ‹©å…¨éƒ¨æ•°å€¼åˆ—", "é€‰æ‹©å‰5åˆ—"],
                        horizontal=True
                    )

                    if quick_select == "é€‰æ‹©å…¨éƒ¨æ•°å€¼åˆ—":
                        selected_columns = numeric_columns
                    elif quick_select == "é€‰æ‹©å‰5åˆ—":
                        selected_columns = numeric_columns[:min(5, len(numeric_columns))]
                    else:
                        default_cols = st.session_state.fe_selected_columns if st.session_state.fe_selected_columns else numeric_columns[
                                                                                                                         :min(
                                                                                                                             3,
                                                                                                                             len(numeric_columns))]
                        selected_columns = st.multiselect(
                            "é€‰æ‹©åˆ—:",
                            numeric_columns,
                            default=default_cols
                        )

                    submitted_cols = st.form_submit_button("ç¡®è®¤åˆ—é€‰æ‹©")
                    if submitted_cols:
                        st.session_state.fe_selected_columns = selected_columns
                        if selected_columns:
                            st.success(f"âœ… å·²é€‰æ‹© {len(selected_columns)} åˆ—")
                        else:
                            st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€åˆ—ï¼")
            else:
                st.error("æ•°æ®ä¸­æ²¡æœ‰æ•°å€¼åˆ—ï¼")
                selected_columns = []

    # ç‰¹å¾æå–æ–¹æ³•å’Œç‰¹å¾é€‰æ‹©
    if st.session_state.fe_active_data is not None and st.session_state.fe_selected_columns:
        st.markdown("---")
        st.subheader("ğŸ”§ ç‰¹å¾æå–æ–¹æ³•å’Œç‰¹å¾é€‰æ‹©")

        # ä½¿ç”¨å•ä¸ªå¤§formå¤„ç†æ‰€æœ‰é€‰æ‹©
        with st.form("feature_extraction_form", clear_on_submit=False):
            # æ–¹æ³•é€‰æ‹©
            st.markdown("### é€‰æ‹©ç‰¹å¾æå–æ–¹æ³•")
            selected_methods = st.multiselect(
                "é€‰æ‹©ç‰¹å¾æå–æ–¹æ³•:",
                list(FEATURE_METHODS_INFO.keys()),
                default=st.session_state.fe_selected_methods if st.session_state.fe_selected_methods else [
                    "Basic Statistical Features"],
                help="å¯ä»¥é€‰æ‹©å¤šä¸ªæ–¹æ³•ç»„åˆä½¿ç”¨"
            )

            st.markdown("---")
            st.markdown("### ğŸ“‹ é€‰æ‹©å…·ä½“ç‰¹å¾")

            # å­˜å‚¨æ¯ä¸ªæ–¹æ³•çš„é€‰æ‹©
            feature_selections = {}

            if selected_methods:
                # ä¸ºæ¯ä¸ªæ–¹æ³•åˆ›å»ºç‰¹å¾é€‰æ‹©
                for method in selected_methods:
                    st.markdown(f"#### ğŸ”¸ {method}")

                    # æ˜¾ç¤ºæ–¹æ³•è¯´æ˜
                    method_info = FEATURE_METHODS_INFO[method]
                    col_desc, col_suit = st.columns(2)
                    with col_desc:
                        st.info(f"**{FEATURE_DEFINITIONS[method]['description']}**")
                    with col_suit:
                        st.success(f"*{method_info['suitable_for']}*")

                    # è·å–ç‰¹å¾åˆ—è¡¨
                    available_features = list(FEATURE_DEFINITIONS[method]["features"].keys())
                    feature_descriptions = FEATURE_DEFINITIONS[method]["features"]

                    # è·å–é»˜è®¤é€‰æ‹©
                    default_features = st.session_state.get(
                        f"confirmed_features_{method}",
                        available_features  # é»˜è®¤å…¨é€‰
                    )

                    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€æ˜¾ç¤ºç‰¹å¾é€‰é¡¹
                    col_left, col_right = st.columns(2)

                    selected_features = []
                    for idx, (feat_key, feat_desc) in enumerate(feature_descriptions.items()):
                        # äº¤æ›¿ä½¿ç”¨å·¦å³åˆ—
                        with col_left if idx % 2 == 0 else col_right:
                            is_selected = st.checkbox(
                                f"{feat_key}",
                                value=feat_key in default_features,
                                key=f"feat_{method}_{feat_key}",
                                help=feat_desc
                            )
                            if is_selected:
                                selected_features.append(feat_key)

                    feature_selections[method] = selected_features

                    # æ˜¾ç¤ºç»Ÿè®¡
                    st.markdown(f"âœ… å·²é€‰æ‹© **{len(selected_features)}/{len(available_features)}** ä¸ªç‰¹å¾")
                    st.markdown("---")

                # å‚æ•°è®¾ç½®éƒ¨åˆ†
                st.markdown("### âš™ï¸ å‚æ•°è®¾ç½®")
                params = {}

                for method in selected_methods:
                    if method in ["Rolling Window Features"]:
                        params[method] = {
                            'window_size': st.slider(
                                f"{method} - çª—å£å¤§å°",
                                min_value=5,
                                max_value=100,
                                value=20,
                                key=f"param_window_{method}"
                            )
                        }
                    elif method in ["Time Domain Features", "Frequency Domain Features", "Enhanced Signal Features"]:
                        params[method] = {
                            'sample_rate': st.number_input(
                                f"{method} - é‡‡æ ·ç‡ (Hz)",
                                min_value=1,
                                max_value=10000,
                                value=625,
                                key=f"param_rate_{method}"
                            )
                        }

            # æäº¤æŒ‰é’®
            col_submit1, col_submit2 = st.columns([3, 1])
            with col_submit1:
                submitted = st.form_submit_button(
                    "ğŸš€ ç¡®è®¤è®¾ç½®å¹¶å¼€å§‹ç‰¹å¾æå–",
                    type="primary",
                    use_container_width=True
                )
            with col_submit2:
                # æ˜¾ç¤ºæ€»ç‰¹å¾æ•°é¢„ä¼°
                if selected_methods and feature_selections:
                    total_features = sum(len(features) for features in feature_selections.values())
                    st.metric("é¢„è®¡ç‰¹å¾æ•°", total_features * len(st.session_state.fe_selected_columns))

            # å¤„ç†æäº¤
            if submitted:
                # éªŒè¯æ˜¯å¦æœ‰é€‰æ‹©
                if not selected_methods:
                    st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾æå–æ–¹æ³•ï¼")
                elif all(len(features) == 0 for features in feature_selections.values()):
                    st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾ï¼")
                else:
                    # ä¿å­˜é€‰æ‹©
                    st.session_state.fe_selected_methods = selected_methods
                    st.session_state.fe_extraction_params = params

                    for method, features in feature_selections.items():
                        st.session_state[f"confirmed_features_{method}"] = features

                    st.session_state.fe_selected_features = feature_selections

                    # æ‰§è¡Œç‰¹å¾æå–
                    with st.spinner("æ­£åœ¨æå–ç‰¹å¾..."):
                        try:
                            all_features = []
                            feature_summary = []

                            progress_bar = st.progress(0)
                            status_text = st.empty()

                            for idx, method in enumerate(selected_methods):
                                status_text.text(f"æ­£åœ¨å¤„ç†: {method}")

                                method_features = None
                                method_selected_features = feature_selections[method]

                                if not method_selected_features:
                                    continue

                                # æ ¹æ®æ–¹æ³•è°ƒç”¨ç›¸åº”çš„ç‰¹å¾æå–å‡½æ•°
                                data = st.session_state.fe_active_data
                                selected_columns = st.session_state.fe_selected_columns

                                if method == "Basic Statistical Features":
                                    method_features = extract_basic_statistical_features(
                                        data, selected_columns, method_selected_features
                                    )
                                elif method == "Advanced Statistical Features":
                                    method_features = extract_advanced_statistical_features(
                                        data, selected_columns, method_selected_features
                                    )
                                elif method == "Time Domain Features":
                                    sample_rate = params.get(method, {}).get('sample_rate', 625)
                                    method_features = extract_time_domain_features(
                                        data, selected_columns, sample_rate, method_selected_features
                                    )
                                elif method == "Frequency Domain Features":
                                    sample_rate = params.get(method, {}).get('sample_rate', 625)
                                    method_features = extract_frequency_domain_features(
                                        data, selected_columns, sample_rate, method_selected_features
                                    )
                                elif method == "Rolling Window Features":
                                    window_size = params.get(method, {}).get('window_size', 20)
                                    method_features = extract_rolling_window_features(
                                        data, selected_columns, window_size, method_selected_features
                                    )
                                elif method == "Enhanced Signal Features":
                                    sample_rate = params.get(method, {}).get('sample_rate', 625)
                                    method_features = extract_enhanced_signal_features(
                                        data, selected_columns, sample_rate, method_selected_features
                                    )

                                if method_features is not None and not method_features.empty:
                                    all_features.append(method_features)
                                    feature_summary.append({
                                        'Method': method,
                                        'Features': len(method_features.columns),
                                        'Selected Features': len(method_selected_features),
                                        'Columns': len(selected_columns)
                                    })

                                progress_bar.progress((idx + 1) / len(selected_methods))

                            status_text.empty()

                            # åˆå¹¶æ‰€æœ‰ç‰¹å¾
                            if all_features:
                                combined_features = pd.concat(all_features, axis=1)
                                st.session_state.fe_extracted_features = combined_features
                                st.session_state.fe_extraction_success = True  # æ·»åŠ æˆåŠŸæ ‡å¿—

                                st.success(f"âœ… ç‰¹å¾æå–å®Œæˆï¼å…±æå– {len(combined_features.columns)} ä¸ªç‰¹å¾")

                                # æ˜¾ç¤ºç‰¹å¾æ±‡æ€»
                                st.markdown("### ğŸ“Š ç‰¹å¾æå–æ±‡æ€»")
                                summary_df = pd.DataFrame(feature_summary)
                                st.dataframe(summary_df, use_container_width=True)

                                # æ˜¾ç¤ºç‰¹å¾ç»“æœ
                                with st.expander("æŸ¥çœ‹æå–çš„ç‰¹å¾", expanded=True):
                                    # é™åˆ¶æ˜¾ç¤ºè¡Œæ•°ä»¥æé«˜æ€§èƒ½
                                    st.dataframe(combined_features.head(100))
                                    if len(combined_features) > 100:
                                        st.info(f"æ˜¾ç¤ºå‰100è¡Œï¼Œå…±{len(combined_features)}è¡Œ")
                            else:
                                st.warning("æ²¡æœ‰æˆåŠŸæå–ä»»ä½•ç‰¹å¾")
                                st.session_state.fe_extraction_success = False

                        except Exception as e:
                            st.error(f"ç‰¹å¾æå–å¤±è´¥: {e}")
                            st.code(traceback.format_exc())
                            st.session_state.fe_extraction_success = False

    # å¯¼å‡ºåŠŸèƒ½ - ç§»åˆ°formå¤–éƒ¨
    if st.session_state.get('fe_extracted_features') is not None:
        st.markdown("---")
        st.subheader("ğŸ’¾ å¯¼å‡ºç‰¹å¾")
        export_features_enhanced(st.session_state.fe_extracted_features)

    # æ‰¹é‡å¤„ç†å¯¼å‡º - ä¹Ÿç§»åˆ°formå¤–éƒ¨
    if st.session_state.fe_batch_data and st.session_state.get('fe_selected_methods'):
        st.markdown("---")
        st.subheader("ğŸ”„ æ‰¹é‡å¤„ç†")

        col1_batch, col2_batch = st.columns([2, 1])
        with col1_batch:
            st.info(f"æ£€æµ‹åˆ° {len(st.session_state.fe_batch_data)} ä¸ªæ‰¹é‡æ–‡ä»¶")
        with col2_batch:
            if st.button("ğŸš€ æ‰¹é‡å¤„ç†æ‰€æœ‰æ–‡ä»¶", type="primary"):
                process_batch_files()


def process_batch_files():
    """æ‰¹é‡å¤„ç†æ–‡ä»¶ - ç‹¬ç«‹å‡½æ•°"""
    with st.spinner("æ­£åœ¨æ‰¹é‡å¤„ç†..."):
        batch_results = {}
        progress_bar = st.progress(0)

        for i, (filename, df) in enumerate(st.session_state.fe_batch_data.items()):
            try:
                # è·å–æ•°å€¼åˆ—
                numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()

                if numeric_cols:
                    # æå–ç‰¹å¾
                    file_features = []
                    for method in st.session_state.fe_selected_methods:
                        method_selected_features = st.session_state.fe_selected_features.get(method, [])
                        if not method_selected_features:
                            continue

                        # æ ¹æ®æ–¹æ³•æå–ç‰¹å¾
                        params = st.session_state.fe_extraction_params.get(method, {})

                        if method == "Basic Statistical Features":
                            features = extract_basic_statistical_features(
                                df, numeric_cols, method_selected_features
                            )
                        elif method == "Advanced Statistical Features":
                            features = extract_advanced_statistical_features(
                                df, numeric_cols, method_selected_features
                            )
                        elif method == "Time Domain Features":
                            sample_rate = params.get('sample_rate', 625)
                            features = extract_time_domain_features(
                                df, numeric_cols, sample_rate, method_selected_features
                            )
                        elif method == "Frequency Domain Features":
                            sample_rate = params.get('sample_rate', 625)
                            features = extract_frequency_domain_features(
                                df, numeric_cols, sample_rate, method_selected_features
                            )
                        elif method == "Rolling Window Features":
                            window_size = params.get('window_size', 20)
                            features = extract_rolling_window_features(
                                df, numeric_cols, window_size, method_selected_features
                            )
                        elif method == "Enhanced Signal Features":
                            sample_rate = params.get('sample_rate', 625)
                            features = extract_enhanced_signal_features(
                                df, numeric_cols, sample_rate, method_selected_features
                            )

                        if features is not None and not features.empty:
                            file_features.append(features)

                    if file_features:
                        combined = pd.concat(file_features, axis=1)
                        batch_results[filename] = combined

            except Exception as e:
                st.warning(f"å¤„ç† {filename} å¤±è´¥: {e}")

            progress_bar.progress((i + 1) / len(st.session_state.fe_batch_data))

        # å¯¼å‡ºæ‰¹é‡ç»“æœ
        if batch_results:
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                for filename, features in batch_results.items():
                    sheet_name = filename.replace('.xlsx', '').replace('.xls', '')[:31]
                    features.to_excel(writer, sheet_name=sheet_name, index=False)

            st.download_button(
                label="ğŸ“¥ ä¸‹è½½æ‰¹é‡å¤„ç†ç»“æœ",
                data=buffer.getvalue(),
                file_name=f"batch_features_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

            st.success(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼å¤„ç†äº† {len(batch_results)} ä¸ªæ–‡ä»¶")


def export_features_enhanced(features_df):
    """å¢å¼ºçš„å¯¼å‡ºåŠŸèƒ½ï¼Œæ”¯æŒä¸åŸå§‹æ•°æ®åˆå¹¶"""
    st.markdown("---")
    st.subheader("ğŸ’¾ å¯¼å‡ºç‰¹å¾")

    col1_export, col2_export = st.columns(2)

    with col1_export:
        st.markdown("### ğŸ“„ æ–‡ä»¶å¯¼å‡º")

        # é€‰æ‹©å¯¼å‡ºæ¨¡å¼
        export_mode = st.radio(
            "å¯¼å‡ºæ¨¡å¼:",
            ["ä»…å¯¼å‡ºç‰¹å¾", "ä¸åŸå§‹æ•°æ®åˆå¹¶å¯¼å‡º"],
            help="é€‰æ‹©æ˜¯åªå¯¼å‡ºç‰¹å¾è¿˜æ˜¯ä¸åŸå§‹æ•°æ®åˆå¹¶"
        )

        # å‡†å¤‡å¯¼å‡ºæ•°æ®
        if export_mode == "ä¸åŸå§‹æ•°æ®åˆå¹¶å¯¼å‡º" and st.session_state.fe_original_data is not None:
            # å°†ç‰¹å¾æ‰©å±•åˆ°åŸå§‹æ•°æ®çš„é•¿åº¦
            original_data = st.session_state.fe_original_data.copy()

            # å¦‚æœç‰¹å¾åªæœ‰ä¸€è¡Œï¼Œæ‰©å±•åˆ°åŸå§‹æ•°æ®çš„é•¿åº¦
            if len(features_df) == 1:
                features_expanded = pd.concat([features_df] * len(original_data), ignore_index=True)
            else:
                features_expanded = features_df

            # åˆå¹¶æ•°æ®
            export_data = pd.concat([original_data.reset_index(drop=True),
                                     features_expanded.reset_index(drop=True)], axis=1)
            st.info(f"å°†å¯¼å‡º {len(export_data)} è¡Œ, {len(export_data.columns)} åˆ—æ•°æ®")
        else:
            export_data = features_df
            st.info(f"å°†å¯¼å‡º {len(export_data)} è¡Œ, {len(export_data.columns)} åˆ—ç‰¹å¾")

        # é€‰æ‹©å¯¼å‡ºæ ¼å¼
        export_format = st.selectbox("é€‰æ‹©å¯¼å‡ºæ ¼å¼:", ["CSV", "Excel"])

        if export_format == "CSV":
            csv = export_data.to_csv(index=False)
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½CSVæ–‡ä»¶",
                data=csv,
                file_name=f"features_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
        else:  # Excel
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                # å¯¼å‡ºä¸»æ•°æ®
                export_data.to_excel(writer, sheet_name='Features', index=False)

                # æ·»åŠ ç‰¹å¾è¯´æ˜è¡¨
                if st.session_state.fe_selected_features:
                    feature_info = []
                    for method, features in st.session_state.fe_selected_features.items():
                        for feat in features:
                            feature_info.append({
                                'Method': method,
                                'Feature': feat,
                                'Description': FEATURE_DEFINITIONS[method]['features'].get(feat, '')
                            })

                    if feature_info:
                        pd.DataFrame(feature_info).to_excel(writer, sheet_name='Feature_Info', index=False)

                # æ·»åŠ æ–¹æ³•è¯´æ˜è¡¨
                if st.session_state.fe_selected_methods:
                    method_info = []
                    for method in st.session_state.fe_selected_methods:
                        method_info.append({
                            'Method': method,
                            'Description': FEATURE_DEFINITIONS[method]['description'],
                            'Suitable For': FEATURE_METHODS_INFO[method]['suitable_for']
                        })
                    pd.DataFrame(method_info).to_excel(writer, sheet_name='Method_Info', index=False)

            st.download_button(
                label="ğŸ“¥ ä¸‹è½½Excelæ–‡ä»¶",
                data=buffer.getvalue(),
                file_name=f"features_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

    with col2_export:
        st.markdown("### ğŸ”„ æ‰¹é‡å¤„ç†å¯¼å‡º")

        if st.session_state.fe_batch_data:
            st.info(f"æ£€æµ‹åˆ° {len(st.session_state.fe_batch_data)} ä¸ªæ‰¹é‡æ–‡ä»¶")

            if st.button("ğŸš€ æ‰¹é‡å¤„ç†æ‰€æœ‰æ–‡ä»¶", type="primary"):
                with st.spinner("æ­£åœ¨æ‰¹é‡å¤„ç†..."):
                    batch_results = {}
                    progress_bar = st.progress(0)

                    for i, (filename, df) in enumerate(st.session_state.fe_batch_data.items()):
                        try:
                            # è·å–æ•°å€¼åˆ—
                            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()

                            if numeric_cols:
                                # æå–ç‰¹å¾
                                file_features = []
                                for method in st.session_state.fe_selected_methods:
                                    method_selected_features = st.session_state.fe_selected_features.get(method, [])
                                    if not method_selected_features:
                                        continue

                                    # æ ¹æ®æ–¹æ³•æå–ç‰¹å¾
                                    if method == "Basic Statistical Features":
                                        features = extract_basic_statistical_features(
                                            df, numeric_cols, method_selected_features
                                        )
                                    # ... å…¶ä»–æ–¹æ³•ç±»ä¼¼

                                    if features is not None and not features.empty:
                                        file_features.append(features)

                                if file_features:
                                    combined = pd.concat(file_features, axis=1)
                                    batch_results[filename] = combined

                        except Exception as e:
                            st.warning(f"å¤„ç† {filename} å¤±è´¥: {e}")

                        progress_bar.progress((i + 1) / len(st.session_state.fe_batch_data))

                    # å¯¼å‡ºæ‰¹é‡ç»“æœ
                    if batch_results:
                        buffer = io.BytesIO()
                        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                            for filename, features in batch_results.items():
                                sheet_name = filename.replace('.xlsx', '').replace('.xls', '')[:31]
                                features.to_excel(writer, sheet_name=sheet_name, index=False)

                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½æ‰¹é‡å¤„ç†ç»“æœ",
                            data=buffer.getvalue(),
                            file_name=f"batch_features_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )

                        st.success(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼å¤„ç†äº† {len(batch_results)} ä¸ªæ–‡ä»¶")