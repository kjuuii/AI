# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
# Import balancing methods from imbalanced-learn
# Make sure to install it: pip install imbalanced-learn
try:
    from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN
    from imblearn.under_sampling import RandomUnderSampler, NearMiss
    IMBLEARN_AVAILABLE = True
except ImportError:
    IMBLEARN_AVAILABLE = False
    # Define dummy classes if imblearn is not installed to avoid errors
    class RandomOverSampler: pass
    class SMOTE: pass
    class ADASYN: pass
    class RandomUnderSampler: pass
    class NearMiss: pass

import io
import base64
import platform
import matplotlib.font_manager as fm
import os

balancing_options = {
    'none': "ä¸è¿›è¡Œå¤„ç†",
    'random_over': "éšæœºè¿‡é‡‡æ · (RandomOverSampler)",
    'smote': "SMOTE (åˆæˆå°‘æ•°ç±»è¿‡é‡‡æ ·æŠ€æœ¯)",
    'adasyn': "ADASYN (è‡ªé€‚åº”åˆæˆæŠ½æ ·)",
    'random_under': "éšæœºæ¬ é‡‡æ · (RandomUnderSampler)",
    'nearmiss': "NearMiss (åŸºäºè·ç¦»çš„æ¬ é‡‡æ ·)",
}

# --- Font Setup (Reusing from other modules) ---
def setup_chinese_font():
    """Set up Chinese font support for matplotlib."""
    system = platform.system()
    font_candidates = []
    if system == 'Windows':
        font_candidates = ['Microsoft YaHei', 'SimHei', 'SimSun', 'Arial Unicode MS']
    elif system == 'Darwin': # macOS
        font_candidates = ['PingFang SC', 'Heiti SC', 'STHeiti', 'Apple LiGothic Medium']
    else: # Linux and other systems
        font_candidates = ['Noto Sans CJK SC', 'WenQuanYi Micro Hei', 'Droid Sans Fallback']

    font_candidates.extend(['DejaVu Sans', 'Arial', 'Helvetica']) # Fallback fonts

    font_prop = None
    for font_name in font_candidates:
        try:
            font_path = fm.findfont(fm.FontProperties(family=font_name))
            if os.path.exists(font_path) and 'DejaVuSans' not in font_path:
                print(f"å­—ä½“æ—¥å¿—: ä½¿ç”¨å­—ä½“ '{font_name}' åœ¨è·¯å¾„: {font_path}")
                plt.rcParams['font.family'] = 'sans-serif'
                plt.rcParams['font.sans-serif'] = [font_name] + plt.rcParams['font.sans-serif']
                font_prop = fm.FontProperties(family=font_name)
                break
        except Exception as e:
            print(f"å­—ä½“æ—¥å¿—: å°è¯•å­—ä½“ {font_name} å¤±è´¥: {e}")

    if not font_prop:
        print("å­—ä½“æ—¥å¿—: æœªæ‰¾åˆ°åˆé€‚çš„ä¸­æ–‡å­—ä½“ï¼Œç»˜å›¾ä¸­çš„ä¸­æ–‡å¯èƒ½æ— æ³•æ­£å¸¸æ˜¾ç¤ºã€‚")

    plt.rcParams['axes.unicode_minus'] = False
    return font_prop

FONT_PROP = setup_chinese_font()

# --- Helper Functions ---
def apply_plot_style(ax):
    """Apply consistent styling to matplotlib axes."""
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.grid(True, linestyle='--', alpha=0.6, color='#bdc3c7')
    ax.tick_params(axis='both', which='major', labelsize=9, colors='#34495e')
    ax.xaxis.label.set_fontsize(10)
    ax.yaxis.label.set_fontsize(10)
    ax.title.set_fontsize(12)
    ax.title.set_fontweight('bold')
    ax.xaxis.label.set_fontweight('bold')
    ax.yaxis.label.set_fontweight('bold')
    # Apply Chinese font if available
    font_kwargs = {'fontproperties': FONT_PROP} if FONT_PROP else {}
    if font_kwargs:
        for label in ax.get_xticklabels() + ax.get_yticklabels():
            label.set_fontproperties(FONT_PROP)
        ax.xaxis.label.set_fontproperties(FONT_PROP)
        ax.yaxis.label.set_fontproperties(FONT_PROP)
        ax.title.set_fontproperties(FONT_PROP)
    return ax

def plot_class_distribution(y, title="ç±»åˆ«åˆ†å¸ƒ"):
    """Plots the distribution of classes."""
    fig, ax = plt.subplots(figsize=(8, 5), dpi=80)
    apply_plot_style(ax)
    counts = y.value_counts().sort_index()
    bars = ax.bar(counts.index.astype(str), counts.values, color=plt.cm.viridis(np.linspace(0, 1, len(counts))))
    ax.set_title(title, fontproperties=FONT_PROP if FONT_PROP else None)
    ax.set_xlabel("ç±»åˆ«", fontproperties=FONT_PROP if FONT_PROP else None)
    ax.set_ylabel("æ ·æœ¬æ•°é‡", fontproperties=FONT_PROP if FONT_PROP else None)
    # Add counts on top of bars
    for bar in bars:
        height = bar.get_height()
        ax.annotate(f'{height}',
                    xy=(bar.get_x() + bar.get_width() / 2, height),
                    xytext=(0, 3),  # 3 points vertical offset
                    textcoords="offset points",
                    ha='center', va='bottom', fontsize=8)
    plt.tight_layout()
    return fig

def get_download_link_csv(df, filename, text):
    """Generates a link to download a DataFrame as a CSV file."""
    csv = df.to_csv(index=False, encoding='utf-8-sig')
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">{text}</a>'
    return href

# --- Balancing Functions ---
def apply_balancing(X, y, method='random_over', random_state=42, **kwargs):
    """Applies the selected balancing method."""
    if not IMBLEARN_AVAILABLE:
        st.error("éœ€è¦å®‰è£… 'imbalanced-learn' åº“æ¥æ‰§è¡Œæ•°æ®å¹³è¡¡ã€‚è¯·è¿è¡Œ: pip install imbalanced-learn")
        return None, None

    sampler = None
    try:
        if method == 'random_over':
            sampler = RandomOverSampler(random_state=random_state)
        elif method == 'smote':
            # SMOTE might require specific k_neighbors depending on minority class size
            n_neighbors = kwargs.get('smote_k_neighbors', 5)
            # Ensure k_neighbors is less than the number of samples in the smallest class
            min_class_count = y.value_counts().min()
            if n_neighbors >= min_class_count:
                 n_neighbors = max(1, min_class_count - 1) # Adjust k_neighbors
                 st.warning(f"SMOTE çš„ k_neighbors å·²è°ƒæ•´ä¸º {n_neighbors} ä»¥é€‚åº”æœ€å°ç±»åˆ«æ ·æœ¬æ•°ã€‚")
            sampler = SMOTE(random_state=random_state, k_neighbors=n_neighbors)
        elif method == 'adasyn':
            n_neighbors = kwargs.get('adasyn_n_neighbors', 5)
            min_class_count = y.value_counts().min()
            if n_neighbors >= min_class_count:
                 n_neighbors = max(1, min_class_count - 1)
                 st.warning(f"ADASYN çš„ n_neighbors å·²è°ƒæ•´ä¸º {n_neighbors} ä»¥é€‚åº”æœ€å°ç±»åˆ«æ ·æœ¬æ•°ã€‚")
            sampler = ADASYN(random_state=random_state, n_neighbors=n_neighbors)
        elif method == 'random_under':
            sampler = RandomUnderSampler(random_state=random_state)
        elif method == 'nearmiss':
            version = kwargs.get('nearmiss_version', 1)
            n_neighbors = kwargs.get('nearmiss_n_neighbors', 3)
            sampler = NearMiss(version=version, n_neighbors=n_neighbors)
        else:
            st.error(f"æœªçŸ¥çš„å¹³è¡¡æ–¹æ³•: {method}")
            return X, y # Return original data

        X_resampled, y_resampled = sampler.fit_resample(X, y)
        return X_resampled, y_resampled

    except ValueError as ve:
         st.error(f"åº”ç”¨å¹³è¡¡æ–¹æ³• '{method}' æ—¶å‡ºé”™: {ve}")
         st.info("è¿™é€šå¸¸å‘ç”Ÿåœ¨ç±»åˆ«æ ·æœ¬æ•°è¿‡å°‘ï¼Œæ— æ³•åº”ç”¨æ‰€é€‰æ–¹æ³•ï¼ˆä¾‹å¦‚SMOTE/ADASYNçš„é‚»å±…æ•°å¤§äºæœ€å°ç±»åˆ«æ ·æœ¬æ•°ï¼‰ã€‚è¯·å°è¯•å…¶ä»–æ–¹æ³•æˆ–æ£€æŸ¥æ•°æ®ã€‚")
         return X, y # Return original data on error
    except Exception as e:
        st.error(f"åº”ç”¨å¹³è¡¡æ–¹æ³• '{method}' æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
        import traceback
        st.code(traceback.format_exc())
        return X, y # Return original data on error


# --- Streamlit UI Functions ---
def initialize_balancing_state():
    """Initialize session state variables for the data balancing page."""
    defaults = {
        'db_data': None,            # Original uploaded data
        'db_X': None,               # Features DataFrame
        'db_y': None,               # Target Series
        'db_target_col': None,      # Selected target column name
        'db_balanced_X': None,      # Balanced features
        'db_balanced_y': None,      # Balanced target
        'db_class_counts_before': None, # Class counts before balancing
        'db_class_counts_after': None,  # Class counts after balancing
        'db_balancing_method': 'random_over', # Default balancing method
        # Parameters for specific methods
        'db_smote_k_neighbors': 5,
        'db_adasyn_n_neighbors': 5,
        'db_nearmiss_version': 1,
        'db_nearmiss_n_neighbors': 3,
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

def show_balancing_page():
    """Main function to display the data balancing handling page."""
    if not IMBLEARN_AVAILABLE:
        st.error("é”™è¯¯ï¼šç¼ºå°‘ `imbalanced-learn` åº“ã€‚è¯·åœ¨ç»ˆç«¯è¿è¡Œ `pip install imbalanced-learn` æ¥å®‰è£…å®ƒï¼Œç„¶åé‡æ–°å¯åŠ¨åº”ç”¨ã€‚")
        st.stop() # Stop execution if library is missing

    initialize_balancing_state()

    st.title("âš–ï¸ æ•°æ®å¹³è¡¡å¤„ç†")
    st.markdown("---")
    st.info("ä¸Šä¼ åˆ†ç±»æ•°æ®ï¼Œåˆ†æç±»åˆ«åˆ†å¸ƒï¼Œå¹¶åº”ç”¨é‡‡æ ·æ–¹æ³•æ¥å¤„ç†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚")

    # --- Create Tabs ---
    tab1, tab2, tab3 = st.tabs(["ğŸ“ æ•°æ®å¯¼å…¥ä¸åˆ†æ", "âš™ï¸ å¹³è¡¡æ–¹æ³•é€‰æ‹©", "ğŸ“Š å¹³è¡¡ç»“æœå±•ç¤º"])

    with tab1:
        create_balancing_data_import_analysis()

    with tab2:
        create_balancing_method_selection()

    with tab3:
        create_balancing_results_section()

def create_balancing_data_import_analysis():
    """UI section for data import and class distribution analysis."""
    st.header("1. æ•°æ®å¯¼å…¥ä¸ç±»åˆ«åˆ†æ")

    uploaded_file = st.file_uploader("ä¸Šä¼ åŒ…å«ç‰¹å¾å’Œç›®æ ‡åˆ—çš„æ–‡ä»¶ (CSV/Excel)", type=["csv", "xlsx", "xls"], key="db_uploader")

    if uploaded_file:
        if st.button("åŠ è½½å¹¶åˆ†ææ•°æ®", key="db_load_analyze_btn"):
            with st.spinner("æ­£åœ¨åŠ è½½å’Œåˆ†ææ•°æ®..."):
                try:
                    # Load data
                    data = pd.read_csv(uploaded_file) if uploaded_file.name.lower().endswith('.csv') else pd.read_excel(uploaded_file)

                    # Store original data
                    st.session_state.db_data = data
                    st.session_state.db_X = None
                    st.session_state.db_y = None
                    st.session_state.db_target_col = None
                    st.session_state.db_balanced_X = None
                    st.session_state.db_balanced_y = None
                    st.session_state.db_class_counts_before = None
                    st.session_state.db_class_counts_after = None

                    st.success(f"æˆåŠŸåŠ è½½æ–‡ä»¶: {uploaded_file.name} ({len(data)} è¡Œ, {len(data.columns)} åˆ—)")
                    st.rerun() # Rerun to update target selection

                except Exception as e:
                    st.error(f"åŠ è½½æ•°æ®æ—¶å‡ºé”™: {e}")
                    st.session_state.db_data = None

    # Display analysis results if data is loaded
    if st.session_state.db_data is not None:
        st.subheader("æ•°æ®é¢„è§ˆ (å‰5è¡Œ)")
        st.dataframe(st.session_state.db_data.head())

        # --- Target Column Selection ---
        st.subheader("é€‰æ‹©ç›®æ ‡åˆ— (ç±»åˆ«æ ‡ç­¾)")
        all_columns = st.session_state.db_data.columns.tolist()
        # Try to guess a categorical column as default
        potential_targets = [col for col in all_columns if st.session_state.db_data[col].nunique() < 20] # Heuristic
        default_target_index = 0
        if st.session_state.db_target_col and st.session_state.db_target_col in all_columns:
             try:
                  default_target_index = all_columns.index(st.session_state.db_target_col)
             except ValueError:
                  default_target_index = 0
        elif potential_targets:
             try:
                  # Try to find common target names
                  common_names = ['target', 'label', 'class', 'category']
                  found = False
                  for name in common_names:
                       if name in potential_targets:
                            default_target_index = all_columns.index(name)
                            found = True
                            break
                  if not found: default_target_index = all_columns.index(potential_targets[-1]) # Default to last potential target
             except ValueError:
                   default_target_index = 0


        selected_target = st.selectbox(
            "é€‰æ‹©åŒ…å«ç±»åˆ«æ ‡ç­¾çš„ç›®æ ‡åˆ—:",
            options=all_columns,
            index=default_target_index,
            key="db_target_select"
        )

        if selected_target:
            st.session_state.db_target_col = selected_target
            try:
                y = st.session_state.db_data[selected_target]
                # Check if target is suitable (not too many unique values)
                if y.nunique() > 50:
                     st.warning(f"è­¦å‘Šï¼šç›®æ ‡åˆ— '{selected_target}' æœ‰è¶…è¿‡ 50 ä¸ªå”¯ä¸€å€¼ï¼Œå¯èƒ½ä¸é€‚åˆåˆ†ç±»æˆ–å¹³è¡¡ã€‚")
                elif y.isnull().any():
                     st.warning(f"è­¦å‘Šï¼šç›®æ ‡åˆ— '{selected_target}' åŒ…å«ç¼ºå¤±å€¼ã€‚è¯·å…ˆå¤„ç†ç¼ºå¤±å€¼ã€‚")
                else:
                    st.session_state.db_y = y
                    # Separate features (X) - exclude target column
                    st.session_state.db_X = st.session_state.db_data.drop(columns=[selected_target])
                    # Analyze class distribution
                    st.session_state.db_class_counts_before = y.value_counts()

                    st.subheader("åŸå§‹ç±»åˆ«åˆ†å¸ƒ")
                    st.dataframe(st.session_state.db_class_counts_before.reset_index().rename(columns={'index': 'ç±»åˆ«', selected_target: 'æ•°é‡'}))

                    # Plot distribution
                    try:
                        fig = plot_class_distribution(y, title="åŸå§‹ç±»åˆ«åˆ†å¸ƒ")
                        st.pyplot(fig)
                    except Exception as plot_e:
                        st.error(f"ç»˜åˆ¶ç±»åˆ«åˆ†å¸ƒå›¾æ—¶å‡ºé”™: {plot_e}")
            except KeyError:
                 st.error(f"æ— æ³•æ‰¾åˆ°åˆ— '{selected_target}'ã€‚")
                 st.session_state.db_y = None
                 st.session_state.db_X = None
                 st.session_state.db_class_counts_before = None
            except Exception as e:
                 st.error(f"å¤„ç†ç›®æ ‡åˆ—æ—¶å‡ºé”™: {e}")
                 st.session_state.db_y = None
                 st.session_state.db_X = None
                 st.session_state.db_class_counts_before = None
        else:
            st.warning("è¯·é€‰æ‹©ä¸€ä¸ªç›®æ ‡åˆ—ä»¥è¿›è¡Œåˆ†æã€‚")
            st.session_state.db_y = None
            st.session_state.db_X = None
            st.session_state.db_class_counts_before = None


def create_balancing_method_selection():
    """UI section for selecting balancing method and parameters."""
    st.header("2. å¹³è¡¡æ–¹æ³•é€‰æ‹©")

    if st.session_state.db_X is None or st.session_state.db_y is None:
        st.info("è¯·å…ˆåœ¨â€œæ•°æ®å¯¼å…¥ä¸åˆ†æâ€é€‰é¡¹å¡ä¸­åŠ è½½æ•°æ®å¹¶é€‰æ‹©ç›®æ ‡åˆ—ã€‚")
        return

    # --- Select Balancing Method ---
    st.subheader("é€‰æ‹©å¹³è¡¡æ–¹æ³•")
    balancing_options = {
        'none': "ä¸è¿›è¡Œå¤„ç†",
        'random_over': "éšæœºè¿‡é‡‡æ · (RandomOverSampler)",
        'smote': "SMOTE (åˆæˆå°‘æ•°ç±»è¿‡é‡‡æ ·æŠ€æœ¯)",
        'adasyn': "ADASYN (è‡ªé€‚åº”åˆæˆæŠ½æ ·)",
        'random_under': "éšæœºæ¬ é‡‡æ · (RandomUnderSampler)",
        'nearmiss': "NearMiss (åŸºäºè·ç¦»çš„æ¬ é‡‡æ ·)",
    }

    st.session_state.db_balancing_method = st.radio(
        "é€‰æ‹©æ•°æ®å¹³è¡¡ç­–ç•¥:",
        options=list(balancing_options.keys()),
        format_func=lambda x: balancing_options[x],
        key="db_method_radio"
    )

    # --- Display Method Descriptions and Parameters ---
    method = st.session_state.db_balancing_method
    if method != 'none':
        with st.expander(f"å…³äº **{balancing_options[method]}** çš„è¯´æ˜ä¸å‚æ•°"):
            if method == 'random_over':
                st.markdown("""
                - **ç±»å‹**: è¿‡é‡‡æ ·
                - **ç®€ä»‹**: éšæœºå¤åˆ¶å°‘æ•°ç±»æ ·æœ¬ï¼Œç›´åˆ°è¾¾åˆ°ä¸å¤šæ•°ç±»ç›¸åŒçš„æ•°é‡ã€‚
                - **é€‚ç”¨èŒƒå›´**: ç®€å•æ˜“æ‡‚ï¼Œé€‚ç”¨äºå„ç§æ•°æ®é›†ã€‚
                - **ä¼˜ç‚¹**: å®ç°ç®€å•ï¼Œä¸ä¸¢å¤±ä¿¡æ¯ã€‚
                - **ç¼ºç‚¹**: å¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆï¼Œå› ä¸ºåªæ˜¯ç®€å•å¤åˆ¶æ ·æœ¬ï¼Œæ²¡æœ‰äº§ç”Ÿæ–°ä¿¡æ¯ã€‚
                """)
            elif method == 'smote':
                st.markdown("""
                - **ç±»å‹**: è¿‡é‡‡æ ·
                - **ç®€ä»‹**: ä¸ºå°‘æ•°ç±»åˆæˆæ–°çš„æ ·æœ¬ã€‚å¯¹æ¯ä¸ªå°‘æ•°ç±»æ ·æœ¬ï¼Œé€‰æ‹©å…¶kä¸ªè¿‘é‚»ï¼Œç„¶ååœ¨è¯¥æ ·æœ¬ä¸å…¶è¿‘é‚»ä¹‹é—´çš„è¿çº¿ä¸Šéšæœºç”Ÿæˆæ–°æ ·æœ¬ã€‚
                - **é€‚ç”¨èŒƒå›´**: é€‚ç”¨äºæ•°å€¼å‹ç‰¹å¾ï¼Œæ˜¯å¤„ç†ä¸å¹³è¡¡é—®é¢˜çš„å¸¸ç”¨ä¸”æœ‰æ•ˆæ–¹æ³•ã€‚
                - **ä¼˜ç‚¹**: äº§ç”Ÿæ–°æ ·æœ¬ï¼Œæä¾›æ›´å¤šä¿¡æ¯ï¼Œé€šå¸¸æ¯”éšæœºè¿‡é‡‡æ ·æ•ˆæœæ›´å¥½ï¼Œèƒ½ç¼“è§£è¿‡æ‹Ÿåˆã€‚
                - **ç¼ºç‚¹**: å¯¹é«˜ç»´æ•°æ®æ•ˆæœå¯èƒ½ä¸‹é™ï¼›å¯èƒ½ç”Ÿæˆå™ªå£°æ ·æœ¬æˆ–æ¨¡ç³Šç±»åˆ«è¾¹ç•Œï¼›å¯¹å‚æ•°kæ•æ„Ÿã€‚
                """)
                st.session_state.db_smote_k_neighbors = st.slider(
                    "k_neighbors (SMOTEè¿‘é‚»æ•°)", min_value=1, max_value=20,
                    value=st.session_state.db_smote_k_neighbors, step=1, key="db_smote_k",
                    help="ç”¨äºåˆæˆæ ·æœ¬çš„è¿‘é‚»æ•°é‡ã€‚æ³¨æ„ï¼šå¿…é¡»å°äºæœ€å°ç±»åˆ«çš„æ ·æœ¬æ•°ã€‚"
                )
            elif method == 'adasyn':
                st.markdown("""
                - **ç±»å‹**: è¿‡é‡‡æ ·
                - **ç®€ä»‹**: è‡ªé€‚åº”åˆæˆæŠ½æ ·ã€‚ä¸SMOTEç±»ä¼¼ï¼Œä½†æ›´å…³æ³¨é‚£äº›éš¾ä»¥å­¦ä¹ çš„å°‘æ•°ç±»æ ·æœ¬ï¼ˆå³é‚»åŸŸä¸­å¤šæ•°ç±»æ ·æœ¬æ¯”ä¾‹é«˜çš„æ ·æœ¬ï¼‰ï¼Œä¸ºè¿™äº›æ ·æœ¬ç”Ÿæˆæ›´å¤šåˆæˆæ•°æ®ã€‚
                - **é€‚ç”¨èŒƒå›´**: é€‚ç”¨äºæ•°å€¼å‹ç‰¹å¾ï¼Œç‰¹åˆ«æ˜¯å½“ç±»åˆ«è¾¹ç•Œå¤æ‚æ—¶ã€‚
                - **ä¼˜ç‚¹**: èƒ½è‡ªé€‚åº”åœ°åœ¨æ›´éœ€è¦çš„åœ°æ–¹ç”Ÿæˆæ ·æœ¬ã€‚
                - **ç¼ºç‚¹**: å¯¹å™ªå£°æ•°æ®æ›´æ•æ„Ÿï¼›å®ç°æ¯”SMOTEå¤æ‚ï¼›å¯¹å‚æ•°n_neighborsæ•æ„Ÿã€‚
                """)
                st.session_state.db_adasyn_n_neighbors = st.slider(
                    "n_neighbors (ADASYNè¿‘é‚»æ•°)", min_value=1, max_value=20,
                    value=st.session_state.db_adasyn_n_neighbors, step=1, key="db_adasyn_k",
                     help="ç”¨äºç¡®å®šæ ·æœ¬å¯†åº¦çš„è¿‘é‚»æ•°é‡ã€‚æ³¨æ„ï¼šå¿…é¡»å°äºæœ€å°ç±»åˆ«çš„æ ·æœ¬æ•°ã€‚"
                )
            elif method == 'random_under':
                st.markdown("""
                - **ç±»å‹**: æ¬ é‡‡æ ·
                - **ç®€ä»‹**: éšæœºåˆ é™¤å¤šæ•°ç±»æ ·æœ¬ï¼Œç›´åˆ°å…¶æ•°é‡ä¸å°‘æ•°ç±»ç›¸åŒï¼ˆæˆ–è¾¾åˆ°æŒ‡å®šæ¯”ä¾‹ï¼‰ã€‚
                - **é€‚ç”¨èŒƒå›´**: å½“æ•°æ®é›†éå¸¸å¤§ï¼Œä¸”å¤šæ•°ç±»æ ·æœ¬åŒ…å«å¤§é‡å†—ä½™ä¿¡æ¯æ—¶ã€‚
                - **ä¼˜ç‚¹**: å®ç°ç®€å•ï¼›å¯ä»¥æ˜¾è‘—å‡å°‘æ•°æ®é›†å¤§å°ï¼ŒåŠ å¿«è®­ç»ƒé€Ÿåº¦ã€‚
                - **ç¼ºç‚¹**: å¯èƒ½ä¸¢å¤±å¤šæ•°ç±»çš„é‡è¦ä¿¡æ¯ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™ã€‚
                """)
            elif method == 'nearmiss':
                st.markdown("""
                - **ç±»å‹**: æ¬ é‡‡æ ·
                - **ç®€ä»‹**: åŸºäºè·ç¦»é€‰æ‹©è¦ä¿ç•™çš„å¤šæ•°ç±»æ ·æœ¬ã€‚æœ‰ä¸åŒç‰ˆæœ¬ï¼š
                    - **Version 1**: é€‰æ‹©ä¸æœ€è¿‘çš„kä¸ªå°‘æ•°ç±»æ ·æœ¬å¹³å‡è·ç¦»æœ€å°çš„å¤šæ•°ç±»æ ·æœ¬ã€‚
                    - **Version 2**: é€‰æ‹©ä¸æœ€è¿œçš„kä¸ªå°‘æ•°ç±»æ ·æœ¬å¹³å‡è·ç¦»æœ€å°çš„å¤šæ•°ç±»æ ·æœ¬ã€‚
                    - **Version 3**: å¯¹æ¯ä¸ªå°‘æ•°ç±»æ ·æœ¬ï¼Œä¿ç•™å…¶æœ€è¿‘çš„kä¸ªå¤šæ•°ç±»æ ·æœ¬ã€‚
                - **é€‚ç”¨èŒƒå›´**: å½“å¤šæ•°ç±»å’Œå°‘æ•°ç±»è¾¹ç•Œæ¸…æ™°æ—¶å¯èƒ½æœ‰æ•ˆã€‚
                - **ä¼˜ç‚¹**: å°è¯•ä¿ç•™é è¿‘è¾¹ç•Œçš„å¤šæ•°ç±»ä¿¡æ¯ã€‚
                - **ç¼ºç‚¹**: å¯¹å™ªå£°å’Œå¼‚å¸¸å€¼æ•æ„Ÿï¼›è®¡ç®—æˆæœ¬è¾ƒé«˜ï¼›å¯èƒ½æ‰­æ›²æ•°æ®åˆ†å¸ƒã€‚
                """)
                st.session_state.db_nearmiss_version = st.selectbox(
                    "NearMiss ç‰ˆæœ¬", options=[1, 2, 3],
                    index=st.session_state.db_nearmiss_version - 1, key="db_nearmiss_v"
                )
                st.session_state.db_nearmiss_n_neighbors = st.slider(
                    "n_neighbors (NearMissè¿‘é‚»æ•°)", min_value=1, max_value=20,
                    value=st.session_state.db_nearmiss_n_neighbors, step=1, key="db_nearmiss_k"
                )

    # --- Apply Balancing Button ---
    if st.button("åº”ç”¨å¹³è¡¡æ–¹æ³•", key="db_apply_btn", type="primary", disabled=(method == 'none')):
        run_balancing()

def run_balancing():
    """Runs the selected balancing method."""
    X = st.session_state.db_X
    y = st.session_state.db_y
    method = st.session_state.db_balancing_method

    if X is None or y is None:
        st.error("æ— æ³•æ‰§è¡Œå¹³è¡¡ï¼šæ•°æ®æˆ–ç›®æ ‡åˆ—æœªå‡†å¤‡å¥½ã€‚")
        return
    if method == 'none':
        st.info("é€‰æ‹©äº†â€œä¸è¿›è¡Œå¤„ç†â€ï¼Œæ•°æ®æœªæ”¹å˜ã€‚")
        st.session_state.db_balanced_X = X.copy()
        st.session_state.db_balanced_y = y.copy()
        st.session_state.db_class_counts_after = y.value_counts()
        return

    # Check if features are numeric for methods that require it
    numeric_methods = ['smote', 'adasyn', 'nearmiss'] # KNN also implicitly requires numeric
    if method in numeric_methods:
        non_numeric_cols = X.select_dtypes(exclude=np.number).columns.tolist()
        if non_numeric_cols:
            st.error(f"é€‰æ‹©çš„æ–¹æ³• '{method}' ä»…é€‚ç”¨äºæ•°å€¼ç‰¹å¾ï¼Œä½†æ•°æ®åŒ…å«éæ•°å€¼åˆ—: {', '.join(non_numeric_cols)}ã€‚è¯·å…ˆè¿›è¡Œç¼–ç æˆ–é€‰æ‹©å…¶ä»–æ–¹æ³•ã€‚")
            return

    st.info(f"æ­£åœ¨åº”ç”¨ '{balancing_options.get(method, method)}' æ–¹æ³•...")
    with st.spinner("æ­£åœ¨å¹³è¡¡æ•°æ®..."):
        kwargs = {}
        if method == 'smote':
            kwargs['smote_k_neighbors'] = st.session_state.db_smote_k_neighbors
        elif method == 'adasyn':
            kwargs['adasyn_n_neighbors'] = st.session_state.db_adasyn_n_neighbors
        elif method == 'nearmiss':
            kwargs['nearmiss_version'] = st.session_state.db_nearmiss_version
            kwargs['nearmiss_n_neighbors'] = st.session_state.db_nearmiss_n_neighbors

        # Apply balancing
        X_res, y_res = apply_balancing(X, y, method, **kwargs)

        if X_res is not None and y_res is not None:
            # Store results
            st.session_state.db_balanced_X = X_res
            st.session_state.db_balanced_y = y_res
            st.session_state.db_class_counts_after = y_res.value_counts()
            st.success("æ•°æ®å¹³è¡¡å¤„ç†å®Œæˆï¼è¯·å‰å¾€â€œå¹³è¡¡ç»“æœå±•ç¤ºâ€é€‰é¡¹å¡æŸ¥çœ‹ã€‚")
        else:
            # Error occurred during balancing (handled in apply_balancing)
            st.session_state.db_balanced_X = None
            st.session_state.db_balanced_y = None
            st.session_state.db_class_counts_after = None


def create_balancing_results_section():
    """UI section to display the data after balancing."""
    st.header("3. å¹³è¡¡ç»“æœå±•ç¤º")

    if st.session_state.db_balanced_X is None or st.session_state.db_balanced_y is None:
        st.info("è¯·å…ˆåœ¨â€œå¹³è¡¡æ–¹æ³•é€‰æ‹©â€é€‰é¡¹å¡ä¸­åº”ç”¨å¹³è¡¡æ–¹æ³•ã€‚")
        return

    st.subheader("å¹³è¡¡åç±»åˆ«åˆ†å¸ƒ")
    if st.session_state.db_class_counts_after is not None:
        st.dataframe(st.session_state.db_class_counts_after.reset_index().rename(columns={'index': 'ç±»åˆ«', st.session_state.db_target_col: 'æ•°é‡'}))
        try:
            fig = plot_class_distribution(st.session_state.db_balanced_y, title="å¹³è¡¡åç±»åˆ«åˆ†å¸ƒ")
            st.pyplot(fig)
        except Exception as plot_e:
            st.error(f"ç»˜åˆ¶å¹³è¡¡åç±»åˆ«åˆ†å¸ƒå›¾æ—¶å‡ºé”™: {plot_e}")
    else:
        st.warning("æœªèƒ½è·å–å¹³è¡¡åçš„ç±»åˆ«è®¡æ•°ã€‚")


    st.subheader("å¹³è¡¡åçš„æ•°æ®é¢„è§ˆ (å‰5è¡Œ)")
    # Combine X and y for preview
    preview_df = st.session_state.db_balanced_X.head().copy()
    preview_df[st.session_state.db_target_col] = st.session_state.db_balanced_y.head()
    st.dataframe(preview_df)

    st.info(f"å¹³è¡¡åçš„æ•°æ®é›†åŒ…å« {len(st.session_state.db_balanced_X)} è¡Œã€‚")

    # Download button for balanced data
    st.subheader("ä¸‹è½½å¹³è¡¡åçš„æ•°æ®")
    if st.button("å‡†å¤‡ä¸‹è½½æ–‡ä»¶", key="db_prep_download"):
        try:
            # Combine X and y for download
            df_to_download = st.session_state.db_balanced_X.copy()
            df_to_download[st.session_state.db_target_col] = st.session_state.db_balanced_y
            method_name = st.session_state.db_balancing_method.replace('_', '-')
            filename = f"balanced_data_{method_name}.csv"
            download_link = get_download_link_csv(df_to_download, filename, f"ç‚¹å‡»ä¸‹è½½ {filename}")
            st.markdown(download_link, unsafe_allow_html=True)
        except Exception as e:
            st.error(f"å‡†å¤‡ä¸‹è½½æ–‡ä»¶æ—¶å‡ºé”™: {e}")

# --- Main function entry point (for potential direct script run) ---
if __name__ == "__main__":
    # This part is optional, allows running this module directly for testing
    st.set_page_config(layout="wide", page_title="æ•°æ®å¹³è¡¡å¤„ç†")
    show_balancing_page()
