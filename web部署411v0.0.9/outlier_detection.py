# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import base64
from io import BytesIO
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
from sklearn.svm import OneClassSVM
from sklearn.covariance import EllipticEnvelope
import platform
import matplotlib.font_manager as fm
import datetime


# --- å­—ä½“è®¾ç½® ---
def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ"""
    system = platform.system()
    font_candidates = []
    if system == 'Windows':
        font_candidates = ['Microsoft YaHei', 'SimHei', 'SimSun', 'Arial Unicode MS']
    elif system == 'Darwin':
        font_candidates = ['PingFang SC', 'Heiti SC', 'STHeiti', 'Apple LiGothic Medium']
    else:
        font_candidates = ['Noto Sans CJK SC', 'WenQuanYi Micro Hei', 'Droid Sans Fallback']
    font_candidates.extend(['DejaVu Sans', 'Arial', 'Helvetica'])

    font_prop = None
    for font_name in font_candidates:
        try:
            font_path = fm.findfont(fm.FontProperties(family=font_name))
            if os.path.exists(font_path) and 'DejaVuSans' not in font_path:
                print(f"å­—ä½“æ—¥å¿—: ä½¿ç”¨å­—ä½“ '{font_name}' åœ¨è·¯å¾„: {font_path}")
                plt.rcParams['font.family'] = 'sans-serif'
                plt.rcParams['font.sans-serif'] = [font_name] + plt.rcParams['font.sans-serif']
                font_prop = fm.FontProperties(family=font_name)
                break
        except Exception as e:
            print(f"å­—ä½“æ—¥å¿—: å°è¯•å­—ä½“ {font_name} å¤±è´¥: {e}")

    if not font_prop:
        print("å­—ä½“æ—¥å¿—: æœªæ‰¾åˆ°åˆé€‚çš„ä¸­æ–‡å­—ä½“ï¼Œç»˜å›¾ä¸­çš„ä¸­æ–‡å¯èƒ½æ— æ³•æ­£å¸¸æ˜¾ç¤ºã€‚")
    plt.rcParams['axes.unicode_minus'] = False
    return font_prop


FONT_PROP = setup_chinese_font()


# --- ç»˜å›¾è¾…åŠ©å‡½æ•° ---
def apply_plot_style(ax):
    """åº”ç”¨ç»Ÿä¸€çš„ç»˜å›¾æ ·å¼"""
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.grid(True, linestyle='--', alpha=0.6, color='#bdc3c7')
    ax.tick_params(axis='both', which='major', labelsize=9, colors='#34495e')
    ax.xaxis.label.set_fontsize(10);
    ax.yaxis.label.set_fontsize(10)
    ax.title.set_fontsize(12);
    ax.title.set_fontweight('bold')
    ax.xaxis.label.set_fontweight('bold');
    ax.yaxis.label.set_fontweight('bold')
    return ax


def plot_outliers_2d(X_df, labels, method_name="å¼‚å¸¸ç‚¹æ£€æµ‹"):
    """ä½¿ç”¨PCAé™ç»´ï¼ˆå¦‚æœéœ€è¦ï¼‰ç»˜åˆ¶2Dæ•£ç‚¹å›¾ï¼Œçªå‡ºæ˜¾ç¤ºå¼‚å¸¸ç‚¹"""
    fig, ax = plt.subplots(figsize=(10, 7), dpi=80)
    apply_plot_style(ax)
    font_kwargs = {'fontproperties': FONT_PROP} if FONT_PROP else {}

    try:
        # PCAé™ç»´
        pca_applied = False
        if X_df.shape[1] > 2:
            pca = PCA(n_components=2, random_state=42)
            scaler_pca = StandardScaler()
            X_scaled_pca = scaler_pca.fit_transform(X_df.values)
            X_2d = pca.fit_transform(X_scaled_pca)
            explained_var = pca.explained_variance_ratio_
            pca_applied = True
            xlabel = "ä¸»æˆåˆ† 1"
            ylabel = "ä¸»æˆåˆ† 2"
        else:
            X_2d = X_df.values
            explained_var = None
            xlabel = X_df.columns[0] if X_df.shape[1] >= 1 else "ç»´åº¦ 1"
            ylabel = X_df.columns[1] if X_df.shape[1] >= 2 else "ç»´åº¦ 2"

        # è¯†åˆ«æ­£å¸¸ç‚¹å’Œå¼‚å¸¸ç‚¹
        normal_points = X_2d[labels != -1]
        outliers = X_2d[labels == -1]

        # ç»˜åˆ¶æ­£å¸¸ç‚¹ï¼ˆè“è‰²åœ†ç‚¹ï¼‰
        ax.scatter(normal_points[:, 0], normal_points[:, 1], c='#3498db', marker='o',
                   s=25, alpha=0.6, label='æ­£å¸¸ç‚¹')

        # ç»˜åˆ¶å¼‚å¸¸ç‚¹ï¼ˆçº¢è‰²å‰å·ï¼‰
        ax.scatter(outliers[:, 0], outliers[:, 1], c='#e74c3c', marker='x',
                   s=60, alpha=0.9, label='å¼‚å¸¸ç‚¹')

        # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
        title = f"{method_name} æ£€æµ‹ç»“æœ"
        if pca_applied:
            title += f" (PCAé™ç»´: æ–¹å·®è§£é‡Šç‡ {explained_var[0]:.2f}, {explained_var[1]:.2f})"

        ax.set_title(title, **font_kwargs)
        ax.set_xlabel(xlabel, **font_kwargs)
        ax.set_ylabel(ylabel, **font_kwargs)

        # æ·»åŠ å›¾ä¾‹
        legend = ax.legend(prop=FONT_PROP, fontsize=9)
        plt.tight_layout()

    except Exception as e:
        print(f"ç»˜åˆ¶å¼‚å¸¸ç‚¹å›¾æ—¶å‡ºé”™: {e}")
        ax.text(0.5, 0.5, f'ç»˜å›¾é”™è¯¯: {e}', ha='center', va='center', color='red', **font_kwargs)

    return fig


def get_download_link(df, filename, text):
    """ç”ŸæˆCSVä¸‹è½½é“¾æ¥"""
    csv = df.to_csv(index=False, encoding='utf-8-sig')
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">{text}</a>'
    return href


# --- å¼‚å¸¸ç‚¹æ£€æµ‹ç®—æ³•ä¿¡æ¯ ---
ALGORITHM_INFO = {
    "DBSCAN": {
        "name": "DBSCAN",
        "description": "åŸºäºå¯†åº¦çš„ç©ºé—´èšç±»ç®—æ³•",
        "suitable_for": [
            "â€¢ èƒ½å‘ç°ä»»æ„å½¢çŠ¶çš„å¼‚å¸¸ç‚¹",
            "â€¢ é€‚åˆå¯†åº¦ä¸å‡åŒ€çš„æ•°æ®",
            "â€¢ ä¸éœ€è¦é¢„å…ˆæŒ‡å®šå¼‚å¸¸ç‚¹æ•°é‡",
            "â€¢ èƒ½åŒºåˆ†å™ªå£°å’Œè¾¹ç•Œç‚¹"
        ],
        "pros": [
            "â€¢ èƒ½è¯†åˆ«ä¸è§„åˆ™å½¢çŠ¶çš„å¼‚å¸¸åŒºåŸŸ",
            "â€¢ å¯¹å¼‚å¸¸ç‚¹å¤§å°ä¸æ•æ„Ÿ",
            "â€¢ ä¸å‡è®¾æ•°æ®åˆ†å¸ƒ"
        ],
        "cons": [
            "â€¢ éœ€è¦æ‰‹åŠ¨è°ƒæ•´å‚æ•°ï¼ˆepså’Œmin_samplesï¼‰",
            "â€¢ åœ¨é«˜ç»´æ•°æ®ä¸­è¡¨ç°å¯èƒ½ä¸ä½³",
            "â€¢ å¯¹å¯†åº¦å·®å¼‚å¤§çš„æ•°æ®æ•æ„Ÿ"
        ],
        "params": ["eps", "min_samples"]
    },
    "IsolationForest": {
        "name": "å­¤ç«‹æ£®æ—",
        "description": "åŸºäºéšæœºæ£®æ—çš„å¼‚å¸¸ç‚¹æ£€æµ‹ç®—æ³•",
        "suitable_for": [
            "â€¢ é«˜ç»´æ•°æ®",
            "â€¢ å¤§å‹æ•°æ®é›†",
            "â€¢ å…¨å±€å¼‚å¸¸ç‚¹æ£€æµ‹",
            "â€¢ ä¸éœ€è¦æ ‡ç­¾çš„æ•°æ®"
        ],
        "pros": [
            "â€¢ è®¡ç®—æ•ˆç‡é«˜ï¼Œé€‚åˆå¤§æ•°æ®é›†",
            "â€¢ åœ¨é«˜ç»´æ•°æ®ä¸­è¡¨ç°è¾ƒå¥½",
            "â€¢ å‚æ•°å°‘ï¼Œæ˜“äºè°ƒä¼˜",
            "â€¢ èƒ½å¤Ÿå¿«é€Ÿè¯†åˆ«å…¨å±€å¼‚å¸¸ç‚¹"
        ],
        "cons": [
            "â€¢ å¯èƒ½å¿½ç•¥å±€éƒ¨å¼‚å¸¸ç‚¹",
            "â€¢ å¯¹æ ‘çš„æ•°é‡æ•æ„Ÿ",
            "â€¢ ä¸»è¦æ£€æµ‹å…¨å±€å¼‚å¸¸ï¼Œä¸æ“…é•¿å±€éƒ¨å¼‚å¸¸"
        ],
        "params": ["n_estimators", "contamination"]
    },
    "LOF": {
        "name": "å±€éƒ¨å¼‚å¸¸å› å­",
        "description": "åŸºäºå±€éƒ¨å¯†åº¦çš„å¼‚å¸¸ç‚¹æ£€æµ‹ç®—æ³•",
        "suitable_for": [
            "â€¢ å¯†åº¦å˜åŒ–çš„æ•°æ®",
            "â€¢ å±€éƒ¨å¼‚å¸¸ç‚¹æ£€æµ‹",
            "â€¢ ä¸­ç­‰è§„æ¨¡æ•°æ®é›†",
            "â€¢ éœ€è¦æ•æ‰å±€éƒ¨å¼‚å¸¸çš„åœºæ™¯"
        ],
        "pros": [
            "â€¢ èƒ½å¤Ÿæ£€æµ‹å±€éƒ¨å¼‚å¸¸ç‚¹",
            "â€¢ é€‚åˆå¯†åº¦ä¸å‡åŒ€çš„æ•°æ®",
            "â€¢ æä¾›å¼‚å¸¸ç¨‹åº¦è¯„åˆ†"
        ],
        "cons": [
            "â€¢ è®¡ç®—å¤æ‚åº¦è¾ƒé«˜ï¼Œä¸é€‚åˆå¤§æ•°æ®é›†",
            "â€¢ éœ€è¦è°ƒæ•´é‚»å±…æ•°é‡å‚æ•°",
            "â€¢ åœ¨é«˜ç»´æ•°æ®ä¸­å¯èƒ½è¡¨ç°ä¸ä½³"
        ],
        "params": ["n_neighbors", "contamination"]
    },
    "OneClassSVM": {
        "name": "å•ç±»æ”¯æŒå‘é‡æœº",
        "description": "åŸºäºæ”¯æŒå‘é‡æœºçš„å¼‚å¸¸ç‚¹æ£€æµ‹",
        "suitable_for": [
            "â€¢ å°åˆ°ä¸­ç­‰è§„æ¨¡æ•°æ®é›†",
            "â€¢ å¸Œæœ›æ‰¾åˆ°å†³ç­–è¾¹ç•Œçš„åœºæ™¯",
            "â€¢ å•ç±»åˆ†ç±»é—®é¢˜",
            "â€¢ ç‰¹å¾ç»´åº¦é€‚ä¸­çš„æ•°æ®"
        ],
        "pros": [
            "â€¢ ç†è®ºåŸºç¡€æ‰å®",
            "â€¢ èƒ½æ‰¾åˆ°æ¸…æ™°çš„å†³ç­–è¾¹ç•Œ",
            "â€¢ å‚æ•°ç›¸å¯¹è¾ƒå°‘"
        ],
        "cons": [
            "â€¢ è®¡ç®—å¤æ‚åº¦é«˜ï¼Œä¸é€‚åˆå¤§æ•°æ®é›†",
            "â€¢ å¯¹æ ¸å‡½æ•°é€‰æ‹©æ•æ„Ÿ",
            "â€¢ å†…å­˜éœ€æ±‚å¤§"
        ],
        "params": ["kernel", "nu", "gamma"]
    },
    "EllipticEnvelope": {
        "name": "æ¤­åœ†åŒ…ç»œ",
        "description": "å‡è®¾æ•°æ®æœä»å¤šå…ƒé«˜æ–¯åˆ†å¸ƒçš„å¼‚å¸¸ç‚¹æ£€æµ‹",
        "suitable_for": [
            "â€¢ æ•°æ®æ¥è¿‘æ­£æ€åˆ†å¸ƒ",
            "â€¢ ä¸­ç­‰è§„æ¨¡æ•°æ®é›†",
            "â€¢ è¿ç»­æ•°å€¼ç‰¹å¾",
            "â€¢ éœ€è¦å¿«é€Ÿæ£€æµ‹çš„åœºæ™¯"
        ],
        "pros": [
            "â€¢ è®¡ç®—é€Ÿåº¦å¿«",
            "â€¢ å‚æ•°å¾ˆå°‘",
            "â€¢ é€‚åˆé«˜æ–¯åˆ†å¸ƒæ•°æ®"
        ],
        "cons": [
            "â€¢ å‡è®¾æ•°æ®æœä»æ­£æ€åˆ†å¸ƒ",
            "â€¢ ä¸é€‚åˆéé«˜æ–¯åˆ†å¸ƒæ•°æ®",
            "â€¢ å¯¹å¼‚å¸¸ç‚¹éå¸¸æ•æ„Ÿ"
        ],
        "params": ["contamination", "support_fraction"]
    }
}


# --- Streamlit UI å‡½æ•° ---
def initialize_outlier_session_state():
    """åˆå§‹åŒ–å¼‚å¸¸ç‚¹æ£€æµ‹é¡µé¢çš„ä¼šè¯çŠ¶æ€"""
    defaults = {
        'outlier_data': None,
        'outlier_original_data_aligned': None,
        'outlier_column_names': [],
        'outlier_selected_features': [],
        'outlier_results': None,
        'outlier_algorithm': 'DBSCAN',
        'outlier_normalize': True,
        # DBSCANå‚æ•°
        'outlier_params_eps': 0.5,
        'outlier_params_min_samples': 5,
        # IsolationForestå‚æ•°
        'outlier_params_n_estimators': 100,
        'outlier_params_contamination': 0.05,
        # LOFå‚æ•°
        'outlier_params_n_neighbors': 20,
        'outlier_params_lof_contamination': 0.05,
        # OneClassSVMå‚æ•°
        'outlier_params_kernel': 'rbf',
        'outlier_params_nu': 0.05,
        'outlier_params_gamma': 'scale',
        # EllipticEnvelopeå‚æ•°
        'outlier_params_ee_contamination': 0.05,
        'outlier_params_support_fraction': None,
    }

    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


def show_outlier_detection_page():
    """æ˜¾ç¤ºå¼‚å¸¸ç‚¹æ£€æµ‹é¡µé¢"""
    initialize_outlier_session_state()

    st.title("ğŸ” å¼‚å¸¸ç‚¹æ£€æµ‹")

    # ä½¿ç”¨å›ºå®šå¸ƒå±€è€Œä¸æ˜¯expanderï¼Œé¿å…çŠ¶æ€ä¸¢å¤±
    st.markdown("## ğŸ“š ç®—æ³•é€‰æ‹©ä¸ä»‹ç»")

    # åˆ›å»ºç®—æ³•é€‰æ‹©å’Œä»‹ç»çš„å¸ƒå±€
    algo_col1, algo_col2 = st.columns([1, 2])

    with algo_col1:
        st.session_state.outlier_algorithm = st.selectbox(
            "é€‰æ‹©å¼‚å¸¸ç‚¹æ£€æµ‹ç®—æ³•",
            options=list(ALGORITHM_INFO.keys()),
            index=list(ALGORITHM_INFO.keys()).index(st.session_state.outlier_algorithm),
            key="outlier_algorithm_select"
        )

    with algo_col2:
        # æ˜¾ç¤ºç®—æ³•ä¿¡æ¯
        algo_info = ALGORITHM_INFO[st.session_state.outlier_algorithm]
        st.markdown(f"### {algo_info['name']} ç®—æ³•")
        st.markdown(f"**æè¿°**: {algo_info['description']}")

    # è¯¦ç»†ä»‹ç»ä½¿ç”¨å¯æŠ˜å çš„columns
    info_col1, info_col2 = st.columns(2)

    with info_col1:
        st.markdown("#### ğŸ¯ é€‚ç”¨åœºæ™¯")
        for item in algo_info['suitable_for']:
            st.markdown(item)

    with info_col2:
        st.markdown("#### âœ… ä¼˜ç‚¹")
        for item in algo_info['pros']:
            st.markdown(item)

        st.markdown("#### âŒ ç¼ºç‚¹")
        for item in algo_info['cons']:
            st.markdown(item)

    st.markdown("---")

    # åˆ›å»ºé€‰é¡¹å¡
    tab1, tab2, tab3 = st.tabs(["ğŸ“ æ•°æ®å¯¼å…¥", "âš™ï¸ å‚æ•°è®¾ç½®", "ğŸ“ˆ ç»“æœå±•ç¤º"])

    with tab1:
        create_outlier_data_import_section()

    with tab2:
        create_outlier_params_section()

    with tab3:
        create_outlier_results_section()


def create_outlier_data_import_section():
    """åˆ›å»ºæ•°æ®å¯¼å…¥å’Œç‰¹å¾é€‰æ‹©éƒ¨åˆ†"""
    st.header("1. æ•°æ®å¯¼å…¥ä¸ç‰¹å¾é€‰æ‹©")

    uploaded_file = st.file_uploader("ä¸Šä¼ åŒ…å«æ•°å€¼ç‰¹å¾çš„æ•°æ®æ–‡ä»¶ (CSV/Excel)",
                                     type=["csv", "xlsx", "xls"], key="outlier_uploader")

    if uploaded_file:
        if st.button("åŠ è½½æ•°æ®", key="outlier_load_btn"):
            with st.spinner("æ­£åœ¨åŠ è½½å’Œå¤„ç†æ•°æ®..."):
                try:
                    # åŠ è½½åŸå§‹æ•°æ®
                    data_original = pd.read_csv(uploaded_file) if uploaded_file.name.lower().endswith(
                        '.csv') else pd.read_excel(uploaded_file)

                    # é€‰æ‹©æ•°å€¼åˆ—
                    numeric_cols = data_original.select_dtypes(include=np.number).columns.tolist()
                    if not numeric_cols:
                        st.error("ä¸Šä¼ çš„æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æ•°å€¼åˆ—ã€‚")
                        st.session_state.outlier_data = None
                        st.session_state.outlier_original_data_aligned = None
                        return

                    # ä»æ•°å€¼åˆ—ä¸­ç§»é™¤åŒ…å«NaNçš„è¡Œ
                    initial_rows = len(data_original)
                    data_numeric_raw = data_original[numeric_cols].copy()
                    data_numeric = data_numeric_raw.dropna()
                    cleaned_rows = len(data_numeric)

                    if cleaned_rows < initial_rows:
                        st.warning(f"ç§»é™¤äº† {initial_rows - cleaned_rows} è¡Œåœ¨æ•°å€¼åˆ—ä¸­åŒ…å«ç¼ºå¤±å€¼çš„æ•°æ®ã€‚")

                    if data_numeric.empty:
                        st.error("å¤„ç†ç¼ºå¤±å€¼åæ•°æ®ä¸ºç©ºã€‚")
                        st.session_state.outlier_data = None
                        st.session_state.outlier_original_data_aligned = None
                        return

                    # å­˜å‚¨æ¸…ç†åçš„æ•°å€¼æ•°æ®å’Œå¯¹åº”çš„åŸå§‹æ•°æ®
                    st.session_state.outlier_data = data_numeric
                    st.session_state.outlier_original_data_aligned = data_original.loc[data_numeric.index]
                    st.session_state.outlier_column_names = list(data_numeric.columns)
                    st.session_state.outlier_selected_features = list(data_numeric.columns)
                    st.session_state.outlier_results = None
                    st.success(f"æˆåŠŸåŠ è½½å¹¶å¤„ç†æ•°æ®: {cleaned_rows} è¡Œæœ‰æ•ˆæ•°å€¼æ•°æ®ã€‚")

                except Exception as e:
                    st.error(f"åŠ è½½æˆ–å¤„ç†æ•°æ®æ—¶å‡ºé”™: {e}")
                    st.session_state.outlier_data = None
                    st.session_state.outlier_original_data_aligned = None

    # æ•°æ®é¢„è§ˆå’Œç‰¹å¾é€‰æ‹©
    if st.session_state.outlier_data is not None:
        st.subheader("æ•°æ®é¢„è§ˆ (æ•°å€¼åˆ— - æ¸…ç†å)")
        st.dataframe(st.session_state.outlier_data.head())

        st.subheader("ç‰¹å¾é€‰æ‹©")
        available_cols = st.session_state.outlier_column_names
        default_selection = [col for col in st.session_state.outlier_selected_features if col in available_cols]
        if not default_selection and available_cols:
            default_selection = available_cols

        st.session_state.outlier_selected_features = st.multiselect(
            "é€‰æ‹©ç”¨äºå¼‚å¸¸ç‚¹æ£€æµ‹çš„ç‰¹å¾åˆ—",
            available_cols,
            default=default_selection,
            key="outlier_feature_select"
        )

        if not st.session_state.outlier_selected_features:
            st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾åˆ—ã€‚")
        else:
            st.info(f"å·²é€‰æ‹© {len(st.session_state.outlier_selected_features)} ä¸ªç‰¹å¾ã€‚")


def create_outlier_params_section():
    """åˆ›å»ºå‚æ•°è®¾ç½®éƒ¨åˆ†"""
    st.header("2. å‚æ•°è®¾ç½®")

    if st.session_state.outlier_data is None:
        st.info("è¯·å…ˆåœ¨æ•°æ®å¯¼å…¥é€‰é¡¹å¡ä¸­åŠ è½½æ•°æ®ã€‚")
        return
    if not st.session_state.outlier_selected_features:
        st.warning("è¯·å…ˆåœ¨æ•°æ®å¯¼å…¥é€‰é¡¹å¡ä¸­é€‰æ‹©ç‰¹å¾åˆ—ã€‚")
        return

    # é¢„å¤„ç†é€‰é¡¹
    st.subheader("é¢„å¤„ç†")
    st.session_state.outlier_normalize = st.checkbox(
        "æ ‡å‡†åŒ–ç‰¹å¾ (æ¨è)",
        value=st.session_state.outlier_normalize,
        key="outlier_norm_cb"
    )

    # ç®—æ³•ç‰¹å®šå‚æ•°
    st.subheader(f"{st.session_state.outlier_algorithm} ç®—æ³•å‚æ•°")

    if st.session_state.outlier_algorithm == "DBSCAN":
        create_dbscan_params()
    elif st.session_state.outlier_algorithm == "IsolationForest":
        create_isolation_forest_params()
    elif st.session_state.outlier_algorithm == "LOF":
        create_lof_params()
    elif st.session_state.outlier_algorithm == "OneClassSVM":
        create_one_class_svm_params()
    elif st.session_state.outlier_algorithm == "EllipticEnvelope":
        create_elliptic_envelope_params()

    # è¿è¡ŒæŒ‰é’®
    can_run = st.session_state.outlier_data is not None and st.session_state.outlier_selected_features
    if st.button(f"è¿è¡Œ {st.session_state.outlier_algorithm} æ£€æµ‹å¼‚å¸¸ç‚¹",
                 type="primary", key="run_outlier_btn", disabled=not can_run):
        run_outlier_detection()


def create_dbscan_params():
    """åˆ›å»ºDBSCANå‚æ•°è®¾ç½®"""
    st.markdown("""
    - **Epsilon (eps)**: å®šä¹‰ä¸€ä¸ªç‚¹çš„é‚»åŸŸåŠå¾„ã€‚å€¼è¶Šå°ï¼Œè¦æ±‚çš„å¯†åº¦è¶Šé«˜ã€‚
    - **Min Samples**: å®šä¹‰ä¸€ä¸ªæ ¸å¿ƒç‚¹æ‰€éœ€çš„é‚»åŸŸå†…æœ€å°æ ·æœ¬æ•°ï¼ˆåŒ…æ‹¬è‡ªèº«ï¼‰ã€‚
    """)

    col1, col2 = st.columns(2)
    with col1:
        st.session_state.outlier_params_eps = st.number_input(
            "Epsilon (eps)", min_value=0.01, max_value=10.0,
            value=st.session_state.outlier_params_eps, step=0.05, format="%.2f",
            key="outlier_eps_input", help="é‚»åŸŸåŠå¾„ï¼Œå½±å“å¯†åº¦è¦æ±‚"
        )
    with col2:
        st.session_state.outlier_params_min_samples = st.number_input(
            "Min Samples", min_value=2, max_value=100,
            value=st.session_state.outlier_params_min_samples, step=1,
            key="outlier_minsamples_input", help="æ ¸å¿ƒç‚¹æ‰€éœ€çš„æœ€å°é‚»åŸŸæ ·æœ¬æ•°"
        )


def create_isolation_forest_params():
    """åˆ›å»ºIsolation Forestå‚æ•°è®¾ç½®"""
    st.markdown("""
    - **n_estimators**: æ„å»ºçš„æ ‘çš„æ•°é‡ã€‚é€šå¸¸å€¼è¶Šå¤§ï¼Œæ€§èƒ½è¶Šå¥½ï¼Œä½†è®¡ç®—æˆæœ¬ä¹Ÿè¶Šé«˜ã€‚
    - **contamination**: æ•°æ®é›†ä¸­å¼‚å¸¸ç‚¹çš„é¢„æœŸæ¯”ä¾‹ã€‚
    """)

    col1, col2 = st.columns(2)
    with col1:
        st.session_state.outlier_params_n_estimators = st.number_input(
            "æ ‘çš„æ•°é‡ (n_estimators)", min_value=10, max_value=1000,
            value=st.session_state.outlier_params_n_estimators, step=10,
            key="outlier_n_estimators_input", help="æ„å»ºçš„å†³ç­–æ ‘æ•°é‡"
        )
    with col2:
        st.session_state.outlier_params_contamination = st.number_input(
            "å¼‚å¸¸ç‚¹æ¯”ä¾‹ (contamination)", min_value=0.001, max_value=0.5,
            value=st.session_state.outlier_params_contamination, step=0.001, format="%.3f",
            key="outlier_contamination_input", help="é¢„æœŸçš„å¼‚å¸¸ç‚¹å æ¯”"
        )


def create_lof_params():
    """åˆ›å»ºLOFå‚æ•°è®¾ç½®"""
    st.markdown("""
    - **n_neighbors**: è®¡ç®—å±€éƒ¨å¯†åº¦ä½¿ç”¨çš„é‚»å±…æ•°é‡ã€‚
    - **contamination**: é¢„æœŸçš„å¼‚å¸¸ç‚¹æ¯”ä¾‹ã€‚
    """)

    col1, col2 = st.columns(2)
    with col1:
        st.session_state.outlier_params_n_neighbors = st.number_input(
            "é‚»å±…æ•°é‡ (n_neighbors)", min_value=2, max_value=100,
            value=st.session_state.outlier_params_n_neighbors, step=1,
            key="outlier_n_neighbors_input", help="è®¡ç®—å¯†åº¦æ—¶è€ƒè™‘çš„é‚»å±…æ•°é‡"
        )
    with col2:
        st.session_state.outlier_params_lof_contamination = st.number_input(
            "å¼‚å¸¸ç‚¹æ¯”ä¾‹ (contamination)", min_value=0.001, max_value=0.5,
            value=st.session_state.outlier_params_lof_contamination, step=0.001, format="%.3f",
            key="outlier_lof_contamination_input", help="é¢„æœŸçš„å¼‚å¸¸ç‚¹å æ¯”"
        )


def create_one_class_svm_params():
    """åˆ›å»ºOne-Class SVMå‚æ•°è®¾ç½®"""
    st.markdown("""
    - **kernel**: æ ¸å‡½æ•°ç±»å‹ã€‚
    - **nu**: å†³ç­–è¾¹ç•Œé”™è¯¯ç‡çš„ä¸Šç•Œã€‚
    - **gamma**: æ ¸å‡½æ•°çš„ç³»æ•°ï¼ˆä»…ç”¨äºrbfã€polyã€sigmoidæ ¸ï¼‰ã€‚
    """)

    col1, col2, col3 = st.columns(3)
    with col1:
        st.session_state.outlier_params_kernel = st.selectbox(
            "æ ¸å‡½æ•° (kernel)", options=['rbf', 'linear', 'poly', 'sigmoid'],
            index=['rbf', 'linear', 'poly', 'sigmoid'].index(st.session_state.outlier_params_kernel),
            key="outlier_kernel_select", help="é€‰æ‹©æ ¸å‡½æ•°ç±»å‹"
        )
    with col2:
        st.session_state.outlier_params_nu = st.number_input(
            "Nu", min_value=0.001, max_value=1.0,
            value=st.session_state.outlier_params_nu, step=0.001, format="%.3f",
            key="outlier_nu_input", help="å†³ç­–è¾¹ç•Œé”™è¯¯ç‡ä¸Šç•Œ"
        )
    with col3:
        st.session_state.outlier_params_gamma = st.selectbox(
            "Gamma", options=['scale', 'auto'],
            index=['scale', 'auto'].index(st.session_state.outlier_params_gamma),
            key="outlier_gamma_select", help="æ ¸å‡½æ•°ç³»æ•°"
        )


def create_elliptic_envelope_params():
    """åˆ›å»ºElliptic Envelopeå‚æ•°è®¾ç½®"""
    st.markdown("""
    - **contamination**: é¢„æœŸçš„å¼‚å¸¸ç‚¹æ¯”ä¾‹ã€‚
    - **support_fraction**: ç”¨äºè®¡ç®—ç»éªŒåæ–¹å·®çš„ç‚¹çš„æ¯”ä¾‹ï¼ˆNone=autoï¼‰ã€‚
    """)

    col1, col2 = st.columns(2)
    with col1:
        st.session_state.outlier_params_ee_contamination = st.number_input(
            "å¼‚å¸¸ç‚¹æ¯”ä¾‹ (contamination)", min_value=0.001, max_value=0.5,
            value=st.session_state.outlier_params_ee_contamination, step=0.001, format="%.3f",
            key="outlier_ee_contamination_input", help="é¢„æœŸçš„å¼‚å¸¸ç‚¹å æ¯”"
        )
    with col2:
        support_fraction_val = st.session_state.outlier_params_support_fraction
        display_value = 1.0 if support_fraction_val is None else support_fraction_val

        st.session_state.outlier_params_support_fraction = st.number_input(
            "æ”¯æŒåˆ†æ•° (support_fraction)", min_value=0.001, max_value=1.0,
            value=display_value, step=0.001, format="%.3f",
            key="outlier_support_fraction_input", help="ç”¨äºè®¡ç®—åæ–¹å·®çš„ç‚¹çš„æ¯”ä¾‹"
        )

        if st.session_state.outlier_params_support_fraction >= 0.999:
            st.session_state.outlier_params_support_fraction = None


def run_outlier_detection():
    """æ‰§è¡Œå¼‚å¸¸ç‚¹æ£€æµ‹"""
    if st.session_state.outlier_data is None or not st.session_state.outlier_selected_features:
        st.error("è¯·å…ˆåŠ è½½æ•°æ®å¹¶é€‰æ‹©ç‰¹å¾ã€‚")
        return

    X = st.session_state.outlier_data[st.session_state.outlier_selected_features].copy()
    if X.empty:
        st.error("é€‰æ‹©çš„ç‰¹å¾æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿è¡Œæ£€æµ‹ã€‚")
        return

    processed_index = X.index.copy()

    with st.spinner(f"æ­£åœ¨è¿è¡Œ {st.session_state.outlier_algorithm}..."):
        try:
            # æ ‡å‡†åŒ–
            X_processed_np = X.values
            if st.session_state.outlier_normalize:
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X)
                X_processed_np = X_scaled
                print("æ•°æ®å·²æ ‡å‡†åŒ–ã€‚")
            else:
                print("æ•°æ®æœªæ ‡å‡†åŒ–ã€‚")

            # æ ¹æ®ç®—æ³•æ‰§è¡Œæ£€æµ‹
            if st.session_state.outlier_algorithm == "DBSCAN":
                labels = run_dbscan(X_processed_np)
            elif st.session_state.outlier_algorithm == "IsolationForest":
                labels = run_isolation_forest(X_processed_np)
            elif st.session_state.outlier_algorithm == "LOF":
                labels = run_lof(X_processed_np)
            elif st.session_state.outlier_algorithm == "OneClassSVM":
                labels = run_one_class_svm(X_processed_np)
            elif st.session_state.outlier_algorithm == "EllipticEnvelope":
                labels = run_elliptic_envelope(X_processed_np)
            else:
                st.error(f"æœªå®ç°çš„ç®—æ³•: {st.session_state.outlier_algorithm}")
                return

            # ä¿å­˜ç»“æœ
            st.session_state.outlier_results = {
                'labels': labels,
                'processed_index': processed_index,
                'X_processed_for_plot': X_processed_np,
                'algorithm': st.session_state.outlier_algorithm
            }
            st.success(f"{st.session_state.outlier_algorithm} è¿è¡Œå®Œæˆï¼è¯·æŸ¥çœ‹ç»“æœå±•ç¤ºã€‚")

        except Exception as e:
            st.error(f"è¿è¡Œ {st.session_state.outlier_algorithm} æ—¶å‡ºé”™: {e}")
            import traceback
            st.code(traceback.format_exc())
            st.session_state.outlier_results = None


def run_dbscan(X):
    """è¿è¡ŒDBSCANç®—æ³•"""
    dbscan = DBSCAN(
        eps=st.session_state.outlier_params_eps,
        min_samples=st.session_state.outlier_params_min_samples,
        n_jobs=-1
    )
    return dbscan.fit_predict(X)


def run_isolation_forest(X):
    """è¿è¡ŒIsolation Forestç®—æ³•"""
    iso_forest = IsolationForest(
        n_estimators=st.session_state.outlier_params_n_estimators,
        contamination=st.session_state.outlier_params_contamination,
        random_state=42,
        n_jobs=-1
    )
    # Isolation Forestè¿”å›1ä¸ºæ­£å¸¸ç‚¹ï¼Œ-1ä¸ºå¼‚å¸¸ç‚¹
    return iso_forest.fit_predict(X)


def run_lof(X):
    """è¿è¡ŒLocal Outlier Factorç®—æ³•"""
    lof = LocalOutlierFactor(
        n_neighbors=st.session_state.outlier_params_n_neighbors,
        contamination=st.session_state.outlier_params_lof_contamination,
        n_jobs=-1
    )
    # LOFè¿”å›1ä¸ºæ­£å¸¸ç‚¹ï¼Œ-1ä¸ºå¼‚å¸¸ç‚¹
    return lof.fit_predict(X)


def run_one_class_svm(X):
    """è¿è¡ŒOne-Class SVMç®—æ³•"""
    svm = OneClassSVM(
        kernel=st.session_state.outlier_params_kernel,
        nu=st.session_state.outlier_params_nu,
        gamma=st.session_state.outlier_params_gamma
    )
    # One-Class SVMè¿”å›1ä¸ºæ­£å¸¸ç‚¹ï¼Œ-1ä¸ºå¼‚å¸¸ç‚¹
    return svm.fit_predict(X)


def run_elliptic_envelope(X):
    """è¿è¡ŒElliptic Envelopeç®—æ³•"""
    elliptic = EllipticEnvelope(
        contamination=st.session_state.outlier_params_ee_contamination,
        support_fraction=st.session_state.outlier_params_support_fraction,
        assume_centered=False
    )
    # Elliptic Envelopeè¿”å›1ä¸ºæ­£å¸¸ç‚¹ï¼Œ-1ä¸ºå¼‚å¸¸ç‚¹
    return elliptic.fit_predict(X)


def create_outlier_results_section():
    """åˆ›å»ºç»“æœå±•ç¤ºéƒ¨åˆ†"""
    st.header("3. ç»“æœå±•ç¤º")

    results = st.session_state.get('outlier_results')
    original_data_aligned = st.session_state.get('outlier_original_data_aligned')

    if results is None or original_data_aligned is None:
        st.info("è¯·å…ˆè¿è¡Œå¼‚å¸¸ç‚¹æ£€æµ‹ã€‚")
        return

    labels = results['labels']
    processed_index = results['processed_index']
    X_processed_for_plot = results['X_processed_for_plot']
    algorithm = results.get('algorithm', st.session_state.outlier_algorithm)

    # è®¡ç®—å¼‚å¸¸ç‚¹ç»Ÿè®¡
    outlier_mask = (labels == -1)
    n_outliers = np.sum(outlier_mask)
    n_total = len(labels)
    outlier_percentage = (n_outliers / n_total) * 100 if n_total > 0 else 0

    # å¯¹äºDBSCANï¼Œè®¡ç®—ç°‡çš„æ•°é‡
    if algorithm == "DBSCAN":
        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
    else:
        n_clusters = None

    # æ‘˜è¦ä¿¡æ¯
    st.subheader("æ£€æµ‹ç»“æœæ‘˜è¦")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("å¤„ç†çš„æ€»æ ·æœ¬æ•°", n_total)
    with col2:
        st.metric("æ£€æµ‹åˆ°çš„å¼‚å¸¸ç‚¹æ•°", n_outliers,
                  delta=f"{outlier_percentage:.2f}%", delta_color="inverse")
    with col3:
        if n_clusters is not None:
            st.metric("æ£€æµ‹åˆ°çš„æœ‰æ•ˆèšç±»æ•°", n_clusters)
        else:
            st.metric("æ£€æµ‹ç®—æ³•", algorithm)

    # å¼‚å¸¸ç‚¹æ•°æ®å±•ç¤º
    st.subheader("å¼‚å¸¸ç‚¹æ•°æ® (åŸå§‹è¡Œ)")
    outlier_indices_in_original = processed_index[outlier_mask]
    outlier_data_original_order = original_data_aligned.loc[outlier_indices_in_original].copy()

    if not outlier_data_original_order.empty:
        st.dataframe(outlier_data_original_order.head(10))

        # ä¸‹è½½æŒ‰é’®
        csv_link = get_download_link(
            outlier_data_original_order,
            f"outlier_data_{algorithm}_{datetime.datetime.now().strftime('%Y%m%d%H%M')}.csv",
            "ä¸‹è½½å¼‚å¸¸ç‚¹æ•°æ® (CSV)"
        )
        st.markdown(csv_link, unsafe_allow_html=True)
    else:
        st.info("æœªæ£€æµ‹åˆ°å¼‚å¸¸ç‚¹ã€‚")

    # å¯è§†åŒ–
    st.subheader("å¯è§†åŒ–")
    plot_data_df = original_data_aligned.loc[processed_index, st.session_state.outlier_selected_features]

    if plot_data_df.empty:
        st.warning("æ²¡æœ‰å¯ç”¨äºå¯è§†åŒ–çš„æ•°æ®ã€‚")
    else:
        fig = plot_outliers_2d(plot_data_df, labels, method_name=algorithm)
        st.pyplot(fig)

        # å›¾è¡¨ä¸‹è½½
        try:
            buffered = BytesIO()
            fig.savefig(buffered, format="png", dpi=100, bbox_inches='tight')
            img_str = base64.b64encode(buffered.getvalue()).decode()
            plt.close(fig)
            img_filename = f"outlier_visualization_{algorithm}_{datetime.datetime.now().strftime('%Y%m%d%H%M')}.png"
            href = f'<a href="data:image/png;base64,{img_str}" download="{img_filename}">ä¸‹è½½å¯è§†åŒ–å›¾è¡¨</a>'
            st.markdown(href, unsafe_allow_html=True)
        except Exception as download_e:
            st.error(f"ç”Ÿæˆå›¾è¡¨ä¸‹è½½é“¾æ¥æ—¶å‡ºé”™: {download_e}")


# --- ä¸»å‡½æ•°å…¥å£ (ç”¨äºç‹¬ç«‹æµ‹è¯•) ---
if __name__ == "__main__":
    st.set_page_config(page_title="å¼‚å¸¸ç‚¹æ£€æµ‹", layout="wide")
    show_outlier_detection_page()