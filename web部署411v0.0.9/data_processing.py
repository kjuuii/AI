# -*- coding: utf-8 -*-
"""
Data Processing Module for Streamlit App
Includes Data Visualization and Segmentation functionalities.
Allows direct data upload within the module.
"""
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import traceback
import io # For download link

# --- å°è¯•å¯¼å…¥å­—ä½“å·¥å…· ---
try:
    from font_utils import apply_plot_style, FONT_PROP, create_figure_with_safe_dimensions
    print("å­—ä½“å·¥å…·ä» font_utils æˆåŠŸåŠ è½½ (in data_processing)")
except ImportError:
    print("è­¦å‘Š: æ— æ³•ä» font_utils å¯¼å…¥ï¼Œå°†åœ¨ data_processing ä¸­ä½¿ç”¨å¤‡ç”¨ç»˜å›¾è®¾ç½®ã€‚")
    FONT_PROP = None
    def apply_plot_style(ax):
        ax.grid(True, linestyle='--', alpha=0.6)
        return ax
    def create_figure_with_safe_dimensions(w, h, dpi=80):
        fig, ax = plt.subplots(figsize=(w, h), dpi=dpi)
        return fig, ax
# --- ç»“æŸå­—ä½“å¯¼å…¥ ---

# --- çŠ¶æ€åˆå§‹åŒ– ---
def initialize_processing_state():
    """Initialize session state variables specific to data processing."""
    defaults = {
        'dp_uploaded_data': None,   # Data uploaded specifically in this module
        'dp_active_data': None,     # The dataframe currently being processed (uploaded or from main app)
        'dp_active_data_source': None, # 'uploaded' or 'main_app' or None
        'dp_selected_vis_col': None,
        'dp_plot_type': 'Histogram',
        'dp_segment_col': None,
        'dp_segment_value': None,
        'dp_segment_mode': 'value',
        'dp_segment_min': None,
        'dp_segment_max': None,
        'dp_segment_results': None,
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

# --- ç»˜å›¾å‡½æ•° (ä¿æŒä¸å˜) ---
def plot_selected_visualization(df, column, plot_type):
    """Generates the selected plot for the specified column."""
    if df is None or column not in df.columns:
        st.warning("è¯·é€‰æ‹©æœ‰æ•ˆçš„æ•°æ®åˆ—è¿›è¡Œå¯è§†åŒ–ã€‚")
        return None

    fig, ax = create_figure_with_safe_dimensions(8, 5)
    font_kwargs = {'fontproperties': FONT_PROP} if FONT_PROP else {}

    try:
        data_to_plot = df[column].dropna() # Drop NaNs for plotting

        if data_to_plot.empty:
            st.warning(f"åˆ— '{column}' æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯ä¾›ç»˜åˆ¶ã€‚")
            plt.close(fig)
            return None

        if plot_type == 'Histogram':
            if pd.api.types.is_numeric_dtype(data_to_plot):
                sns.histplot(data_to_plot, kde=True, ax=ax)
                ax.set_title(f"'{column}' çš„ç›´æ–¹å›¾åˆ†å¸ƒ", **font_kwargs)
            else:
                st.warning("ç›´æ–¹å›¾ä»…é€‚ç”¨äºæ•°å€¼å‹æ•°æ®ã€‚è¯·å°è¯•æ¡å½¢å›¾ã€‚")
                plt.close(fig)
                return None
        elif plot_type == 'Box Plot':
            if pd.api.types.is_numeric_dtype(data_to_plot):
                sns.boxplot(y=data_to_plot, ax=ax)
                ax.set_title(f"'{column}' çš„ç®±çº¿å›¾", **font_kwargs)
                ax.set_ylabel(column, **font_kwargs) # Set y-axis label
                ax.tick_params(axis='x', bottom=False, labelbottom=False) # Hide x-axis ticks/labels
            else:
                st.warning("ç®±çº¿å›¾ä»…é€‚ç”¨äºæ•°å€¼å‹æ•°æ®ã€‚")
                plt.close(fig)
                return None
        elif plot_type == 'Bar Chart':
            # Suitable for categorical or low-cardinality numeric
            if data_to_plot.nunique() <= 50: # Limit cardinality for bar charts
                counts = data_to_plot.value_counts().nlargest(30) # Show top 30 categories
                sns.barplot(x=counts.index.astype(str), y=counts.values, ax=ax, palette="viridis")
                ax.set_title(f"'{column}' çš„é¢‘ç‡æ¡å½¢å›¾ (Top {len(counts)})", **font_kwargs)
                ax.tick_params(axis='x', rotation=45, labelsize=8)
            else:
                st.warning("æ¡å½¢å›¾é€‚ç”¨äºç±»åˆ«å‹æˆ–ä½åŸºæ•°æ•°å€¼å‹æ•°æ® (æœ€å¤š50ä¸ªå”¯ä¸€å€¼)ã€‚")
                plt.close(fig)
                return None
        else:
            st.error(f"æœªçŸ¥çš„ç»˜å›¾ç±»å‹: {plot_type}")
            plt.close(fig)
            return None

        apply_plot_style(ax)
        plt.tight_layout()
        return fig

    except Exception as e:
        st.error(f"ç»˜åˆ¶å›¾è¡¨æ—¶å‡ºé”™: {e}")
        print(traceback.format_exc())
        plt.close(fig) # Ensure figure is closed on error
        return None

# --- æ•°æ®åˆ†å‰²å‡½æ•° (ä¿æŒä¸å˜) ---
def segment_data(df, column, mode, value=None, min_val=None, max_val=None):
    """Segments the dataframe based on the selected column and criteria."""
    if df is None or column not in df.columns:
        st.error("æ— æ•ˆçš„æ•°æ®æˆ–åˆ—ç”¨äºåˆ†å‰²ã€‚")
        return None

    try:
        if mode == 'value':
            if value is None or value == "": # Check for empty string too
                st.error("è¯·ä¸º'æŒ‰å€¼åˆ†å‰²'æ¨¡å¼è¾“å…¥ä¸€ä¸ªå€¼ã€‚")
                return None
            # Attempt to convert value to column type if possible
            try:
                col_type = df[column].dtype
                if pd.api.types.is_numeric_dtype(col_type):
                    # Handle potential commas or other non-numeric chars if input is string
                    if isinstance(value, str): value = value.replace(',', '')
                    value_typed = pd.to_numeric(value)
                elif pd.api.types.is_datetime64_any_dtype(col_type):
                     value_typed = pd.to_datetime(value)
                elif pd.api.types.is_bool_dtype(col_type):
                     # Handle boolean conversion carefully
                     if str(value).lower() in ['true', '1', 'yes', 't']: value_typed = True
                     elif str(value).lower() in ['false', '0', 'no', 'f']: value_typed = False
                     else: raise ValueError("æ— æ³•è½¬æ¢ä¸ºå¸ƒå°”å€¼")
                else: # Treat as string otherwise
                     value_typed = str(value)
            except (ValueError, TypeError) as conv_err:
                st.error(f"æ— æ³•å°†è¾“å…¥å€¼ '{value}' è½¬æ¢ä¸ºåˆ— '{column}' çš„ç±»å‹ ({col_type}): {conv_err}")
                return None

            segment1 = df[df[column] == value_typed].copy()
            segment2 = df[df[column] != value_typed].copy()
            desc1 = f"ç­‰äº {value}"
            desc2 = f"ä¸ç­‰äº {value}"

        elif mode == 'range':
            if min_val is None or max_val is None or min_val == "" or max_val == "": # Check empty
                st.error("è¯·ä¸º'æŒ‰èŒƒå›´åˆ†å‰²'æ¨¡å¼è¾“å…¥æœ€å°å€¼å’Œæœ€å¤§å€¼ã€‚")
                return None
            # Attempt to convert range values
            try:
                col_type = df[column].dtype
                if not pd.api.types.is_numeric_dtype(col_type) and not pd.api.types.is_datetime64_any_dtype(col_type):
                    st.error("èŒƒå›´åˆ†å‰²ä»…é€‚ç”¨äºæ•°å€¼æˆ–æ—¥æœŸæ—¶é—´ç±»å‹åˆ—ã€‚")
                    return None
                if pd.api.types.is_numeric_dtype(col_type):
                    # Handle potential commas
                    if isinstance(min_val, str): min_val = min_val.replace(',', '')
                    if isinstance(max_val, str): max_val = max_val.replace(',', '')
                    min_typed = pd.to_numeric(min_val)
                    max_typed = pd.to_numeric(max_val)
                else: # Datetime
                    min_typed = pd.to_datetime(min_val)
                    max_typed = pd.to_datetime(max_val)

                if min_typed >= max_typed:
                     st.error("èŒƒå›´åˆ†å‰²çš„æœ€å°å€¼å¿…é¡»å°äºæœ€å¤§å€¼ã€‚")
                     return None

            except (ValueError, TypeError) as conv_err:
                st.error(f"æ— æ³•å°†è¾“å…¥èŒƒå›´å€¼ '{min_val}', '{max_val}' è½¬æ¢ä¸ºåˆ— '{column}' çš„ç±»å‹ ({col_type}): {conv_err}")
                return None

            segment1 = df[(df[column] >= min_typed) & (df[column] < max_typed)].copy()
            segment2 = df[(df[column] < min_typed) | (df[column] >= max_typed)].copy()
            desc1 = f"åœ¨ [{min_val}, {max_val}) èŒƒå›´å†…"
            desc2 = f"ä¸åœ¨ [{min_val}, {max_val}) èŒƒå›´å†…"

        else:
            st.error(f"æœªçŸ¥çš„åˆ†å‰²æ¨¡å¼: {mode}")
            return None

        return {
            'segment1': {'df': segment1, 'desc': desc1},
            'segment2': {'df': segment2, 'desc': desc2}
        }

    except Exception as e:
        st.error(f"æ•°æ®åˆ†å‰²æ—¶å‡ºé”™: {e}")
        print(traceback.format_exc())
        return None

# --- ä¸» UI å‡½æ•° ---
def show_data_processing_page():
    """Displays the Data Processing page UI."""
    initialize_processing_state()
    st.title("ğŸ”§ æ•°æ®å¤„ç†ä¸å¯è§†åŒ–")
    st.markdown("---")

    # --- æ•°æ®æºé€‰æ‹©ä¸ä¸Šä¼  ---
    st.header("1. æ•°æ®æº")

    # Option to use data from other modules OR upload new data
    data_source_option = st.radio(
        "é€‰æ‹©æ•°æ®æ¥æº:",
        ["ä½¿ç”¨ä¸»åº”ç”¨å·²åŠ è½½æ•°æ®", "åœ¨æ­¤å¤„ä¸Šä¼ æ–°æ•°æ®"],
        key="dp_data_source_radio",
        horizontal=True
    )

    df_to_process = None
    source_description = ""
    all_columns = []

    if data_source_option == "åœ¨æ­¤å¤„ä¸Šä¼ æ–°æ•°æ®":
        uploaded_file_dp = st.file_uploader(
            "ä¸Šä¼ ç”¨äºå¤„ç†çš„ CSV æˆ– Excel æ–‡ä»¶",
            type=["csv", "xlsx", "xls"],
            key="dp_file_uploader"
        )
        if uploaded_file_dp:
            # Check if it's a new upload or the same file
            # This simple check might not be perfect but helps avoid reloading unnecessarily
            if 'dp_last_uploaded_name' not in st.session_state or st.session_state.dp_last_uploaded_name != uploaded_file_dp.name:
                with st.spinner("åŠ è½½ä¸Šä¼ çš„æ•°æ®..."):
                    try:
                        data = pd.read_csv(uploaded_file_dp) if uploaded_file_dp.name.lower().endswith('.csv') else pd.read_excel(uploaded_file_dp)
                        data.dropna(axis=1, how='all', inplace=True)
                        if data.empty:
                            st.error("ä¸Šä¼ çš„æ–‡ä»¶ä¸ºç©ºã€‚")
                            st.session_state.dp_uploaded_data = None
                        else:
                            st.session_state.dp_uploaded_data = data
                            st.session_state.dp_last_uploaded_name = uploaded_file_dp.name
                            # Reset selections when new data is uploaded
                            st.session_state.dp_selected_vis_col = None
                            st.session_state.dp_segment_col = None
                            st.session_state.dp_segment_results = None
                            st.success(f"å·²åŠ è½½ä¸Šä¼ æ–‡ä»¶: {uploaded_file_dp.name}")
                    except Exception as e:
                        st.error(f"åŠ è½½ä¸Šä¼ æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                        st.session_state.dp_uploaded_data = None

            # Use the uploaded data if available
            if st.session_state.dp_uploaded_data is not None:
                df_to_process = st.session_state.dp_uploaded_data
                st.session_state.dp_active_data = df_to_process
                st.session_state.dp_active_data_source = 'uploaded'
                source_description = f"æ¥æº: ä¸Šä¼ çš„æ–‡ä»¶ ({uploaded_file_dp.name})"
                all_columns = df_to_process.columns.tolist()

    else: # Use data from main app
        # Clear uploaded data state if switching back
        st.session_state.dp_uploaded_data = None
        if 'dp_last_uploaded_name' in st.session_state: del st.session_state.dp_last_uploaded_name

        # Find data loaded in other modules (adjust keys as needed)
        data_key_found = None
        potential_keys = ['classification_data', 'regression_data', 'clustering_data', 'mv_data', 'db_data', 'outlier_data', 'de_data'] # Add more keys if needed
        for key in potential_keys:
            if key in st.session_state and st.session_state[key] is not None:
                loaded_data = st.session_state[key]
                # Handle both DataFrame and dict cases
                if isinstance(loaded_data, pd.DataFrame):
                    df_to_process = loaded_data
                    data_key_found = key
                    break
                elif isinstance(loaded_data, dict) and 'X' in loaded_data and isinstance(loaded_data['X'], pd.DataFrame):
                    df_temp = loaded_data['X'].copy()
                    if 'y' in loaded_data and isinstance(loaded_data['y'], pd.Series):
                         df_temp[loaded_data['y'].name] = loaded_data['y']
                    if 'groups' in loaded_data and isinstance(loaded_data['groups'], pd.Series):
                         df_temp[loaded_data['groups'].name] = loaded_data['groups']
                    df_to_process = df_temp
                    data_key_found = key
                    break

        if df_to_process is not None:
            st.session_state.dp_active_data = df_to_process
            st.session_state.dp_active_data_source = 'main_app'
            source_description = f"æ¥æº: ä¸»åº”ç”¨æ•°æ® (æ¥è‡ª '{data_key_found}')"
            all_columns = df_to_process.columns.tolist()
        else:
            st.session_state.dp_active_data = None
            st.session_state.dp_active_data_source = None
            st.warning("ä¸»åº”ç”¨ä¸­æ²¡æœ‰æ‰¾åˆ°å·²åŠ è½½çš„æ•°æ®ã€‚è¯·å…ˆåœ¨å…¶ä»–æ¨¡å—åŠ è½½æ•°æ®ï¼Œæˆ–åœ¨æ­¤å¤„ä¸Šä¼ æ–°æ•°æ®ã€‚")
            return # Stop further processing if no data is active

    # Display active data source and preview
    st.markdown(f"**å½“å‰å¤„ç†æ•°æ®:** {source_description}")
    if df_to_process is not None and not df_to_process.empty:
        with st.expander("é¢„è§ˆå½“å‰æ•°æ® (å‰5è¡Œ)"):
            st.dataframe(df_to_process.head())
    elif df_to_process is not None and df_to_process.empty:
         st.warning("å½“å‰æ´»åŠ¨æ•°æ®ä¸ºç©ºã€‚")
         return
    else:
         # This case should be handled by the return above, but as a fallback:
         st.error("æ— æ³•ç¡®å®šè¦å¤„ç†çš„æ•°æ®ï¼Œè¯·å¯¼å…¥æ­£ç¡®çš„æ•°æ®ã€‚")
         return

    st.markdown("---")

    # --- Create Tabs for Processing ---
    st.header("2. æ•°æ®å¤„ç†æ“ä½œ")
    tab_vis, tab_seg = st.tabs(["ğŸ“Š æ•°æ®å¯è§†åŒ–", "âœ‚ï¸ æ•°æ®åˆ†å‰²"])

    # --- Visualization Tab ---
    with tab_vis:
        st.subheader("æ•°æ®å¯è§†åŒ–")
        st.markdown("é€‰æ‹©ä¸€ä¸ªåˆ—å’Œå›¾è¡¨ç±»å‹æ¥æ¢ç´¢æ•°æ®åˆ†å¸ƒã€‚")

        col1, col2 = st.columns(2)
        with col1:
            # Select column for visualization
            vis_col_options = [None] + all_columns
            # Reset selection if previous selection is no longer valid
            if st.session_state.dp_selected_vis_col not in all_columns:
                 st.session_state.dp_selected_vis_col = None
            vis_col_index = 0
            if st.session_state.dp_selected_vis_col:
                try: vis_col_index = vis_col_options.index(st.session_state.dp_selected_vis_col)
                except ValueError: pass
            st.session_state.dp_selected_vis_col = st.selectbox(
                "é€‰æ‹©è¦å¯è§†åŒ–çš„åˆ—:",
                options=vis_col_options,
                index=vis_col_index,
                key="dp_vis_col_select"
            )

        with col2:
            # Select plot type
            plot_options = ['Histogram', 'Box Plot', 'Bar Chart']
            plot_type_index = plot_options.index(st.session_state.dp_plot_type) if st.session_state.dp_plot_type in plot_options else 0
            st.session_state.dp_plot_type = st.selectbox(
                "é€‰æ‹©å›¾è¡¨ç±»å‹:",
                options=plot_options,
                index=plot_type_index,
                key="dp_plot_type_select"
            )

        # Generate and display plot
        if st.session_state.dp_selected_vis_col:
            fig = plot_selected_visualization(df_to_process, st.session_state.dp_selected_vis_col, st.session_state.dp_plot_type)
            if fig:
                st.pyplot(fig)
                plt.close(fig) # Close figure after displaying

    # --- Segmentation Tab ---
    with tab_seg:
        st.subheader("æ•°æ®åˆ†å‰²")
        st.markdown("æ ¹æ®é€‰å®šåˆ—çš„å€¼æˆ–èŒƒå›´å°†æ•°æ®åˆ†å‰²æˆä¸¤éƒ¨åˆ†ã€‚")

        col1, col2 = st.columns([2, 1])
        with col1:
            # Select column for segmentation
            seg_col_options = [None] + all_columns
            # Reset selection if previous selection is no longer valid
            if st.session_state.dp_segment_col not in all_columns:
                 st.session_state.dp_segment_col = None
            seg_col_index = 0
            if st.session_state.dp_segment_col:
                 try: seg_col_index = seg_col_options.index(st.session_state.dp_segment_col)
                 except ValueError: pass
            st.session_state.dp_segment_col = st.selectbox(
                "é€‰æ‹©ç”¨äºåˆ†å‰²çš„åˆ—:",
                options=seg_col_options,
                index=seg_col_index,
                key="dp_seg_col_select"
            )

        with col2:
            # Select segmentation mode
            seg_mode_options = {'value': 'æŒ‰ç‰¹å®šå€¼åˆ†å‰²', 'range': 'æŒ‰æ•°å€¼/æ—¥æœŸèŒƒå›´åˆ†å‰²'}
            st.session_state.dp_segment_mode = st.radio(
                "é€‰æ‹©åˆ†å‰²æ¨¡å¼:",
                options=list(seg_mode_options.keys()),
                format_func=lambda x: seg_mode_options[x],
                key="dp_seg_mode_radio",
                horizontal=True
            )

        # Input for segmentation criteria
        if st.session_state.dp_segment_col:
            # Display column type info
            try:
                 col_dtype = df_to_process[st.session_state.dp_segment_col].dtype
                 st.info(f"æ‰€é€‰åˆ— '{st.session_state.dp_segment_col}' çš„æ•°æ®ç±»å‹: {col_dtype}")
            except KeyError:
                 st.error("æ‰€é€‰åˆ—ä¸å­˜åœ¨ã€‚")


            if st.session_state.dp_segment_mode == 'value':
                st.session_state.dp_segment_value = st.text_input(
                    f"è¾“å…¥ '{st.session_state.dp_segment_col}' åˆ—ä¸­ç”¨äºåˆ†å‰²çš„å€¼:",
                    value=st.session_state.dp_segment_value if st.session_state.dp_segment_value is not None else "",
                    key="dp_seg_value_input",
                    help="è¾“å…¥è¦åŒ¹é…çš„ç¡®åˆ‡å€¼ï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰ã€‚å¯¹äºå¸ƒå°”å€¼ï¼Œå¯è¾“å…¥ True/False æˆ– 1/0ã€‚"
                )
            elif st.session_state.dp_segment_mode == 'range':
                col_range1, col_range2 = st.columns(2)
                with col_range1:
                    st.session_state.dp_segment_min = st.text_input(
                        "è¾“å…¥èŒƒå›´æœ€å°å€¼ (åŒ…å«):",
                        value=st.session_state.dp_segment_min if st.session_state.dp_segment_min is not None else "",
                        key="dp_seg_min_input",
                        help="å¯¹äºæ—¥æœŸæ—¶é—´ï¼Œæ ¼å¼å¦‚ 'YYYY-MM-DD' æˆ– 'YYYY-MM-DD HH:MM:SS'"
                    )
                with col_range2:
                    st.session_state.dp_segment_max = st.text_input(
                        "è¾“å…¥èŒƒå›´æœ€å¤§å€¼ (ä¸åŒ…å«):",
                        value=st.session_state.dp_segment_max if st.session_state.dp_segment_max is not None else "",
                        key="dp_seg_max_input",
                        help="å¯¹äºæ—¥æœŸæ—¶é—´ï¼Œæ ¼å¼å¦‚ 'YYYY-MM-DD' æˆ– 'YYYY-MM-DD HH:MM:SS'"
                    )

            # Button to perform segmentation
            if st.button("æ‰§è¡Œåˆ†å‰²", key="dp_run_segment_btn"):
                st.session_state.dp_segment_results = segment_data(
                    df_to_process, # Use the currently active dataframe
                    st.session_state.dp_segment_col,
                    st.session_state.dp_segment_mode,
                    st.session_state.dp_segment_value,
                    st.session_state.dp_segment_min,
                    st.session_state.dp_segment_max
                )
                # Rerun to display results immediately
                if st.session_state.dp_segment_results:
                     st.rerun()


        # Display segmentation results
        if st.session_state.dp_segment_results:
            st.markdown("---")
            st.subheader("åˆ†å‰²ç»“æœé¢„è§ˆ")
            res = st.session_state.dp_segment_results
            seg1_info = res.get('segment1', {})
            seg2_info = res.get('segment2', {})
            df1 = seg1_info.get('df', pd.DataFrame())
            df2 = seg2_info.get('df', pd.DataFrame())

            col_res1, col_res2 = st.columns(2)
            with col_res1:
                st.markdown(f"**éƒ¨åˆ† 1: {seg1_info.get('desc', '')} ({len(df1)} è¡Œ)**")
                if not df1.empty:
                    st.dataframe(df1.head())
                    # Download Button for Segment 1
                    csv1 = df1.to_csv(index=False).encode('utf-8-sig')
                    st.download_button(
                        label="ä¸‹è½½éƒ¨åˆ† 1 (CSV)",
                        data=csv1,
                        file_name="segment_1.csv",
                        mime="text/csv",
                        key="dp_download_seg1"
                    )
                else:
                    st.info("æ­¤éƒ¨åˆ†æ— æ•°æ®ã€‚")
            with col_res2:
                st.markdown(f"**éƒ¨åˆ† 2: {seg2_info.get('desc', '')} ({len(df2)} è¡Œ)**")
                if not df2.empty:
                    st.dataframe(df2.head())
                     # Download Button for Segment 2
                    csv2 = df2.to_csv(index=False).encode('utf-8-sig')
                    st.download_button(
                        label="ä¸‹è½½éƒ¨åˆ† 2 (CSV)",
                        data=csv2,
                        file_name="segment_2.csv",
                        mime="text/csv",
                        key="dp_download_seg2"
                    )
                else:
                    st.info("æ­¤éƒ¨åˆ†æ— æ•°æ®ã€‚")

# --- Entry point for testing (optional) ---
# if __name__ == "__main__":
#     st.set_page_config(layout="wide", page_title="æ•°æ®å¤„ç†æµ‹è¯•")
#     # Manually set some dummy data in session state for standalone testing
#     if 'classification_data' not in st.session_state:
#         st.session_state.classification_data = pd.DataFrame({
#             'NumericCol': np.random.rand(100) * 10,
#             'CategoryCol': np.random.choice(['A', 'B', 'C', 'D'], 100),
#             'DateCol': pd.to_datetime(pd.date_range(start='2023-01-01', periods=100, freq='D')),
#             'BoolCol': np.random.choice([True, False], 100)
#         })
#     show_data_processing_page()

