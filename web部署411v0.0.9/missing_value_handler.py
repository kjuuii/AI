# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import SimpleImputer, KNNImputer
# Consider adding MICE if needed, it requires: pip install fancyimpute or iterativeimputer
# from sklearn.experimental import enable_iterative_imputer
# from sklearn.impute import IterativeImputer
import io
import base64
import platform
import matplotlib.font_manager as fm
import os

# --- Font Setup (Reusing from other modules) ---
def setup_chinese_font():
    """Set up Chinese font support for matplotlib."""
    system = platform.system()
    font_candidates = []
    if system == 'Windows':
        font_candidates = ['Microsoft YaHei', 'SimHei', 'SimSun', 'Arial Unicode MS']
    elif system == 'Darwin': # macOS
        font_candidates = ['PingFang SC', 'Heiti SC', 'STHeiti', 'Apple LiGothic Medium']
    else: # Linux and other systems
        font_candidates = ['Noto Sans CJK SC', 'WenQuanYi Micro Hei', 'Droid Sans Fallback']

    font_candidates.extend(['DejaVu Sans', 'Arial', 'Helvetica']) # Fallback fonts

    font_prop = None
    for font_name in font_candidates:
        try:
            font_path = fm.findfont(fm.FontProperties(family=font_name))
            if os.path.exists(font_path) and 'DejaVuSans' not in font_path:
                print(f"å­—ä½“æ—¥å¿—: ä½¿ç”¨å­—ä½“ '{font_name}' åœ¨è·¯å¾„: {font_path}")
                plt.rcParams['font.family'] = 'sans-serif'
                plt.rcParams['font.sans-serif'] = [font_name] + plt.rcParams['font.sans-serif']
                font_prop = fm.FontProperties(family=font_name)
                break
        except Exception as e:
            print(f"å­—ä½“æ—¥å¿—: å°è¯•å­—ä½“ {font_name} å¤±è´¥: {e}")

    if not font_prop:
        print("å­—ä½“æ—¥å¿—: æœªæ‰¾åˆ°åˆé€‚çš„ä¸­æ–‡å­—ä½“ï¼Œç»˜å›¾ä¸­çš„ä¸­æ–‡å¯èƒ½æ— æ³•æ­£å¸¸æ˜¾ç¤ºã€‚")

    plt.rcParams['axes.unicode_minus'] = False
    return font_prop

FONT_PROP = setup_chinese_font()

# --- Helper Functions ---
def apply_plot_style(ax):
    """Apply consistent styling to matplotlib axes."""
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.grid(True, linestyle='--', alpha=0.6, color='#bdc3c7')
    ax.tick_params(axis='both', which='major', labelsize=9, colors='#34495e')
    ax.xaxis.label.set_fontsize(10)
    ax.yaxis.label.set_fontsize(10)
    ax.title.set_fontsize(12)
    ax.title.set_fontweight('bold')
    ax.xaxis.label.set_fontweight('bold')
    ax.yaxis.label.set_fontweight('bold')
    # Apply Chinese font if available
    font_kwargs = {'fontproperties': FONT_PROP} if FONT_PROP else {}
    if font_kwargs:
        for label in ax.get_xticklabels() + ax.get_yticklabels():
            label.set_fontproperties(FONT_PROP)
        ax.xaxis.label.set_fontproperties(FONT_PROP)
        ax.yaxis.label.set_fontproperties(FONT_PROP)
        ax.title.set_fontproperties(FONT_PROP)
    return ax

def plot_missing_values_heatmap(df):
    """Create a heatmap visualization of missing values."""
    fig, ax = plt.subplots(figsize=(10, 6), dpi=80)
    sns.heatmap(df.isnull(), cbar=False, cmap='viridis', ax=ax)
    ax.set_title("æ•°æ®ç¼ºå¤±å€¼çƒ­åŠ›å›¾", fontproperties=FONT_PROP if FONT_PROP else None)
    ax.set_xlabel("åˆ—å", fontproperties=FONT_PROP if FONT_PROP else None)
    ax.set_ylabel("æ ·æœ¬ç´¢å¼•", fontproperties=FONT_PROP if FONT_PROP else None)
    # Apply Chinese font to tick labels if needed
    if FONT_PROP:
        plt.setp(ax.get_xticklabels(), fontproperties=FONT_PROP, rotation=45, ha="right")
        plt.setp(ax.get_yticklabels(), fontproperties=FONT_PROP)
    else:
         plt.setp(ax.get_xticklabels(), rotation=45, ha="right")

    plt.tight_layout()
    return fig

def get_download_link_csv(df, filename, text):
    """Generates a link to download a DataFrame as a CSV file."""
    csv = df.to_csv(index=False, encoding='utf-8-sig')
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">{text}</a>'
    return href

# --- Imputation Functions ---
def impute_with_strategy(df, columns_to_impute, strategy='mean'):
    """Impute missing values using SimpleImputer (mean, median, most_frequent)."""
    imputer = SimpleImputer(strategy=strategy)
    df_imputed = df.copy()
    # Fit on selected columns and transform
    df_imputed[columns_to_impute] = imputer.fit_transform(df[columns_to_impute])
    return df_imputed

def impute_with_knn(df, columns_to_impute, n_neighbors=5):
    """Impute missing values using KNNImputer."""
    imputer = KNNImputer(n_neighbors=n_neighbors)
    df_imputed = df.copy()
    # KNNImputer works best with scaled data, but for simplicity, apply directly here.
    # Consider adding scaling as an option.
    # Fit on selected columns and transform
    df_imputed[columns_to_impute] = imputer.fit_transform(df[columns_to_impute])
    return df_imputed

# --- New Imputation Functions ---
def impute_with_zero(df, columns_to_impute):
    """Impute missing values with 0."""
    df_imputed = df.copy()
    df_imputed[columns_to_impute] = df_imputed[columns_to_impute].fillna(0)
    return df_imputed

def impute_with_ffill(df, columns_to_impute):
    """Impute missing values using forward fill."""
    df_imputed = df.copy()
    df_imputed[columns_to_impute] = df_imputed[columns_to_impute].ffill()
    # Note: ffill might leave NaNs at the beginning if the first value is NaN.
    # Consider adding a subsequent bfill or zero fill for those cases if needed.
    # For simplicity, we'll leave it as is for now.
    return df_imputed

def impute_with_bfill(df, columns_to_impute):
    """Impute missing values using backward fill."""
    df_imputed = df.copy()
    df_imputed[columns_to_impute] = df_imputed[columns_to_impute].bfill()
    # Note: bfill might leave NaNs at the end if the last value is NaN.
    # Consider adding a subsequent ffill or zero fill for those cases if needed.
    return df_imputed
# --- End New Imputation Functions ---

# --- Streamlit UI Functions ---
def initialize_missing_value_state():
    """Initialize session state variables for the missing value page."""
    defaults = {
        'mv_data': None,            # Original uploaded data
        'mv_data_imputed': None,    # Data after imputation
        'mv_missing_info': None,    # DataFrame with missing value stats
        'mv_imputation_method': 'mean', # Default imputation method
        'mv_columns_to_impute': [], # Columns selected for imputation
        'mv_knn_neighbors': 5,      # Parameter for KNN
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

def show_missing_value_page():
    """Main function to display the missing value handling page."""
    initialize_missing_value_state()

    st.title("ğŸ§© æ•°æ®ç¼ºå¤±å€¼å¤„ç†")
    st.markdown("---")
    st.info("ä¸Šä¼ æ•°æ®ï¼Œåˆ†æç¼ºå¤±å€¼ï¼Œå¹¶é€‰æ‹©åˆé€‚çš„æ–¹æ³•è¿›è¡Œå¡«å……ã€‚")

    # --- Create Tabs ---
    tab1, tab2, tab3 = st.tabs(["ğŸ“ æ•°æ®å¯¼å…¥ä¸åˆ†æ", "ğŸ› ï¸ ç¼ºå¤±å€¼å¡«å……", "ğŸ“Š ç»“æœå±•ç¤º"])

    with tab1:
        create_mv_data_import_analysis_section()

    with tab2:
        create_mv_imputation_section()

    with tab3:
        create_mv_results_section()

def create_mv_data_import_analysis_section():
    """UI section for data import and missing value analysis."""
    st.header("1. æ•°æ®å¯¼å…¥ä¸ç¼ºå¤±å€¼åˆ†æ")

    uploaded_file = st.file_uploader("ä¸Šä¼ åŒ…å«æ•°æ®çš„æ–‡ä»¶ (CSV/Excel)", type=["csv", "xlsx", "xls"], key="mv_uploader")

    if uploaded_file:
        if st.button("åŠ è½½å¹¶åˆ†ææ•°æ®", key="mv_load_analyze_btn"):
            with st.spinner("æ­£åœ¨åŠ è½½å’Œåˆ†ææ•°æ®..."):
                try:
                    # Load data
                    data = pd.read_csv(uploaded_file) if uploaded_file.name.lower().endswith('.csv') else pd.read_excel(uploaded_file)

                    # Store original data
                    st.session_state.mv_data = data
                    st.session_state.mv_data_imputed = None # Clear previous imputed data

                    # Analyze missing values
                    missing_counts = data.isnull().sum()
                    missing_percentages = (missing_counts / len(data)) * 100
                    missing_info = pd.DataFrame({
                        'ç¼ºå¤±æ•°é‡': missing_counts,
                        'ç¼ºå¤±æ¯”ä¾‹ (%)': missing_percentages
                    })
                    # Filter to show only columns with missing values
                    missing_info = missing_info[missing_info['ç¼ºå¤±æ•°é‡'] > 0].sort_values(by='ç¼ºå¤±æ¯”ä¾‹ (%)', ascending=False)
                    st.session_state.mv_missing_info = missing_info

                    st.success(f"æˆåŠŸåŠ è½½æ–‡ä»¶: {uploaded_file.name} ({len(data)} è¡Œ, {len(data.columns)} åˆ—)")

                except Exception as e:
                    st.error(f"åŠ è½½æˆ–åˆ†ææ•°æ®æ—¶å‡ºé”™: {e}")
                    st.session_state.mv_data = None
                    st.session_state.mv_missing_info = None

    # Display analysis results if data is loaded
    if st.session_state.mv_data is not None:
        st.subheader("æ•°æ®é¢„è§ˆ (å‰5è¡Œ)")
        st.dataframe(st.session_state.mv_data.head())

        st.subheader("ç¼ºå¤±å€¼ç»Ÿè®¡")
        if st.session_state.mv_missing_info is not None and not st.session_state.mv_missing_info.empty:
            st.dataframe(st.session_state.mv_missing_info)

            st.subheader("ç¼ºå¤±å€¼çƒ­åŠ›å›¾")
            try:
                fig = plot_missing_values_heatmap(st.session_state.mv_data)
                st.pyplot(fig)
            except Exception as e:
                st.error(f"ç»˜åˆ¶çƒ­åŠ›å›¾æ—¶å‡ºé”™: {e}")
        elif st.session_state.mv_missing_info is not None:
            st.success("ğŸ‰ æ•°æ®ä¸­æ²¡æœ‰å‘ç°ç¼ºå¤±å€¼ï¼")
        else:
            st.info("è¯·ç‚¹å‡»â€œåŠ è½½å¹¶åˆ†ææ•°æ®â€æŒ‰é’®ä»¥æŸ¥çœ‹ç¼ºå¤±å€¼ä¿¡æ¯ã€‚")

def create_mv_imputation_section():
    """UI section for selecting imputation method and columns."""
    st.header("2. ç¼ºå¤±å€¼å¡«å……æ–¹æ³•é€‰æ‹©")

    if st.session_state.mv_data is None:
        st.info("è¯·å…ˆåœ¨â€œæ•°æ®å¯¼å…¥ä¸åˆ†æâ€é€‰é¡¹å¡ä¸­åŠ è½½æ•°æ®ã€‚")
        return

    if st.session_state.mv_missing_info is None or st.session_state.mv_missing_info.empty:
        st.info("å½“å‰æ•°æ®æ²¡æœ‰æ£€æµ‹åˆ°ç¼ºå¤±å€¼ï¼Œæ— éœ€å¡«å……ã€‚")
        return

    # --- Select Columns for Imputation ---
    st.subheader("é€‰æ‹©è¦å¡«å……çš„åˆ—")
    # Default to columns with missing values
    default_cols = st.session_state.mv_missing_info.index.tolist()
    # Ensure columns still exist in the dataframe
    valid_default_cols = [col for col in default_cols if col in st.session_state.mv_data.columns]

    # Get all columns suitable for imputation (numeric or potentially categorical)
    # For simplicity, let's focus on numeric for now, but allow selecting others
    all_columns = st.session_state.mv_data.columns.tolist()

    st.session_state.mv_columns_to_impute = st.multiselect(
        "é€‰æ‹©éœ€è¦å¡«å……ç¼ºå¤±å€¼çš„åˆ—",
        options=all_columns,
        default=valid_default_cols,
        key="mv_col_select"
    )

    if not st.session_state.mv_columns_to_impute:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€åˆ—è¿›è¡Œå¡«å……ã€‚")
        return

    # --- Select Imputation Method ---
    st.subheader("é€‰æ‹©å¡«å……æ–¹æ³•")
    # --- Updated: Added 'zero', 'ffill', 'bfill' ---
    imputation_options = {
        'zero': "å¡«å……ä¸º 0",
        'mean': "å‡å€¼å¡«å…… (é€‚ç”¨äºæ•°å€¼å‹)",
        'median': "ä¸­ä½æ•°å¡«å…… (é€‚ç”¨äºæ•°å€¼å‹ï¼Œå¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿ)",
        'most_frequent': "ä¼—æ•°å¡«å…… (é€‚ç”¨äºæ•°å€¼å‹æˆ–ç±»åˆ«å‹)",
        'ffill': "å‰å‘å¡«å…… (ç”¨å‰ä¸€ä¸ªéç¼ºå¤±å€¼å¡«å……)",
        'bfill': "åå‘å¡«å…… (ç”¨åä¸€ä¸ªéç¼ºå¤±å€¼å¡«å……)",
        'knn': "K-è¿‘é‚»å¡«å…… (åŸºäºç›¸ä¼¼æ ·æœ¬å¡«å……ï¼Œè®¡ç®—é‡è¾ƒå¤§)",
        # 'mice': "å¤šé‡æ’è¡¥ (MICE - é«˜çº§æ–¹æ³•ï¼Œæš‚æœªå®ç°)"
    }
    # --- End Update ---

    st.session_state.mv_imputation_method = st.radio(
        "é€‰æ‹©å¡«å……ç­–ç•¥:",
        options=list(imputation_options.keys()),
        format_func=lambda x: imputation_options[x],
        key="mv_method_radio"
    )

    # --- Display Method Descriptions and Parameters ---
    method = st.session_state.mv_imputation_method
    with st.expander(f"å…³äº **{imputation_options[method]}** çš„è¯´æ˜"):
        # --- Updated: Added descriptions for new methods ---
        if method == 'zero':
            st.markdown("""
            - **ç®€ä»‹**: å°†æ‰€æœ‰é€‰å®šåˆ—ä¸­çš„ç¼ºå¤±å€¼ï¼ˆNaNï¼‰æ›¿æ¢ä¸º0ã€‚
            - **é€‚ç”¨èŒƒå›´**: é€‚ç”¨äºç¼ºå¤±å€¼æœ¬èº«å°±ä»£è¡¨0æˆ–è€…å¯ä»¥åˆç†åœ°è§†ä¸º0çš„æƒ…å†µï¼ˆä¾‹å¦‚ï¼ŒæŸäº›è®¡æ•°æˆ–é‡‘é¢ï¼‰ã€‚ä¹Ÿé€‚ç”¨äºæŸäº›æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚åŸºäºæ ‘çš„æ¨¡å‹ï¼‰å¯ä»¥å¤„ç†0å€¼çš„æƒ…å†µã€‚
            - **ä¼˜ç‚¹**: å®ç°éå¸¸ç®€å•å¿«é€Ÿã€‚
            - **ç¼ºç‚¹**: å¯èƒ½ä¼šæ˜¾è‘—æ”¹å˜åˆ—çš„åˆ†å¸ƒï¼ˆå‡å€¼ã€æ–¹å·®ç­‰ï¼‰ï¼Œå¼•å…¥åå·®ï¼›å¦‚æœ0ä¸æ˜¯ä¸€ä¸ªæœ‰æ„ä¹‰çš„æ›¿æ¢å€¼ï¼Œå¯èƒ½ä¼šè¯¯å¯¼æ¨¡å‹ã€‚
            """)
        elif method == 'mean':
            st.markdown("""
            - **ç®€ä»‹**: ä½¿ç”¨è¯¥åˆ—æ‰€æœ‰éç¼ºå¤±å€¼çš„å¹³å‡æ•°æ¥å¡«å……ç¼ºå¤±å€¼ã€‚
            - **é€‚ç”¨èŒƒå›´**: æ•°å€¼å‹æ•°æ®ï¼Œä¸”æ•°æ®åˆ†å¸ƒè¿‘ä¼¼æ­£æ€åˆ†å¸ƒï¼Œå¯¹å¼‚å¸¸å€¼è¾ƒæ•æ„Ÿã€‚
            - **ä¼˜ç‚¹**: è®¡ç®—ç®€å•å¿«é€Ÿã€‚
            - **ç¼ºç‚¹**: ä¼šæ”¹å˜æ•°æ®çš„æ–¹å·®ï¼›å¯¹å¼‚å¸¸å€¼æ•æ„Ÿã€‚
            """)
        elif method == 'median':
            st.markdown("""
            - **ç®€ä»‹**: ä½¿ç”¨è¯¥åˆ—æ‰€æœ‰éç¼ºå¤±å€¼çš„ä¸­ä½æ•°æ¥å¡«å……ç¼ºå¤±å€¼ã€‚
            - **é€‚ç”¨èŒƒå›´**: æ•°å€¼å‹æ•°æ®ï¼Œç‰¹åˆ«æ˜¯å½“æ•°æ®å­˜åœ¨åæ€åˆ†å¸ƒæˆ–åŒ…å«å¼‚å¸¸å€¼æ—¶ã€‚
            - **ä¼˜ç‚¹**: å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿï¼›è®¡ç®—ç›¸å¯¹ç®€å•ã€‚
            - **ç¼ºç‚¹**: å¯èƒ½ä¸å¦‚å‡å€¼å¡«å……ä¿ç•™æ•°æ®çš„æŸäº›ç»Ÿè®¡ç‰¹æ€§ã€‚
            """)
        elif method == 'most_frequent':
            st.markdown("""
            - **ç®€ä»‹**: ä½¿ç”¨è¯¥åˆ—ä¸­å‡ºç°é¢‘ç‡æœ€é«˜çš„å€¼ï¼ˆä¼—æ•°ï¼‰æ¥å¡«å……ç¼ºå¤±å€¼ã€‚
            - **é€‚ç”¨èŒƒå›´**: ç±»åˆ«å‹æ•°æ®ï¼Œä¹Ÿå¯ç”¨äºæ•°å€¼å‹æ•°æ®ï¼ˆç‰¹åˆ«æ˜¯ç¦»æ•£æ•°å€¼ï¼‰ã€‚
            - **ä¼˜ç‚¹**: é€‚ç”¨äºç±»åˆ«æ•°æ®ï¼›å®ç°ç®€å•ã€‚
            - **ç¼ºç‚¹**: å¯èƒ½å¼•å…¥åå·®ï¼Œç‰¹åˆ«æ˜¯å½“ä¼—æ•°å æ¯”å¾ˆé«˜æ—¶ï¼›ä¸é€‚ç”¨äºè¿ç»­æ•°å€¼æ•°æ®ã€‚
            """)
        elif method == 'ffill':
            st.markdown("""
            - **ç®€ä»‹**: å‰å‘å¡«å…… (Forward Fill)ã€‚ä½¿ç”¨è¯¥åˆ—ä¸­ç¼ºå¤±å€¼ä¹‹å‰çš„æœ€åä¸€ä¸ªæœ‰æ•ˆè§‚æµ‹å€¼æ¥å¡«å……ã€‚
            - **é€‚ç”¨èŒƒå›´**: æ—¶é—´åºåˆ—æ•°æ®æˆ–æœ‰åºæ•°æ®ï¼Œå‡è®¾ç¼ºå¤±å€¼ä¸ç´§é‚»çš„å‰ä¸€ä¸ªå€¼ç›¸ä¼¼ã€‚
            - **ä¼˜ç‚¹**: å®ç°ç®€å•ï¼›åœ¨æ—¶é—´åºåˆ—ä¸­èƒ½ä¿æŒä¸€å®šçš„è¿ç»­æ€§ã€‚
            - **ç¼ºç‚¹**: å¦‚æœç¼ºå¤±å€¼ä¹‹å‰çš„æœ‰æ•ˆå€¼è·ç¦»å¾ˆè¿œæˆ–ä¸ç›¸å…³ï¼Œå¡«å……æ•ˆæœå¯èƒ½ä¸å¥½ï¼›å¦‚æœåˆ—çš„å¼€å¤´å°±æœ‰ç¼ºå¤±å€¼ï¼Œåˆ™æ— æ³•å¡«å……ã€‚
            """)
        elif method == 'bfill':
            st.markdown("""
            - **ç®€ä»‹**: åå‘å¡«å…… (Backward Fill)ã€‚ä½¿ç”¨è¯¥åˆ—ä¸­ç¼ºå¤±å€¼ä¹‹åçš„ç¬¬ä¸€ä¸ªæœ‰æ•ˆè§‚æµ‹å€¼æ¥å¡«å……ã€‚
            - **é€‚ç”¨èŒƒå›´**: æ—¶é—´åºåˆ—æ•°æ®æˆ–æœ‰åºæ•°æ®ï¼Œå‡è®¾ç¼ºå¤±å€¼ä¸ç´§é‚»çš„åä¸€ä¸ªå€¼ç›¸ä¼¼ã€‚
            - **ä¼˜ç‚¹**: å®ç°ç®€å•ï¼›å¯ä»¥å¡«å……åˆ—å¼€å¤´çš„ç¼ºå¤±å€¼ï¼ˆå¦‚æœåé¢æœ‰å€¼ï¼‰ã€‚
            - **ç¼ºç‚¹**: å¦‚æœç¼ºå¤±å€¼ä¹‹åçš„æœ‰æ•ˆå€¼è·ç¦»å¾ˆè¿œæˆ–ä¸ç›¸å…³ï¼Œå¡«å……æ•ˆæœå¯èƒ½ä¸å¥½ï¼›å¦‚æœåˆ—çš„æœ«å°¾æœ‰ç¼ºå¤±å€¼ï¼Œåˆ™æ— æ³•å¡«å……ã€‚
            """)
        # --- End Update ---
        elif method == 'knn':
            st.markdown("""
            - **ç®€ä»‹**: ä½¿ç”¨Kä¸ªæœ€ç›¸ä¼¼ï¼ˆæœ€è¿‘é‚»ï¼‰æ ·æœ¬çš„ç‰¹å¾å€¼çš„åŠ æƒå¹³å‡ï¼ˆæˆ–ä¼—æ•°ï¼‰æ¥ä¼°è®¡ç¼ºå¤±å€¼ã€‚
            - **é€‚ç”¨èŒƒå›´**: æ•°å€¼å‹æ•°æ®ï¼Œèƒ½æ•æ‰ç‰¹å¾é—´çš„å¤æ‚å…³ç³»ã€‚
            - **ä¼˜ç‚¹**: é€šå¸¸æ¯”ç®€å•å¡«å……æ–¹æ³•æ›´å‡†ç¡®ï¼›èƒ½å¤„ç†éçº¿æ€§å…³ç³»ã€‚
            - **ç¼ºç‚¹**: è®¡ç®—æˆæœ¬è¾ƒé«˜ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤§æ•°æ®é›†ï¼›å¯¹Kå€¼çš„é€‰æ‹©æ•æ„Ÿï¼›éœ€è¦ç¡®å®šåˆé€‚çš„è·ç¦»åº¦é‡ã€‚
            """)
            # KNN specific parameter
            st.session_state.mv_knn_neighbors = st.slider(
                "Kå€¼ (é‚»å±…æ•°é‡)", min_value=1, max_value=20,
                value=st.session_state.mv_knn_neighbors, step=1, key="mv_knn_k"
            )
        # elif method == 'mice':
        #     st.markdown("""
        #     - **ç®€ä»‹**: å¤šé‡æ’è¡¥æ³• (Multivariate Imputation by Chained Equations)ã€‚é€šè¿‡è¿­ä»£å›å½’æ¨¡å‹æ¥ä¼°è®¡ç¼ºå¤±å€¼ï¼Œè€ƒè™‘äº†å˜é‡é—´çš„ä¸ç¡®å®šæ€§ã€‚
        #     - **é€‚ç”¨èŒƒå›´**: æ•°å€¼å‹å’Œç±»åˆ«å‹æ•°æ®ï¼Œèƒ½å¤„ç†å¤æ‚çš„ç¼ºå¤±æ¨¡å¼ã€‚
        #     - **ä¼˜ç‚¹**: æœ€å‡†ç¡®çš„æ–¹æ³•ä¹‹ä¸€ï¼›èƒ½è¾ƒå¥½åœ°ä¿ç•™æ•°æ®çš„ç»Ÿè®¡ç‰¹æ€§å’Œä¸ç¡®å®šæ€§ã€‚
        #     - **ç¼ºç‚¹**: è®¡ç®—éå¸¸å¯†é›†ï¼›å®ç°å’Œç†è§£ç›¸å¯¹å¤æ‚ã€‚
        #     - **æ³¨æ„**: æ­¤æ–¹æ³•å½“å‰æœªåœ¨æ­¤åº”ç”¨ä¸­å®ç°ã€‚
        #     """)

    # --- Apply Imputation Button ---
    if st.button("åº”ç”¨å¡«å……æ–¹æ³•", key="mv_apply_btn", type="primary"):
        run_imputation()

def run_imputation():
    """Runs the selected imputation method."""
    df = st.session_state.mv_data
    columns_to_impute = st.session_state.mv_columns_to_impute
    method = st.session_state.mv_imputation_method

    if df is None or not columns_to_impute:
        st.error("æ— æ³•æ‰§è¡Œå¡«å……ï¼šæ•°æ®æœªåŠ è½½æˆ–æœªé€‰æ‹©è¦å¡«å……çš„åˆ—ã€‚")
        return

    # Check if selected columns exist
    missing_in_df = [col for col in columns_to_impute if col not in df.columns]
    if missing_in_df:
        st.error(f"é€‰æ‹©çš„åˆ—åœ¨æ•°æ®ä¸­ä¸å­˜åœ¨: {', '.join(missing_in_df)}")
        return

    # Filter to only impute columns that actually have missing values
    actual_cols_with_missing = df[columns_to_impute].isnull().sum()
    actual_cols_to_impute = actual_cols_with_missing[actual_cols_with_missing > 0].index.tolist()

    if not actual_cols_to_impute:
        st.warning("é€‰æ‹©çš„åˆ—ä¸­æ²¡æœ‰ç¼ºå¤±å€¼ï¼Œæ— éœ€å¡«å……ã€‚")
        st.session_state.mv_data_imputed = df.copy() # Store original as imputed
        return

    st.info(f"å°†å¯¹ä»¥ä¸‹åˆ—åº”ç”¨ '{imputation_options.get(method, method)}' å¡«å……: {', '.join(actual_cols_to_impute)}")

    with st.spinner(f"æ­£åœ¨ä½¿ç”¨ {imputation_options.get(method, method)} æ–¹æ³•å¡«å……ç¼ºå¤±å€¼..."):
        try:
            df_imputed = None
            # Select only numeric columns for mean, median, knn for now
            numeric_cols_selected = df[actual_cols_to_impute].select_dtypes(include=np.number).columns.tolist()

            # --- Updated: Handle new methods ---
            if method == 'zero':
                # Zero fill can apply to any selected column type
                df_imputed = impute_with_zero(df, actual_cols_to_impute)
            elif method == 'ffill':
                # ffill can apply to any selected column type
                df_imputed = impute_with_ffill(df, actual_cols_to_impute)
            elif method == 'bfill':
                # bfill can apply to any selected column type
                df_imputed = impute_with_bfill(df, actual_cols_to_impute)
            # --- End Update ---
            elif method in ['mean', 'median', 'most_frequent']:
                strategy = method
                cols_for_simple_impute = actual_cols_to_impute # Allow most_frequent for non-numeric
                if method in ['mean', 'median']:
                     cols_for_simple_impute = numeric_cols_selected
                     if not cols_for_simple_impute:
                          st.error(f"é€‰æ‹©çš„æ–¹æ³• '{method}' ä»…é€‚ç”¨äºæ•°å€¼åˆ—ï¼Œä½†æ‰€é€‰åˆ—ä¸­æ²¡æœ‰æ•°å€¼åˆ—ã€‚")
                          return
                df_imputed = impute_with_strategy(df, cols_for_simple_impute, strategy)

            elif method == 'knn':
                if not numeric_cols_selected:
                    st.error("KNNå¡«å……ä»…é€‚ç”¨äºæ•°å€¼åˆ—ï¼Œä½†æ‰€é€‰åˆ—ä¸­æ²¡æœ‰æ•°å€¼åˆ—ã€‚")
                    return
                n_neighbors = st.session_state.mv_knn_neighbors
                df_imputed = impute_with_knn(df, numeric_cols_selected, n_neighbors)

            # elif method == 'mice':
            #     st.error("MICEæ–¹æ³•æš‚æœªå®ç°ã€‚")
            #     return

            else:
                st.error("é€‰æ‹©äº†æ— æ•ˆçš„å¡«å……æ–¹æ³•ã€‚")
                return

            # Store the imputed data
            st.session_state.mv_data_imputed = df_imputed
            st.success("ç¼ºå¤±å€¼å¡«å……å®Œæˆï¼è¯·å‰å¾€â€œç»“æœå±•ç¤ºâ€é€‰é¡¹å¡æŸ¥çœ‹ã€‚")

        except Exception as e:
            st.error(f"å¡«å……è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            st.code(traceback.format_exc())
            st.session_state.mv_data_imputed = None

def create_mv_results_section():
    """UI section to display the data after imputation."""
    st.header("3. å¡«å……ç»“æœå±•ç¤º")

    if st.session_state.mv_data_imputed is None:
        st.info("è¯·å…ˆåœ¨â€œç¼ºå¤±å€¼å¡«å……â€é€‰é¡¹å¡ä¸­åº”ç”¨å¡«å……æ–¹æ³•ã€‚")
        return

    st.subheader("å¡«å……åçš„æ•°æ®é¢„è§ˆ (å‰5è¡Œ)")
    st.dataframe(st.session_state.mv_data_imputed.head())

    # Verify if missing values are filled in the selected columns
    st.subheader("å¡«å……åç¼ºå¤±å€¼æ£€æŸ¥")
    # Check only the columns that were *intended* for imputation
    cols_checked = st.session_state.mv_columns_to_impute
    if not cols_checked: # If somehow selection is empty, check all columns
         cols_checked = st.session_state.mv_data_imputed.columns.tolist()

    missing_after = st.session_state.mv_data_imputed[cols_checked].isnull().sum()
    missing_after_df = pd.DataFrame({'å¡«å……åç¼ºå¤±æ•°é‡': missing_after})
    missing_after_df = missing_after_df[missing_after_df['å¡«å……åç¼ºå¤±æ•°é‡'] > 0]

    if missing_after_df.empty:
        st.success("åŸå…ˆé€‰æ‹©å¡«å……çš„åˆ—ä¸­çš„ç¼ºå¤±å€¼å·²æˆåŠŸå¤„ç†ï¼")
        # Optionally show heatmap of the whole dataset after imputation
        st.subheader("å¡«å……åæ•°æ®æ•´ä½“ç¼ºå¤±å€¼çƒ­åŠ›å›¾")
        try:
            fig_after = plot_missing_values_heatmap(st.session_state.mv_data_imputed)
            st.pyplot(fig_after)
        except Exception as e:
            st.error(f"ç»˜åˆ¶å¡«å……åçƒ­åŠ›å›¾æ—¶å‡ºé”™: {e}")

    else:
        st.warning("å¡«å……åï¼Œä»¥ä¸‹åŸå…ˆé€‰æ‹©çš„åˆ—ä»å­˜åœ¨ç¼ºå¤±å€¼ (å¯èƒ½æ˜¯å› ä¸ºé€‰æ‹©äº†ä¸é€‚ç”¨çš„æ–¹æ³•ã€åˆ—ç±»å‹ï¼Œæˆ–è€…ffill/bfillæ— æ³•å¡«å……å¼€å¤´/ç»“å°¾çš„NaN):")
        st.dataframe(missing_after_df)
        # Show heatmap anyway to see the overall picture
        st.subheader("å¡«å……åæ•°æ®æ•´ä½“ç¼ºå¤±å€¼çƒ­åŠ›å›¾")
        try:
            fig_after = plot_missing_values_heatmap(st.session_state.mv_data_imputed)
            st.pyplot(fig_after)
        except Exception as e:
            st.error(f"ç»˜åˆ¶å¡«å……åçƒ­åŠ›å›¾æ—¶å‡ºé”™: {e}")


    # Download button for imputed data
    st.subheader("ä¸‹è½½å¡«å……åçš„æ•°æ®")
    if st.button("å‡†å¤‡ä¸‹è½½æ–‡ä»¶", key="mv_prep_download"):
        try:
            df_to_download = st.session_state.mv_data_imputed
            # Use a more descriptive filename including the method
            method_name = st.session_state.mv_imputation_method.replace('_', '-')
            filename = f"imputed_data_{method_name}.csv"
            download_link = get_download_link_csv(df_to_download, filename, f"ç‚¹å‡»ä¸‹è½½ {filename}")
            st.markdown(download_link, unsafe_allow_html=True)
        except Exception as e:
            st.error(f"å‡†å¤‡ä¸‹è½½æ–‡ä»¶æ—¶å‡ºé”™: {e}")

# --- Main function entry point (for potential direct script run) ---
if __name__ == "__main__":
    # This part is optional, allows running this module directly for testing
    st.set_page_config(layout="wide", page_title="ç¼ºå¤±å€¼å¤„ç†")
    show_missing_value_page()
